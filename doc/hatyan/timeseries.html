<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>hatyan.timeseries API documentation</title>
<meta name="description" content="timeseries.py contains all definitions related to hatyan timeseries â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>hatyan.timeseries</code></h1>
</header>
<section id="section-intro">
<p>timeseries.py contains all definitions related to hatyan timeseries.</p>
<p>hatyan is a Python program for tidal analysis and prediction, based on the FORTRAN version.
Copyright (C) 2019-2020 Rijkswaterstaat.
Maintained by Deltares, contact: Jelmer Veenstra (jelmer.veenstra@deltares.nl).
Source code available at: <a href="https://repos.deltares.nl/repos/lib_tide/trunk/src/hatyan_python/hatyan">https://repos.deltares.nl/repos/lib_tide/trunk/src/hatyan_python/hatyan</a></p>
<p>This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.</p>
<p>This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
See the
GNU General Public License for more details.</p>
<p>You should have received a copy of the GNU General Public License
along with this program.
If not, see <a href="https://www.gnu.org/licenses/">https://www.gnu.org/licenses/</a>.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># -*- coding: utf-8 -*-
&#34;&#34;&#34;
timeseries.py contains all definitions related to hatyan timeseries.

hatyan is a Python program for tidal analysis and prediction, based on the FORTRAN version. 
Copyright (C) 2019-2020 Rijkswaterstaat.
Maintained by Deltares, contact: Jelmer Veenstra (jelmer.veenstra@deltares.nl).
Source code available at: https://repos.deltares.nl/repos/lib_tide/trunk/src/hatyan_python/hatyan

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program.  If not, see &lt;https://www.gnu.org/licenses/&gt;.

&#34;&#34;&#34;


def calc_HWLW(ts, calc_HWLW345=False, calc_HWLW345_cleanup1122=True, debug=False):
    &#34;&#34;&#34;
    
    Calculates extremes (high and low waters) for the provided timeseries. 
    This definition uses scipy.signal.find_peaks() with arguments &#39;distance&#39; and &#39;prominence&#39;. 
    The minimal &#39;distance&#39; between two high or low water peaks is based on the M2 period: 12.42/1.5=8.28 hours for HW and 12.42/1.7=7.30 hours for LW (larger because of aggers). 
    Based on tests with several stations the &#39;prominence&#39; is set to 0.1 to avoid local dips around high water to be seen as low waters.
    The prominence for local extremes is set to 0.01m, to filter out very minor dips in the timeseries.
    If there are two equal high or low water values, the first one is taken. 
    This function can deal with gaps. Since scipy.signal.find_peaks() warns about nan values, those are removed first.
    
    Parameters
    ----------
    ts : pandas.DataFrame
        The DataFrame should contain a &#39;values&#39; column and a pd.DatetimeIndex as index, it contains the timeseries with a tidal prediction or water level measurements.
    calc_HWLW345 : boolean, optional
        Whether to also calculate local extremes, first/second low waters and &#39;aggers&#39;. 
        The default is False, in which case only extremes per tidal period are calculated.
        When first/second low waters and aggers are calculated, the local extremes around highwater (eg double highwaters and dips) are filtered out first.
    calc_HWLW345_cleanup1122 : boolean, optional
        Whether to remove HWLWcodes 11 and 22 from DataFrame. The default is True.
    debug : boolean, optional
        Whether to print debug information. The default is False.
    
    Raises
    ------
    Exception
        DESCRIPTION.
    
    Returns
    -------
    data_pd_HWLW : pandas.DataFrame
        The DataFrame contains colums &#39;times&#39;, &#39;values&#39; and &#39;HWLWcode&#39;, it contains the times, values and codes of the timeseries that are extremes.
        1 (high water) and 2 (low water). And if calc_HWLW345=True also 3 (first low water), 4 (agger) and 5 (second low water).

    &#34;&#34;&#34;
    import numpy as np
    import scipy.signal as ssig

    from hatyan.hatyan_core import get_hatyan_freqs
    
    #calculate the amount of steps in a M2 period, based on the most occurring timestep
    M2_period_min = get_hatyan_freqs([&#39;M2&#39;]).loc[&#39;M2&#39;,&#39;period [hr]&#39;]*60
    ts_steps_min_most = np.argmax(np.bincount((ts.index.to_series().diff().iloc[1:].dt.total_seconds()/60).astype(int).values))
    if ts_steps_min_most &gt; 1:
        print(&#39;WARNING: the timestep of the series for which to calculate extremes/HWLW is %i minutes, but 1 minute is recommended&#39;%(ts_steps_min_most))
    M2period_numsteps = M2_period_min/ts_steps_min_most #now based on M2 period (was called ts_poscrossing_moststeps before)
    
    ts = ts.copy()
    ts[&#39;times&#39;] = ts.index
    ts = ts.reset_index(drop=True)
    #create empty HWLW dataframe
    if ts[&#39;values&#39;].isnull().any():
        data_pd_HWLW = ts[~ts[&#39;values&#39;].isnull()]
        print(&#39;WARNING: the provided ts for extreme/HWLW calculation contained NaN values. To avoid unexpected results from scipy.signal.find_peaks(), the %i NaN values were removed from the ts (%.2f%%) before calculating extremes/HWLW.&#39;%(len(ts)-len(data_pd_HWLW), (len(ts)-len(data_pd_HWLW))/len(ts)*100))
    else:
        data_pd_HWLW = ts.copy()
    data_pd_HWLW[&#39;HWLWcode&#39;] = np.nan
    
    if calc_HWLW345:
        #get all local extremes, including aggers and second high waters (1/2/11/22)
        LWid_all, LWid_all_properties = ssig.find_peaks(-ts[&#39;values&#39;].values, distance=None, #takes first value of two equal lower values
                                                        prominence=(0.01,None), width=(None,None)) #prominence naar 0.01 om matige aggers uit te sluiten
        HWid_all, HWid_all_properties = ssig.find_peaks(ts[&#39;values&#39;].values, distance=None, #takes first value of two equal peaks
                                                        prominence=(0.01,None), width=(None,None)) #prominence naar 0.01 om matige aggers uit te sluiten
        LWid_all_toindex = ts.index[LWid_all]
        HWid_all_toindex = ts.index[HWid_all]
        data_pd_HWLW.loc[LWid_all_toindex,&#39;HWLWcode&#39;] = 22 #all LW
        data_pd_HWLW.loc[HWid_all_toindex,&#39;HWLWcode&#39;] = 11 #all HW


    #get HWLW (extremes per tidal period)
    LWid_main,LWid_main_properties = ssig.find_peaks(-ts[&#39;values&#39;].values, distance=M2period_numsteps/1.7, #most stations work with factor 1.4. 1.5 results in all LW values for HoekvanHolland for 2000, 1.7 results in all LW values for Rotterdam for 2000 (also for 1999-2002)
                                                     prominence=(0.1,None), width=(None,None)) #prominence van 0.1 om de echte piek te isoleren
    HWid_main,HWid_main_properties = ssig.find_peaks(ts[&#39;values&#39;].values, distance=M2period_numsteps/1.5, #most stations work with factor 1.4. 1.5 value results in all HW values for DenHelder for year 2000 (also for 1999-2002)
                                                     prominence=(0.1,None), width=(None,None)) #prominence van 0.1 om de echte piek te isoleren
    LWid_main_toindex = ts.index[LWid_main]
    HWid_main_toindex = ts.index[HWid_main]
    data_pd_HWLW.loc[LWid_main_toindex,&#39;HWLWcode&#39;] = 2
    data_pd_HWLW.loc[HWid_main_toindex,&#39;HWLWcode&#39;] = 1
    data_pd_HWLW = data_pd_HWLW[-data_pd_HWLW[&#39;HWLWcode&#39;].isnull()] #minus: not nan
    
    #convert HWLWcode column to integers
    data_pd_HWLW[&#39;HWLWcode&#39;] = data_pd_HWLW[&#39;HWLWcode&#39;].astype(int)
    
    if debug: #debug statistics
        prop_list = [&#39;prominences&#39;,&#39;widths&#39;]
        for prop in prop_list:
            data_pd_HWLW.loc[data_pd_HWLW[&#39;HWLWcode&#39;]==2,prop] = LWid_main_properties[prop]
        print(&#39;LW values:\n%s\n&#39;%(data_pd_HWLW[data_pd_HWLW[&#39;HWLWcode&#39;]==2]))
        
        for prop in prop_list:
            data_pd_HWLW.loc[data_pd_HWLW[&#39;HWLWcode&#39;]==1,prop] = HWid_main_properties[prop]
        print(&#39;HW values:\n%s\n&#39;%(data_pd_HWLW[data_pd_HWLW[&#39;HWLWcode&#39;]==1]))
        
        if 22 in data_pd_HWLW[&#39;HWLWcode&#39;].values:
            LW_local_bool = ~np.in1d(LWid_all, LWid_main)
            for prop in prop_list:
                data_pd_HWLW.loc[data_pd_HWLW[&#39;HWLWcode&#39;]==22,prop] = LWid_all_properties[prop][LW_local_bool]
            print(&#39;LW_local values:\n%s\n&#39;%(data_pd_HWLW[data_pd_HWLW[&#39;HWLWcode&#39;]==22]))
            
        if 11 in data_pd_HWLW[&#39;HWLWcode&#39;].values:
            HW_local_bool = ~np.in1d(HWid_all, HWid_main)
            for prop in prop_list:
                data_pd_HWLW.loc[data_pd_HWLW[&#39;HWLWcode&#39;]==11,prop] = HWid_all_properties[prop][HW_local_bool]
            print(&#39;HW_local values:\n%s\n&#39;%(data_pd_HWLW[data_pd_HWLW[&#39;HWLWcode&#39;]==11]))
        
    if not (data_pd_HWLW[&#39;HWLWcode&#39;].iloc[[0,-1]] == 1).all():
        print(&#39;WARNING: ts does not start and end with HW (HWLWcode=1), HW very close to start/end of ts might be missed because of too low prominence and 1stLW/agger/2ndLW is not calculated if not between two HWs (if calc_HWLW345=True). Check if begin/end HWLWcodes are correct and extend ts if necessary:\n%s&#39;%(data_pd_HWLW))

    if calc_HWLW345: #recalculate local LW/HWs between two main HWs to firstLW/agger/secondLW
        print(&#39;calculating 1stLW/agger/2ndLW for all tidalperiods...&#39;)
        for iTide, dummy in enumerate(HWid_main[:-1]):
            data_pd_HWLW_1tide = data_pd_HWLW.loc[HWid_main[iTide]:HWid_main[iTide+1],:]
            
            if 0: #remove only HW (not local values around HW)
                data_pd_HWLW_1tide_noHWs = data_pd_HWLW_1tide.iloc[1:-1]
            else: #filter local extremes around HW (only interested in aggers, so LW), this is necessary for eg DENHDR and PETTZD, otherwise second HW is seen as first LW
                data_pd_HWLW_1tide_minHW = data_pd_HWLW_1tide.loc[data_pd_HWLW_1tide[&#39;HWLWcode&#39;]==1,[&#39;values&#39;]].min()[0]
                data_pd_HWLW_1tide_min = data_pd_HWLW_1tide[&#39;values&#39;].min()
                data_pd_HWLW_1tide_mid = np.mean([data_pd_HWLW_1tide_minHW,data_pd_HWLW_1tide_min])
                bool_LWs = data_pd_HWLW_1tide[&#39;values&#39;]&lt;data_pd_HWLW_1tide_mid
                data_pd_HWLW_1tide_noHWs = data_pd_HWLW_1tide[bool_LWs]
            
            if len(data_pd_HWLW_1tide_noHWs) &gt; 3: #(attempt to) reduce to three values between two HWs
                print(&#39;WARNING: more than 3 values between HWs, removing part of them&#39;)
                #print(data_pd_HWLW_1tide)
                agger35_prim = data_pd_HWLW_1tide_noHWs[data_pd_HWLW_1tide_noHWs[&#39;HWLWcode&#39;]==2]
                if len(agger35_prim)&gt;1:
                    raise Exception(&#39;should be only one HWLWcode=2 per tide period&#39;)
                agger35_prim_loc = agger35_prim.index[0]
                agger35_sec_loc = data_pd_HWLW_1tide_noHWs.loc[data_pd_HWLW_1tide_noHWs[&#39;HWLWcode&#39;]==22,&#39;values&#39;].idxmin()
                agger35_loc = np.sort([agger35_prim_loc,agger35_sec_loc])
                data_pd_HWLW_1tide_noHWs = data_pd_HWLW_1tide_noHWs.loc[agger35_loc.min():agger35_loc.max(),:]
                agger4_loc = data_pd_HWLW_1tide_noHWs[&#39;values&#39;].idxmax()
                data_pd_HWLW_1tide_noHWs = data_pd_HWLW_1tide_noHWs.loc[[agger35_loc.min(),agger4_loc,agger35_loc.max()],:]
            
            if len(data_pd_HWLW_1tide_noHWs) == 1: #primary low water already has code 2
                if data_pd_HWLW_1tide_noHWs[&#39;HWLWcode&#39;].iloc[0] != 2:
                    raise Exception(&#39;Only 1 LW value but does not have HWLWcode 2&#39;)
            elif len(data_pd_HWLW_1tide_noHWs) == 3:
                if not data_pd_HWLW_1tide_noHWs[&#39;values&#39;].argmax() == 1:
                    raise Exception(&#39;3 values between two HW values, but center one is not the largest:\n%s&#39;%(data_pd_HWLW_1tide_noHWs))
                agger345_loc = data_pd_HWLW_1tide_noHWs.index
                if not (data_pd_HWLW.loc[agger345_loc[0],&#39;HWLWcode&#39;] in [2,22] and data_pd_HWLW.loc[agger345_loc[1],&#39;HWLWcode&#39;] in [11] and data_pd_HWLW.loc[agger345_loc[2],&#39;HWLWcode&#39;] in [2,22]):
                    raise Exception(&#39;3 values between two HW values, but do not correspond to LW/agger/LW:\n%s&#39;%(data_pd_HWLW_1tide_noHWs))
                data_pd_HWLW.loc[agger345_loc,&#39;HWLWcode&#39;] = [3,4,5]
            else:
                raise Exception(&#39;unexpected number of values between two HWs (0, 2 or more than 3):\n%s&#39;%(data_pd_HWLW_1tide_noHWs))
                
        #remove remaining 11 and 22 values from array
        if calc_HWLW345_cleanup1122:
            data_pd_HWLW = data_pd_HWLW.drop(data_pd_HWLW[data_pd_HWLW[&#39;HWLWcode&#39;]==11].index)
            data_pd_HWLW = data_pd_HWLW.drop(data_pd_HWLW[data_pd_HWLW[&#39;HWLWcode&#39;]==22].index)
        print(&#39;finished calculating 1stLW/agger/2ndLW for all tidalperiods&#39;)
    #return to normal time-index
    data_pd_HWLW = data_pd_HWLW.set_index(&#39;times&#39;)
    return data_pd_HWLW







def calc_HWLWnumbering(ts_ext, station=None, corr_tideperiods=None):
    &#34;&#34;&#34;
    For calculation of the extremes numbering, w.r.t. the first high water at Cadzand in 2000 (occurred on 1-1-2000 at approximately 9:45). 
    The number of every high and low water is calculated by taking the time difference between itself and the first high water at Cadzand, correcting it with the station phase difference (M2phasediff). 
    Low waters are searched for half an M2 period from the high waters. 
    By adding a search window of half the period of M2 (searchwindow_hr), even strong time variance between consecutive high or low waters should be caputered. 
    
    Parameters
    ----------
    ts_ext : pandas.DataFrame
        The DataFrame should contain a &#39;values&#39; and &#39;HWLWcode&#39; column and a pd.DatetimeIndex as index, it contains the times, values and codes of the timeseries that are extremes.
    station: string, optional
        The station for which the M2 phase difference should be retrieved from data_M2phasediff_perstation.txt.
        This value is the phase difference in degrees of the occurrence of the high water generated by the same tidal wave as the first high water in 2000 at Cadzand (actually difference between M2 phases of stations).
        This value is used to correct the search window of high/low water numbering. The default is None.
    corr_tideperiods : integer, optional
        Test keyword to derive HWLWnumbering with a n*360 degrees offset only, but this does not work properly. The default is None.

    Raises
    ------
    Exception
        DESCRIPTION.

    Returns
    -------
    ts_ext : pandas.DataFrame
        The input DataFrame with the column &#39;HWLWno&#39; added, which contains the numbers of the extremes.

    &#34;&#34;&#34;
    import os
    import pandas as pd
    import numpy as np
    import datetime as dt
    
    from hatyan.hatyan_core import get_hatyan_freqs
    
    M2_period_hr = get_hatyan_freqs([&#39;M2&#39;]).loc[&#39;M2&#39;,&#39;period [hr]&#39;]
    firstHWcadz_fixed = dt.datetime(2000, 1, 1, 9, 45)
    searchwindow_hr = M2_period_hr/2
    
    if not all((ts_ext[&#39;HWLWcode&#39;]==1) | (ts_ext[&#39;HWLWcode&#39;]==2) | (ts_ext[&#39;HWLWcode&#39;]==3) | (ts_ext[&#39;HWLWcode&#39;]==4) | (ts_ext[&#39;HWLWcode&#39;]==5)):
        raise Exception(&#39;calc_HWLWnumbering() not implemented for HWLWcode other than 1,2,3,4,5 (so no HWLWcode 11 or 22 supported), provide extreme timeseries derived with Timeseries.calc_HWLW(calc_HWLW345=False) or Timeseries.calc_HWLW(calc_HWLW345=True, calc_HWLW345_cleanup1122=True)&#39;)
    ts_ext = ts_ext.copy()
    
    HW_bool = ts_ext[&#39;HWLWcode&#39;]==1
    HW_tdiff_cadzdraw = (ts_ext.loc[HW_bool].index.to_series()-firstHWcadz_fixed).dt.total_seconds()/3600
    if station is None:
        HW_tdiff_cadzdraw_M2remainders = (HW_tdiff_cadzdraw)%M2_period_hr
        M2phasediff_hr = (HW_tdiff_cadzdraw_M2remainders).mean()
        M2phasediff_deg = M2phasediff_hr/M2_period_hr*360
        print(&#39;no value or None for argument M2phasediff provided, automatically calculated correction w.r.t. Cadzand is %.2f hours (%.2f degrees)&#39;%(M2phasediff_hr, M2phasediff_deg))
        if corr_tideperiods is not None:
            M2phasediff_deg = M2phasediff_deg+corr_tideperiods
            M2phasediff_hr = M2phasediff_deg/360*M2_period_hr
            print(&#39;additional tideperiod correction provided via corr_tideperiods of %.1f degrees, new correction w.r.t. Cadzand is %.2f hours (%.2f degrees)&#39;%(corr_tideperiods, M2phasediff_hr, M2phasediff_deg))
    else:
        dir_scriptfile = os.path.realpath(__file__) #F9 doesnt work, only F5 (F5 also only method to reload external definition scripts)
        file_M2phasediff = os.path.join(dir_scriptfile,os.pardir,&#39;data_M2phasediff_perstation.txt&#39;)
        stations_M2phasediff = pd.read_csv(file_M2phasediff, names=[&#39;M2phasediff&#39;], comment=&#39;#&#39;, delim_whitespace=True)
        stat_M2phasediff = stations_M2phasediff.loc[station,&#39;M2phasediff&#39;]
        M2phasediff_hr = stat_M2phasediff/360*M2_period_hr
    HW_tdiff_cadzd = HW_tdiff_cadzdraw - M2phasediff_hr + searchwindow_hr
    HW_tdiff_div, HW_tdiff_mod_searchwindow = np.divmod(HW_tdiff_cadzd.values, M2_period_hr)
    HW_tdiff_mod = HW_tdiff_mod_searchwindow - searchwindow_hr
    if not all(np.diff(HW_tdiff_div) &gt; 0):
        raise Exception(&#39;tidal wave numbering: HW numbers not always increasing&#39;)
    if not all(np.abs(HW_tdiff_mod)&lt;searchwindow_hr):
        raise Exception(&#39;tidal wave numbering: not all HW fall into hardcoded search window&#39;)
    ts_ext.loc[HW_bool,&#39;HWLWno&#39;] = HW_tdiff_div
    
    for LWcode_2345 in [2,3,4,5]:
        LW_bool = ts_ext[&#39;HWLWcode&#39;]==LWcode_2345
        LW_tdiff_cadzdraw = (ts_ext.loc[LW_bool].index.to_series()-firstHWcadz_fixed).dt.total_seconds()/3600
        LW_tdiff_cadzd = LW_tdiff_cadzdraw - M2phasediff_hr + searchwindow_hr - M2_period_hr/2
        LW_tdiff_div, LW_tdiff_mod_searchwindow = np.divmod(LW_tdiff_cadzd.values, M2_period_hr)
        LW_tdiff_mod = LW_tdiff_mod_searchwindow - searchwindow_hr
        if not all(np.diff(LW_tdiff_div) &gt; 0):
            raise Exception(&#39;tidal wave numbering: LW numbers not always increasing&#39;)
        if not all(np.abs(LW_tdiff_mod)&lt;searchwindow_hr):
            raise Exception(&#39;tidal wave numbering: not all LW fall into defined search window&#39;)
        ts_ext.loc[LW_bool,&#39;HWLWno&#39;] = LW_tdiff_div
    
    #check if LW is after HW
    ts_ext_checkfirst = ts_ext[ts_ext[&#39;HWLWno&#39;]==np.min(HW_tdiff_div)]
    tdiff_firstHWLW = (ts_ext_checkfirst.index.to_series().diff().dt.total_seconds()/3600).values[1]
    if (tdiff_firstHWLW&lt;0) or (tdiff_firstHWLW&gt;M2_period_hr):
        raise Exception(&#39;tidal wave numbering: first LW does not match first HW&#39;)
    
    ts_ext[&#39;HWLWno&#39;] = ts_ext[&#39;HWLWno&#39;].astype(int)
    
    return ts_ext






def timeseries_fft(ts_residue, prominence=10**3, plot_fft=True):
    import matplotlib.pyplot as plt
    import numpy as np
    from scipy.fft import fft, fftfreq
    import scipy.signal as ssig
    from hatyan.hatyan_core import get_hatyan_freqs
    
    print(&#39;analyzing timeseries with fft and fftfreq&#39;)
    
    y = ts_residue[&#39;values&#39;].values
    N = len(y)
    T = np.unique((ts_residue.index[1:]-ts_residue.index[:-1])).astype(float)/1e9/3600 #timestep in hours.
    if len(T)!=1:
        raise Exception(&#39;timestep of supplied timeseries should be constant for fourier analysis&#39;)
    yf = fft(y)
    power = np.abs(yf)
    freq = fftfreq(N, T[0])
    peaks = ssig.find_peaks(power[freq &gt;=0], prominence=prominence)[0]
    peak_freq =  freq[peaks]
    peak_power = power[peaks]
    
    if plot_fft:
        fig,ax = plt.subplots()
        ax.plot(freq[:N//2], power[:N//2])
        ax.plot(peak_freq, peak_power, &#39;ro&#39;)
        ax.grid()
        ax.set_xlim(0,0.5)
    
    hatyan_freqs = get_hatyan_freqs(const_list=&#39;all&#39;)[[&#39;freq&#39;]]
    const_match = []
    const_closest = []
    for peak_freq_one in peak_freq:
        hatyan_freqs_match = hatyan_freqs[np.abs(hatyan_freqs[&#39;freq&#39;]-peak_freq_one)&lt;4e-5]
        #print(peak_freq_one)
        #print(hatyan_freqs_match)
        hatyan_freqs_match_list = [x for x in hatyan_freqs_match.index if &#39;_IHO&#39; not in x]
        const_match = const_match+hatyan_freqs_match_list
        hatyan_freqs_closest = hatyan_freqs.iloc[np.argmin(np.abs(hatyan_freqs-peak_freq_one)),:]
        const_closest.append(hatyan_freqs_closest.name)
    hatyan_freqs_matches = get_hatyan_freqs(const_list=const_match)[[&#39;freq&#39;,&#39;period [hr]&#39;]]
    hatyan_freqs_suggestions = get_hatyan_freqs(const_list=const_closest)[[&#39;freq&#39;,&#39;period [hr]&#39;]]
    hatyan_freqs_suggestions[&#39;peak_freq&#39;] = peak_freq
    hatyan_freqs_suggestions[&#39;peak_power&#39;] = peak_power
    print(&#39;dominant freqs from fft:\n%s&#39;%(peak_freq))
    print(&#39;suggested constituents+freqs from hatyan:\n%s&#39;%(hatyan_freqs_suggestions))
    
    return peak_freq, hatyan_freqs_suggestions, hatyan_freqs_matches





    
def plot_timeseries(ts, ts_validation=None, ts_ext=None, ts_ext_validation=None):
    &#34;&#34;&#34;
    Creates a plot with the provided timeseries

    Parameters
    ----------
    ts : pandas.DataFrame
        The DataFrame should contain a &#39;values&#39; column and a pd.DatetimeIndex as index, it contains the timeseries.
    ts_validation : pandas.DataFrame, optional
        The DataFrame should contain a &#39;values&#39; column and a pd.DatetimeIndex as index, it contains the timeseries. The default is None.
    ts_ext : pandas.DataFrame, optional
        The DataFrame should contain a &#39;values&#39; and &#39;HWLW_code&#39; column and a pd.DatetimeIndex as index, it contains the times, values and codes of the timeseries that are extremes. The default is None.
    ts_ext_validation : pandas.DataFrame, optional
        The DataFrame should contain a &#39;values&#39; and &#39;HWLW_code&#39; column and a pd.DatetimeIndex as index, it contains the times, values and codes of the timeseries that are extremes. The default is None.

    Returns
    -------
    fig : matplotlib.figure.Figure
        The generated figure handle, with which the figure can be adapted and saved.
    axs : (tuple of) matplotlib.axes._subplots.AxesSubplot
        The generated axis handle, whith which the figure can be adapted.

    &#34;&#34;&#34;
    
    import numpy as np
    import matplotlib.pyplot as plt
        
    size_figure = (15,9)
    size_line_ts = 0.7
    size_marker_ts = 1
    figure_ylim_ts = [-3,3]
    figure_ylim_tsdiff = [-0.02,0.02]
    
    if ts_validation is not None:
        times_predval_ext = [min(min(ts_validation.index),min(ts.index)), max(max(ts_validation.index),max(ts.index))]

    else:
        times_predval_ext = [min(ts.index), max(ts.index)]    

    fig, (ax1, ax2) = plt.subplots(2,1,figsize=size_figure, sharex=True, gridspec_kw={&#39;height_ratios&#39;:[2,1]})
    
    ax1.set_title(&#39;hatyan timeseries&#39;)
    ax1.plot(ts.index, ts[&#39;values&#39;],&#39;o-&#39;,linewidth=size_line_ts,markersize=size_marker_ts, label=&#39;ts&#39;)
    if ts_validation is not None:
        #overlap between timeseries for difference plots
        times_id_validationinpred = np.where(ts_validation.index.isin(ts.index))[0]
        times_id_predinvalidation = np.where(ts.index.isin(ts_validation.index))[0]
        ax1.plot(ts_validation.index, ts_validation[&#39;values&#39;],&#39;o-&#39;,linewidth=size_line_ts,markersize=size_marker_ts, label=&#39;ts_validation&#39;, alpha=0.7)
        ax1.plot(ts.index[times_id_predinvalidation], ts[&#39;values&#39;].iloc[times_id_predinvalidation].values-ts_validation[&#39;values&#39;].iloc[times_id_validationinpred].values,&#39;go-&#39;,linewidth=size_line_ts,markersize=size_marker_ts, label=&#39;difference&#39;, alpha=0.7)
    ax1.plot(times_predval_ext,[0,0],&#39;-k&#39;,linewidth=size_line_ts)
    ts_mean = np.mean(ts[&#39;values&#39;])
    ax1.plot(ts.index[[0,-1]],[ts_mean,ts_mean],&#39;-r&#39;,linewidth=size_line_ts,label=&#39;mean of ts&#39;)
    if ts_ext is not None:
        HWLW_codesnames = {1:&#39;HW (1)&#39;,
                           2:&#39;LW (2)&#39;,
                           3:&#39;LW1 (3)&#39;,
                           4:&#39;topagger (4)&#39;,
                           5:&#39;LW2 (5)&#39;,
                           11:&#39;HW_local (11)&#39;,
                           22:&#39;LW_local (22)&#39;}
        for HWLW_code in HWLW_codesnames.keys():
            iExt = ts_ext[&#39;HWLWcode&#39;]==HWLW_code
            if iExt.any():
                HWLW_name = HWLW_codesnames[HWLW_code]
                HWLW_markersize=10
                if HWLW_code in [4,11,22]:
                    HWLW_markersize=5
                ax1.plot(ts_ext.index[iExt],ts_ext[&#39;values&#39;][iExt],&#39;x&#39;,markersize=HWLW_markersize,label=HWLW_name)
    if ts_ext_validation is not None:
        vali_codes = [1,2,3,4,5]
        vali_codenames = [&#39;vali_HW&#39;,&#39;vali_LW&#39;,&#39;vali_LW1&#39;,&#39;vali_topagger&#39;,&#39;vali_LW2&#39;]
        for vali_code, vali_codename in zip(vali_codes,vali_codenames):
            vali_code_ids = ts_ext_validation[&#39;HWLWcode&#39;].values==vali_code
            if any(vali_code_ids): #only plot vali_code in legend if present in HWLW_timeseries
                ax1.plot(ts_ext_validation.index[vali_code_ids],ts_ext_validation[&#39;values&#39;][vali_code_ids],&#39;1&#39;,markersize=10,label=vali_codename)
        #print HWLW statistics
        try:
            plot_HWLW_validatestats(ts_ext=ts_ext, ts_ext_validation=ts_ext_validation, create_plot=False)        
        except:
            print(&#39;WARNING: plot_HWLW_validatestats() failed, probably due to missing HWLWno where autocalculation failed. Consider adding HWLWno to ts_ext and ts_ext_validation with calc_HWLWnumbering() before plotting.&#39;)
    ax1.set_ylim(figure_ylim_ts)
    ax2.set_xlabel(&#39;Time&#39;)
    ax1.set_ylabel(&#39;waterlevel [m]&#39;)
    ax1.legend(loc=&#39;lower right&#39;)
    ax1.grid()
    if ts_validation is not None:
        ax2.plot(ts.index[times_id_predinvalidation], ts[&#39;values&#39;].iloc[times_id_predinvalidation].values-ts_validation[&#39;values&#39;].iloc[times_id_validationinpred].values,&#39;go-&#39;,linewidth=size_line_ts,markersize=size_marker_ts, label=&#39;difference&#39;)
    ax2.plot(times_predval_ext,[0,0],&#39;-k&#39;,linewidth=size_line_ts)
    ax2.set_ylim(figure_ylim_tsdiff)
    rmse = np.nan
    if ts_validation is not None:
        overlapdiff = ts[&#39;values&#39;].iloc[times_id_predinvalidation].values-ts_validation[&#39;values&#39;].iloc[times_id_validationinpred].values
        if len(overlapdiff) != 0:
            rmse = np.sqrt(np.nanmean(overlapdiff ** 2))
    ax2.set_ylabel(&#39;timeseries difference [m], RMSE = %.5f&#39;%(rmse))
    ax2.legend(loc=&#39;lower right&#39;)
    ax2.grid()
    fig.tight_layout()
    
    axs = (ax1,ax2)
    return fig, axs


    


def plot_HWLW_validatestats(ts_ext, ts_ext_validation, create_plot=True):
    &#34;&#34;&#34;
    This definition calculates (and plots and prints) some statistics when comparing extreme values.
    This is done by calculating the extreme number (sort of relative to Cadzand 1jan2000, but see &#39;warning&#39;) and subtracting the ts_ext and ts_ext_validation dataframes based on these numbers (and HWLWcode).
    It will only result in values for the overlapping extremes, other values will be NaN and are not considered for the statistics.
    Warning: the calculated extreme numbers in this definition are not corrected for the real phase difference with the M2phasediff argument, the calculated extreme are fine for internal use (to match corresponding extremes) but the absolute number might be incorrect.

    Parameters
    ----------
    ts_ext : pandas.DataFrame
        The DataFrame should contain a &#39;values&#39; and &#39;HWLW_code&#39; column and a pd.DatetimeIndex as index, it contains the times, values and codes of the timeseries that are extremes.
    ts_ext_validation : pandas.DataFrame
        The DataFrame should contain a &#39;values&#39; and &#39;HWLW_code&#39; column and a pd.DatetimeIndex as index, values and codes of the timeseries that are extremes.
    create_plot : boolean, optional
        Whether to plot the time/value differences or only print the statistics. The default is True.

    Returns
    -------
    fig : matplotlib.figure.Figure
        The generated figure handle, with which the figure can be adapted and saved.
    axs : (tuple of) matplotlib.axes._subplots.AxesSubplot
        The generated axis handle, whith which the figure can be adapted.

    &#34;&#34;&#34;
    import numpy as np
    import matplotlib.pyplot as plt
    
    print(&#39;Calculating comparison statistics for extremes&#39;)
    if not &#39;HWLWno&#39; in ts_ext.columns or not &#39;HWLWno&#39; in ts_ext_validation.columns:
        print(&#39;HWLWno is not present in ts_ext or ts_ext_validation, trying to automatically derive it without M2phasediff argument (this might fail)&#39;)
        try:
            ts_ext_nrs = calc_HWLWnumbering(ts_ext=ts_ext)
            ts_ext_validation_nrs = calc_HWLWnumbering(ts_ext=ts_ext_validation)
        except:
            raise Exception(&#39;ERROR: deriving HWLWno failed, so HWLW statistics cannot be calculated. Add HWLWno with calc_HWLWnumbering() before calling plot_HWLW_validatestats().&#39;)
    else:
        ts_ext_nrs = ts_ext.copy()
        ts_ext_validation_nrs = ts_ext_validation.copy()

    #set HWLWcode and HWLWno as index, to make easy subtraction possible
    ts_ext_nrs[&#39;times&#39;] = ts_ext_nrs.index
    ts_ext_nrs = ts_ext_nrs.set_index([&#39;HWLWcode&#39;,&#39;HWLWno&#39;],drop=False)
    ts_ext_validation_nrs[&#39;times&#39;] = ts_ext_validation_nrs.index
    ts_ext_validation_nrs = ts_ext_validation_nrs.set_index([&#39;HWLWcode&#39;,&#39;HWLWno&#39;],drop=False)
    HWLW_diff = ts_ext_nrs.sub(ts_ext_validation_nrs)
    
    tdiff_minutes = HWLW_diff[&#39;times&#39;].dt.total_seconds()/60
    vdiff_cm = HWLW_diff[&#39;values&#39;]*100
    print(&#39;Time differences [minutes]&#39;)
    print(&#39;    RMSE: %.2f&#39;%(np.sqrt(np.mean(tdiff_minutes**2))))
    print(&#39;    std: %.2f&#39;%(tdiff_minutes.std()))
    print(&#39;    abs max: %.2f&#39;%(tdiff_minutes.abs().max()))
    print(&#39;    abs mean: %.2f&#39;%(tdiff_minutes.abs().mean()))
    print(&#39;    #NaN: %i of %i&#39;%(tdiff_minutes.isnull().sum(),len(vdiff_cm)))
    print(&#39;Value differences [cm]&#39;)
    print(&#39;    RMSE: %.2f&#39;%(np.sqrt(np.mean(vdiff_cm**2))))
    print(&#39;    std: %.2f&#39;%(vdiff_cm.std()))
    print(&#39;    abs max: %.2f&#39;%(vdiff_cm.abs().max()))
    print(&#39;    abs mean: %.2f&#39;%(vdiff_cm.abs().mean()))
    print(&#39;    #NaN: %i of %i&#39;%(vdiff_cm.isnull().sum(),len(vdiff_cm)))
    
    if create_plot:
        fig, ax1 = plt.subplots()
        ax1.plot(HWLW_diff.loc[1,&#39;times&#39;].dt.total_seconds()/60,HWLW_diff.loc[1,&#39;values&#39;]*100,&#39;+&#39;,label=&#39;HWdiff&#39;)
        ax1.plot(HWLW_diff.loc[2,&#39;times&#39;].dt.total_seconds()/60,HWLW_diff.loc[2,&#39;values&#39;]*100,&#39;.&#39;,label=&#39;LWdiff&#39;)
        ax1.set_xlabel(&#39;Time difference [minutes]&#39;)
        ax1.set_ylabel(&#39;Value difference [cm]&#39;)
        ax1.legend(loc=1)
        ax1.grid()
    
        axs = (ax1)
        return fig, axs







def write_tsnetcdf(ts, station, vertref, filename, ts_ext=None, tzone_hr=1):
    &#34;&#34;&#34;
    Writes the timeseries to a netCDF file

    Parameters
    ----------
    ts : pandas.DataFrame
        The DataFrame should contain a &#39;values&#39; column and a pd.DatetimeIndex as index, it contains the timeseries.
    station : str
        DESCRIPTION.
    vertref : str
        DESCRIPTION.
    filename : str
        The filename of the netCDF file that will be written.
    ts_ext : pandas.DataFrame, optional
        The DataFrame should contain a &#39;values&#39; and &#39;HWLW_code&#39; column and a pd.DatetimeIndex as index, it contains the times, values and codes of the timeseries that are extremes. The default is None.
    tzone_hr : int, optional
        The timezone (GMT+tzone_hr) that applies to the data. The default is 1 (MET).

    Returns
    -------
    None.

    &#34;&#34;&#34;

    #import os
    import datetime as dt
    from netCDF4 import Dataset, date2num, stringtoarr#, num2date
    import hatyan
    version_no = hatyan.__version__
    
    
    times_all = ts.index
    timeseries = ts[&#39;values&#39;]
    times_stepmin = (ts.index[1]-ts.index[0]).total_seconds()/60
    dt_analysistime = dt.datetime.now()
    data_nc = Dataset(filename, &#39;w&#39;, format=&#34;NETCDF3_CLASSIC&#34;)
    attr_dict = {&#39;title&#39;: &#39;tidal prediction for %s to %s&#39;%(times_all[0].strftime(&#39;%Y-%m-%d %H:%M:%S&#39;), times_all[-1].strftime(&#39;%Y-%m-%d %H:%M:%S&#39;)),
                 &#39;institution&#39;: &#39;Rijkswaterstaat&#39;,
                 &#39;source&#39;: &#39;hatyan-%s tidal analysis program of Rijkswaterstaat&#39;%(version_no),
                 &#39;timestep_min&#39;: times_stepmin}
    for ncattrname in list(attr_dict.keys()):
        data_nc.setncattr(ncattrname, attr_dict[ncattrname])

    ncvarlist = list(data_nc.variables.keys())
    ncdimlist = list(data_nc.dimensions.keys())
    statname_len = 64
    
    if &#39;stations&#39; not in ncdimlist:
        data_nc.createDimension(&#39;stations&#39;,None)
    if &#39;statname_len&#39; not in ncdimlist:
        data_nc.createDimension(&#39;statname_len&#39;,statname_len)
    if &#39;time&#39; not in ncdimlist:
        data_nc.createDimension(&#39;time&#39;,len(times_all.tolist()))
    if &#39;analysis_time&#39; not in ncdimlist:
        data_nc.createDimension(&#39;analysis_time&#39;,1)

    refdate_tz = dt.datetime(1900,1,1,tzinfo=dt.timezone(dt.timedelta(hours=tzone_hr)))
    dict_statattr = {&#39;cf_role&#39;: &#39;timeseries_id&#39;}
    dict_anatimattr = {&#39;units&#39;: &#39;minutes since %s&#39;%(refdate_tz.strftime(&#39;%Y-%m-%d %H:%M:%S %z&#39;)), &#39;standard_name&#39;:&#39;forecast_reference_time&#39;, &#39;long_name&#39;:&#39;forecast_reference_time&#39;}
    dict_timattr = {&#39;units&#39;: &#39;minutes since %s&#39;%(refdate_tz.strftime(&#39;%Y-%m-%d %H:%M:%S %z&#39;))}
    dict_wlattr = {&#39;units&#39;:&#39;m&#39;, &#39;vertical_reference&#39;: vertref, &#39;standard_name&#39;: &#39;sea_surface_height_above_geopotential_datum&#39;, &#39;long_name&#39;: &#39;astronomical prediction of water level above reference level&#39;}
    dict_HWattr = {&#39;units&#39;:&#39;m&#39;, &#39;vertical_reference&#39;: vertref, &#39;standard_name&#39;: &#39;sea_surface_height_above_geopotential_datum&#39;, &#39;long_name&#39;: &#39;astronomical prediction of high water extremes above reference level&#39;}
    dict_LWattr = {&#39;units&#39;:&#39;m&#39;, &#39;vertical_reference&#39;: vertref, &#39;standard_name&#39;: &#39;sea_surface_height_above_geopotential_datum&#39;, &#39;long_name&#39;: &#39;astronomical prediction of low water extremes above reference level&#39;}
    #dict_HWrowsizeattr = {&#39;long_name&#39;:&#39;number of observations for this station&#39;, &#39;sample_dimension&#39;:&#39;obs_raggedHW&#39;}
    if not &#39;stations&#39; in ncvarlist: #create empty variables if not yet present
        nc_newvar = data_nc.createVariable(&#39;stations&#39;,&#39;S1&#39;,(&#39;stations&#39;,&#39;statname_len&#39;,))
        for attrname in list(dict_statattr.keys()):
            nc_newvar.setncattr(attrname, dict_statattr[attrname])
    
    if not &#39;analysis_time&#39; in ncvarlist:
        nc_newvar = data_nc.createVariable(&#39;analysis_time&#39;,&#39;f8&#39;,(&#39;analysis_time&#39;,))
        for attrname in list(dict_anatimattr.keys()):
            nc_newvar.setncattr(attrname, dict_anatimattr[attrname])
        data_nc.variables[&#39;analysis_time&#39;][0] = date2num([dt_analysistime], units=data_nc.variables[&#39;analysis_time&#39;].units)   
    
    #current length is used as index
    nstat = data_nc.variables[&#39;stations&#39;].shape[0]
    #append current data to netcdf files
    data_nc.variables[&#39;stations&#39;][nstat,:] = stringtoarr(station, statname_len, dtype=&#39;S&#39;)
    
    
    #general prediction
    if not &#39;time&#39; in ncvarlist:
        nc_newvar = data_nc.createVariable(&#39;time&#39;,&#39;f8&#39;,(&#39;time&#39;,))
        for attrname in list(dict_timattr.keys()):
            nc_newvar.setncattr(attrname, dict_timattr[attrname])
        #set time contents upon creation of variable, is constant over loop
        data_nc.variables[&#39;time&#39;][:] = date2num(times_all.tolist(),units=data_nc.variables[&#39;time&#39;].units)
    if not &#39;waterlevel_astro&#39; in ncvarlist:
        nc_newvar = data_nc.createVariable(&#39;waterlevel_astro&#39;,&#39;f8&#39;,(&#39;stations&#39;,&#39;time&#39;,))
        for attrname in list(dict_wlattr.keys()):
            nc_newvar.setncattr(attrname, dict_wlattr[attrname])
    data_nc.variables[&#39;waterlevel_astro&#39;][nstat,:] = timeseries
    
    #HWLW prediction
    if ts_ext is not None:
        data_HWLW = ts_ext.copy()
        data_HWLW = data_HWLW.sort_index(axis=0)
        data_HW = data_HWLW[data_HWLW[&#39;HWLWcode&#39;]==1]
        data_LW = data_HWLW[data_HWLW[&#39;HWLWcode&#39;]==2]
        #create empty variables if not yet present

        #HW
        if &#39;time_HW&#39; not in ncdimlist:
            data_nc.createDimension(&#39;time_HW&#39;,len(data_HW))
        if not &#39;time_HW&#39; in ncvarlist:
            nc_newvar = data_nc.createVariable(&#39;time_HW&#39;,&#39;f8&#39;,(&#39;time_HW&#39;,))
            for attrname in list(dict_timattr.keys()):
                nc_newvar.setncattr(attrname, dict_timattr[attrname])
        data_nc.variables[&#39;time_HW&#39;][:] = date2num(data_HW.index.tolist(),units=data_nc.variables[&#39;time_HW&#39;].units)
        if not &#39;waterlevel_astro_HW&#39; in ncvarlist:
            nc_newvar = data_nc.createVariable(&#39;waterlevel_astro_HW&#39;,&#39;f8&#39;,(&#39;stations&#39;,&#39;time_HW&#39;,))
            for attrname in list(dict_HWattr.keys()):
                nc_newvar.setncattr(attrname, dict_HWattr[attrname])
        data_nc.variables[&#39;waterlevel_astro_HW&#39;][nstat,:] = data_HW[&#39;values&#39;]
        
        #LW
        if &#39;time_LW&#39; not in ncdimlist:
            data_nc.createDimension(&#39;time_LW&#39;,len(data_LW))
        if not &#39;time_LW&#39; in ncvarlist:
            nc_newvar = data_nc.createVariable(&#39;time_LW&#39;,&#39;f8&#39;,(&#39;time_LW&#39;,))
            for attrname in list(dict_timattr.keys()):
                nc_newvar.setncattr(attrname, dict_timattr[attrname])
        data_nc.variables[&#39;time_LW&#39;][:] = date2num(data_LW.index.tolist(),units=data_nc.variables[&#39;time_LW&#39;].units)
        if not &#39;waterlevel_astro_LW&#39; in ncvarlist:
            nc_newvar = data_nc.createVariable(&#39;waterlevel_astro_LW&#39;,&#39;f8&#39;,(&#39;stations&#39;,&#39;time_LW&#39;,))
            for attrname in list(dict_LWattr.keys()):
                nc_newvar.setncattr(attrname, dict_LWattr[attrname])
        data_nc.variables[&#39;waterlevel_astro_LW&#39;][nstat,:] = data_LW[&#39;values&#39;]
        
        #HWLW numbering
        if &#39;HWLWno&#39; in ts_ext.columns:
            if not &#39;waterlevel_astro_HW_numbers&#39; in ncvarlist:
                nc_newvar = data_nc.createVariable(&#39;waterlevel_astro_HW_numbers&#39;,&#39;i4&#39;,(&#39;stations&#39;,&#39;time_HW&#39;,))
                #for attrname in list(dict_HWattr.keys()):
                #    nc_newvar.setncattr(attrname, dict_HWattr[attrname])
            data_nc.variables[&#39;waterlevel_astro_HW_numbers&#39;][nstat,:] = data_HW[&#39;HWLWno&#39;]
            if not &#39;waterlevel_astro_LW_numbers&#39; in ncvarlist:
                nc_newvar = data_nc.createVariable(&#39;waterlevel_astro_LW_numbers&#39;,&#39;i4&#39;,(&#39;stations&#39;,&#39;time_LW&#39;,))
                #for attrname in list(dict_LWattr.keys()):
                #    nc_newvar.setncattr(attrname, dict_LWattr[attrname])
            data_nc.variables[&#39;waterlevel_astro_LW_numbers&#39;][nstat,:] = data_LW[&#39;HWLWno&#39;]
            

    else:
        print(&#39;no HWLW prediction written&#39;)

        
    data_nc.close()
       
    






def write_tsdia(ts, station, vertref, filename):
    &#34;&#34;&#34;
    Writes the timeseries to an equidistant dia file

    Parameters
    ----------
    ts : pandas.DataFrame
        The DataFrame should contain a &#39;values&#39; column and a pd.DatetimeIndex as index, it contains the timeseries.
    station : TYPE
        DESCRIPTION.
    vertref : TYPE
        DESCRIPTION.
    filename : TYPE
        DESCRIPTION.

    Raises
    ------
    Exception
        DESCRIPTION.

    Returns
    -------
    None.

    &#34;&#34;&#34;
    import io
    import datetime as dt
    
    if vertref == &#39;NAP&#39;:
        waarnemingssoort = 18
    elif vertref == &#39;MSL&#39;:
        waarnemingssoort = 55
    else:
        raise Exception(&#39;ERROR: currently only vertref=&#34;NAP&#34; and vertref=&#34;MSL&#34; are supported for writing diafiles&#39;)

    ts_times = ts.index
    ts_values = ts[&#39;values&#39;]

    with io.open(filename,&#39;w&#39;, newline=&#39;\n&#39;) as f:
        #f.write(&#39;#### created by Python prototype of HATYAN 2.0 ####\n&#39;)
        f.write(&#39;[IDT;*DIF*;A;CENT;%6s]\n&#39;%(dt.datetime.today().strftime(&#39;%Y%m%d&#39;)))
        f.write(&#39;[W3H]\n&#39;)
        f.write(&#39;WNS;%i\n&#39;%(waarnemingssoort))
        f.write(&#39;PAR;WATHTBRKD;;;\n&#39;) #parameter, gelijk voor waarnemingssoorten 18 en 55
        f.write(&#39;CPM;10\n&#39;) #compartiment, gelijk voor waarnemingssoorten 18 en 55
        f.write(&#39;EHD;I;cm\n&#39;) #eenheid, gelijk voor waarnemingssoorten 18 en 55
        f.write(&#39;HDH;%s\n&#39;%(vertref))
        f.write(&#39;ANI;RIKZITSDHG\n&#39;)
        f.write(&#39;BHI;RIKZITSDHG\n&#39;)
        f.write(&#39;BMI;NVT\n&#39;)
        f.write(&#39;OGI;RIKZMON_WAT\n&#39;)
        f.write(&#39;LOC;%s\n&#39;%(station))
        f.write(&#39;ANA;F012\n&#39;)
        f.write(&#39;BEM;NVT\n&#39;)
        f.write(&#39;BEW;NVT\n&#39;)
        f.write(&#39;VAT;NVT\n&#39;)
        f.write(&#39;TYP;TE\n&#39;)
        f.write(&#39;[TPS]\n&#39;)
        f.write(&#39;STA;%6s;%4s;%6s;%4s;O\n&#39;%(ts_times[0].strftime(&#39;%Y%m%d&#39;),ts_times[0].strftime(&#39;%H%M&#39;),ts_times[-1].strftime(&#39;%Y%m%d&#39;),ts_times[-1].strftime(&#39;%H%M&#39;)))
        f.write(&#39;[RKS]\n&#39;)
        f.write(&#39;TYD;%6s;%4s;%6s;%4s;%i;min\n&#39;%(ts_times[0].strftime(&#39;%Y%m%d&#39;),ts_times[0].strftime(&#39;%H%M&#39;),ts_times[-1].strftime(&#39;%Y%m%d&#39;),ts_times[-1].strftime(&#39;%H%M&#39;), (ts_times[1]-ts_times[0]).total_seconds()/60))
        f.write(&#39;[WRD]\n&#39;)

        linestr = &#39;&#39;
        filelim = len(ts_values)
        for iV, ts_value in enumerate(ts_values):
            blocklength = 720
            linestr_add = &#34;%i/0:&#34;%(ts_value*100)
            if len(linestr+linestr_add)&lt;=120:
                linestr = linestr + linestr_add
                if iV==filelim-1 or iV%blocklength==blocklength-1:
                    f.write(linestr+&#39;\n&#39;)
                    linestr = &#39;&#39;
            else:
                f.write(linestr+&#39;\n&#39;)
                linestr = linestr_add




    

    

def write_tsdia_HWLW(ts_ext, station, vertref, filename):
    &#34;&#34;&#34;
    writes the extremes timeseries to a non-equidistant dia file

    Parameters
    ----------
    ts_ext : pandas.DataFrame
        The DataFrame should contain a &#39;values&#39; and &#39;HWLW_code&#39; column and a pd.DatetimeIndex as index, it contains the times, values and codes of the timeseries that are extremes.
    station : TYPE
        DESCRIPTION.
    vertref : TYPE
        DESCRIPTION.
    filename : TYPE
        DESCRIPTION.

    Raises
    ------
    Exception
        DESCRIPTION.

    Returns
    -------
    None.

    &#34;&#34;&#34;
    import io
    import datetime as dt
    
    if vertref == &#39;NAP&#39;:
        waarnemingssoort = 18
        vertreflong = &#39;T.o.v. Normaal Amsterdams Peil&#39;
        parameter = &#39;GETETBRKD2&#39;
        parameterlong = &#39;Getijextreem berekend&#39;
    elif vertref == &#39;MSL&#39;:
        waarnemingssoort = 55
        vertreflong = &#39;T.o.v. Mean Sea Level&#39;
        parameter = &#39;GETETBRKDMSL2&#39;
        parameterlong = &#39;Getijextreem berekend t.o.v. MSL&#39;
    else:
        raise Exception(&#39;ERROR: currently only vertref=&#34;NAP&#34; and vertref=&#34;MSL&#34; are supported for writing diafiles&#39;)
            
    data_HWLW = ts_ext.copy()
    if 11 in data_HWLW[&#39;HWLWcode&#39;].values or 22 in data_HWLW[&#39;HWLWcode&#39;].values:
        raise Exception(&#39;ERROR: invalid HWLWcodes in provided extreme timeseries (11 and/or 22)&#39;)
    
    with io.open(filename,&#39;w&#39;, newline=&#39;\n&#39;) as f:
        f.write(&#39;[IDT;*DIF*;A;;%6s]\n&#39;%(dt.datetime.today().strftime(&#39;%Y%m%d&#39;)))
        f.write(&#39;[W3H]\n&#39;)
        f.write(&#39;MUX;%s;%s\n&#39;%(parameter, parameterlong))
        f.write(&#39;ANI;RIKZITSDHG;RIKZ - afdeling ZDI te Den Haag\n&#39;)
        f.write(&#39;BHI;RIKZITSDHG;RIKZ - afdeling ZDI te Den Haag\n&#39;)
        f.write(&#39;BMI;NVT;Niet van toepassing\n&#39;)
        f.write(&#39;OGI;RIKZMON_WAT;RIKZ - Landelijke monitoring waterhoogten gegevens\n&#39;)
        f.write(&#39;LOC;%s\n&#39;%(station))
        f.write(&#39;ANA;F012;Waterhoogte astronomisch mbv harmonische analyse\n&#39;) #HW en LW uit 1 min. waterhoogten gefilterd uit 10 min. gem.
        f.write(&#39;BEM;NVT;Niet van toepassing\n&#39;)
        f.write(&#39;BEW;NVT;Niet van toepassing\n&#39;)
        f.write(&#39;VAT;NVT;Niet van toepassing\n&#39;)
        f.write(&#39;TYP;TN\n&#39;)
        f.write(&#39;[MUX]\n&#39;)
        f.write(&#39;MXW;1;15\n&#39;)
        f.write(&#39;MXP;1;GETETCDE;Getijextreem code;J\n&#39;)
        f.write(&#39;MXC;1;10;Oppervlaktewater\n&#39;)
        f.write(&#39;MXE;1;T;DIMSLS\n&#39;)
        f.write(&#39;MXH;1;NVT;Niet van toepassing\n&#39;)
        f.write(&#39;MXO;1;NVT;Niet van toepassing\n&#39;)
        f.write(&#39;MXS;1;NVT\n&#39;)
        f.write(&#39;MXW;2;%i\n&#39;%(waarnemingssoort))
        f.write(&#39;MXP;2;WATHTBRKD;Waterhoogte berekend;J\n&#39;)
        f.write(&#39;MXC;2;10;Oppervlaktewater\n&#39;)
        f.write(&#39;MXE;2;I;cm\n&#39;)
        f.write(&#39;MXH;2;%s;%s\n&#39;%(vertref, vertreflong))
        f.write(&#39;MXO;2;NVT;Niet van toepassing\n&#39;)
        f.write(&#39;MXS;2;NVT\n&#39;)
        f.write(&#39;[TYP]\n&#39;)
        f.write(&#39;TVL;1;1;hoogwater\n&#39;)
        f.write(&#39;TVL;1;2;laagwater\n&#39;)
        f.write(&#39;TVL;1;3;laagwater 1\n&#39;)
        f.write(&#39;TVL;1;4;topagger\n&#39;)
        f.write(&#39;TVL;1;5;laagwater 2\n&#39;)
        f.write(&#39;[RKS]\n&#39;)
        f.write(&#39;TYD;%6s;%4s;%6s;%4s\n&#39;%(data_HWLW.index[0].strftime(&#39;%Y%m%d&#39;),data_HWLW.index[0].strftime(&#39;%H%M&#39;),data_HWLW.index[-1].strftime(&#39;%Y%m%d&#39;),data_HWLW.index[-1].strftime(&#39;%H%M&#39;)))
        f.write(&#39;SYS;CENT\n&#39;)
        f.write(&#39;[TPS]\n&#39;)
        f.write(&#39;STA;%6s;%4s;%6s;%4s;O\n&#39;%(data_HWLW.index[0].strftime(&#39;%Y%m%d&#39;),data_HWLW.index[0].strftime(&#39;%H%M&#39;),data_HWLW.index[-1].strftime(&#39;%Y%m%d&#39;),data_HWLW.index[-1].strftime(&#39;%H%M&#39;)))
        f.write(&#39;[WRD]\n&#39;)

        for index,data_pd_row in data_HWLW.iterrows():
            f.write(&#39;%6s;%4s;%d/0;%d:\n&#39;%(index.strftime(&#39;%Y%m%d&#39;), index.strftime(&#39;%H%M&#39;), data_pd_row[&#39;HWLWcode&#39;], data_pd_row[&#39;values&#39;]*100))
                    





def crop_timeseries(ts, times_ext):
    &#34;&#34;&#34;
    Crops the provided timeseries

    Parameters
    ----------
    ts : pandas.DataFrame
        The DataFrame should contain a &#39;values&#39; column and a pd.DatetimeIndex as index, it contains the timeseries.
    times_ext : TYPE
        DESCRIPTION.

    Raises
    ------
    Exception
        DESCRIPTION.

    Returns
    -------
    ts_pd_out : TYPE
        DESCRIPTION.

    &#34;&#34;&#34;
    ts_pd_in = ts
    
    print(&#39;-&#39;*100)
    print(&#39;cropping timeseries&#39;)
    if not times_ext[0]&lt;times_ext[1]:
        raise Exception(&#39;ERROR: the two times times_ext should be increasing, but they are not: %s.&#39;%(times_ext))
    if (times_ext[0] &lt; ts_pd_in.index[0]) or (times_ext[-1] &gt; ts_pd_in.index[-1]):
        raise Exception(&#39;ERROR: imported timeseries is not available within entire requested period:\nrequested period:    %s to %s\nimported timeseries: %s to %s\nNOTE: if te requested period does not correspond with the one provided in the configfile, try setting analysis_peryear=None&#39;%(times_ext[0],times_ext[-1],ts_pd_in.index.iloc[0],ts_pd_in.index.iloc[-1]))
    
    times_selected_bool = (ts_pd_in.index &gt;= times_ext[0]) &amp; (ts_pd_in.index &lt;= times_ext[-1])
    ts_pd_out = ts_pd_in.loc[times_selected_bool]
    
    check_ts(ts_pd_out)
    return ts_pd_out





def resample_timeseries(ts, timestep_min):
    &#34;&#34;&#34;
    resamples the provided timeseries, only overlapping timesteps are selected, so no interpolation

    Parameters
    ----------
    ts : pandas.DataFrame
        The DataFrame should contain a &#39;values&#39; and &#39;HWLW_code&#39; column and a pd.DatetimeIndex as index, it contains the timeseries to be resampled.
    timestep_min : int
        the amount of minutes with which to resample the timeseries.

    Returns
    -------
    data_pd_resample : pandas.DataFrame with a &#39;values&#39; column and a pd.DatetimeIndex as index
        the resampled timeseries.

    &#34;&#34;&#34;
    
    import pandas as pd
    import numpy as np
    
    print(&#39;-&#39;*100)
    print(&#39;resampling timeseries to %i mintues&#39;%(timestep_min))
    data_pd_resample = pd.DataFrame({},index=pd.date_range(ts.index[0],ts.index[-1],freq=&#39;%dmin&#39;%(timestep_min)))
    data_pd_resample[&#39;values&#39;] = np.nan
    id_allinmeas = ts.index.isin(data_pd_resample.index)
    id_measinall = data_pd_resample.index.isin(ts.index)
    data_pd_resample.loc[id_measinall,&#39;values&#39;] = ts.loc[id_allinmeas,&#39;values&#39;].values
    
    
    check_ts(data_pd_resample)
    return data_pd_resample




def check_ts(ts):
    &#34;&#34;&#34;
    prints several statistics of the provided timeseries

    Parameters
    ----------
    ts : pandas.DataFrame
        The DataFrame should contain a &#39;values&#39; column and a pd.DatetimeIndex as index, it contains the timeseries to be checked.

    Returns
    -------
    print_statement: str
        For printing as a substring of another string.

    &#34;&#34;&#34;
    import numpy as np
    
    timesteps_min_all = ts.index.to_series().diff()[1:].dt.total_seconds()/60
    bool_int = (timesteps_min_all-timesteps_min_all.round(0))&lt;1e-9
    if bool_int.all():
        timesteps_min_all = timesteps_min_all.astype(int)
    else: #in case of non integer minute timesteps (eg seconds)
        timesteps_min_all[bool_int] = timesteps_min_all[bool_int].round(0)
    timesteps_min = set(timesteps_min_all)
    #print(timesteps_min)
    if len(timesteps_min)&lt;=100:
        timesteps_min_print = timesteps_min
    else:
        timesteps_min_print = &#39;too much unique timesteps (&gt;100) to display all of them, %i timesteps ranging from %i to %i minutes&#39;%(len(timesteps_min),np.min(list(timesteps_min)),np.max(list(timesteps_min)))
    if (timesteps_min_all&gt;0).all():
        timesteps_incr_print = &#39;all timesteps are in increasing order and are never equal&#39;
    else:
        timesteps_incr_print = &#39;the times-order of ts is not always increasing (duplicate values or wrong order)&#39;
        
    list_statements = [&#39;timeseries contents:\n%s&#39;%(ts),
                       &#39;timeseries # unique timesteps: %i&#39;%(len(timesteps_min)),
                       &#39;timeseries unique timesteps (minutes):\n%s&#39;%(timesteps_min_print),
                       &#39;timeseries validity: %s&#39;%(timesteps_incr_print),
                       &#39;timeseries length: %i&#39;%(len(ts)),
                       &#39;timeseries # nonan: %i&#39;%(ts[&#39;values&#39;].count()),
                       &#39;timeseries %% nonan: %.1f%%&#39;%(ts[&#39;values&#39;].count()/len(ts)*100),
                       &#39;timeseries # nan: %i&#39;%(len(ts)-ts[&#39;values&#39;].count()),
                       &#39;timeseries %% nan: %.1f%%&#39;%((len(ts)-ts[&#39;values&#39;].count())/len(ts)*100)]
    print_statement = &#39;\n&#39;.join(list_statements)
    print(print_statement)
    
    return print_statement
    
    
    
    
###############################
################# READING FILES
###############################







def get_diablocks_startstopstation(filename):
    &#34;&#34;&#34;
    Gets information about the data blocks present in a dia file

    Parameters
    ----------
    filename : TYPE
        DESCRIPTION.
    station : TYPE
        DESCRIPTION.

    Raises
    ------
    Exception
        DESCRIPTION.

    Returns
    -------
    block_starts : TYPE
        DESCRIPTION.
    data_starts : TYPE
        DESCRIPTION.
    data_ends : TYPE
        DESCRIPTION.
    block_stations : TYPE
        DESCRIPTION.
    block_id : TYPE
        DESCRIPTION.

    &#34;&#34;&#34;
    import pandas as pd
    
    #get list of starts/ends of datasets in diafile
    print(&#39;-&#39;*100)
    print(&#39;reading file: %s&#39;%(filename))
    linenum_colnames = [&#39;block_starts&#39;,&#39;data_starts&#39;,&#39;data_ends&#39;]
    diablocks_pd_startstopstation = pd.DataFrame({},columns=linenum_colnames)
    
    with open(filename, encoding=&#39;latin1&#39;) as f: #&#39;latin1 is nodig om predictie diafile die rechtstreeks uit hatyan komen in te lezen (validatietijdserie met op regel 4 (PAR) ongeldige tekens aan het einde)
        block_id = -1
        for linenum, line in enumerate(f, 1):
            if linenum == 1:
                if not &#39;[IDT;*DIF*;A;&#39; in line:
                    raise Exception(&#39;ERROR: not a valid dia-file, first line should contain &#34;[IDT;*DIF*;A;&#34;&#39;)
            if &#39;[W3H]&#39; in line:
                block_id += 1
                diablocks_pd_startstopstation.loc[block_id,&#39;block_starts&#39;] = linenum
            elif &#39;[WRD]&#39; in line:
                diablocks_pd_startstopstation.loc[block_id,&#39;data_starts&#39;] = linenum
            elif &#39;LOC&#39; in line:
                diablocks_pd_startstopstation.loc[block_id,&#39;station&#39;] = line.rstrip().split(&#39;;&#39;)[1]
    diablocks_pd_startstopstation[&#39;data_ends&#39;] = (diablocks_pd_startstopstation[&#39;block_starts&#39;]-1).tolist()[1:]+[linenum]
    if diablocks_pd_startstopstation.isnull().any().any():
        raise Exception(&#39;ERROR: multiple blocks in diafile, but unequal amount of start/end/datastart/stationnames&#39;)
    
    #convert columns with line numbers to integers
    diablocks_pd_startstopstation[linenum_colnames] = diablocks_pd_startstopstation[linenum_colnames].astype(int)
        
    return diablocks_pd_startstopstation







def get_diablocks(filename):
    import datetime as dt
    import numpy as np
    import pandas as pd
    
    mincontent_equidistant = [&#39;PAR&#39;,&#39;LOC&#39;,&#39;HDH&#39;,&#39;TYD&#39;]
    mincontent_nonequidistant = [&#39;MUX&#39;,&#39;LOC&#39;,&#39;MXH;2&#39;]
    getpossible = mincontent_equidistant+mincontent_nonequidistant
    
    diablocks_pd_startstopstation = get_diablocks_startstopstation(filename)
    diablocks_pd = diablocks_pd_startstopstation.copy()
    for block_id in diablocks_pd.index.tolist():
        data_meta_nrows = diablocks_pd.loc[block_id,&#39;data_starts&#39;] - diablocks_pd.loc[block_id,&#39;block_starts&#39;]
        data_meta_pd = pd.read_csv(filename,skiprows=diablocks_pd.loc[block_id,&#39;block_starts&#39;],nrows=data_meta_nrows,sep=&#39;;&#39;,names=range(7),header=None)
        for get_content_sel in getpossible:
            bool_mincontent = data_meta_pd[0]==get_content_sel
            if bool_mincontent.any(): #if get_content_sel available in diafile
                id_mincontent = np.where(bool_mincontent)[0][0]
                if get_content_sel in [&#39;PAR&#39;,&#39;MUX&#39;]:
                    pardef = data_meta_pd.loc[id_mincontent,0]
                    file_parametername = data_meta_pd.loc[id_mincontent,1]
                    if pardef == &#39;PAR&#39;:
                        valid_parameternames = [&#39;WATHTE&#39;,&#39;WATHTBRKD&#39;]
                    else:
                        valid_parameternames = [&#39;GETETBRKD2&#39;,&#39;GETETBRKDMSL2&#39;,&#39;GETETM2&#39;]
                    if not file_parametername in valid_parameternames:
                        raise Exception(&#39;ERROR: parameter name (%s) should be in %s but is %s&#39;%(pardef, valid_parameternames, file_parametername))
                    diablocks_pd.loc[block_id,&#39;parameter&#39;] = file_parametername
                elif get_content_sel in [&#39;LOC&#39;]:
                    file_station_coord_pd = data_meta_pd.loc[id_mincontent,4:6]
                    if file_station_coord_pd.isnull().any():
                        print(&#39;no coordinate data available in LOC line of dia file&#39;)
                    else:
                        file_station_coord = file_station_coord_pd.tolist()
                        if file_station_coord[0] == &#39;RD&#39;:
                            epsg_in = 28992
                            factor = 100
                        elif file_station_coord[0] == &#39;W84&#39;:
                            print(&#39;WARNING: diafile contains W84(epsg:4326) coordinate, correctness is unsure&#39;)
                            epsg_in = 4326
                            factor = 1000000
                        elif file_station_coord[0] == &#39;E50&#39;:
                            print(&#39;WARNING: diafile contains E50(epsg:4230) coordinate, correctness is unsure&#39;)
                            epsg_in = 4230
                            factor = 1000000
                        else:
                            raise Exception(&#39;unknown coordinate system in diafile&#39;)
                        diablocks_pd.loc[block_id,&#39;x&#39;] = int(file_station_coord[1])/factor
                        diablocks_pd.loc[block_id,&#39;y&#39;] = int(file_station_coord[2])/factor
                        diablocks_pd.loc[block_id,&#39;coordsys&#39;] = file_station_coord[0]
                        diablocks_pd.loc[block_id,&#39;epsg&#39;] = epsg_in
                elif get_content_sel in [&#39;HDH&#39;,&#39;MXH;2&#39;]:
                    if get_content_sel in [&#39;HDH&#39;]:
                        file_vertref = data_meta_pd.loc[id_mincontent,1]
                    else:
                        file_vertref = data_meta_pd.loc[id_mincontent,2]
                    diablocks_pd.loc[block_id,&#39;vertref&#39;] = file_vertref
                    print(&#39;the vertical reference level in the imported file is: %s&#39;%(file_vertref))
                    if not isinstance(file_vertref,str): #in case of nan value
                        raise Exception(&#39;ERROR: the imported file does not have a vertical reference in the metadata&#39;)
                elif get_content_sel in [&#39;TYD&#39;]:
                    datestart = dt.datetime.strptime(data_meta_pd.loc[id_mincontent,1:2].str.cat(), &#34;%Y%m%d%H%M&#34;)
                    datestop = dt.datetime.strptime(data_meta_pd.loc[id_mincontent,3:4].str.cat(), &#34;%Y%m%d%H%M&#34;)
                    timestep_value_raw = data_meta_pd.loc[id_mincontent,5]
                    if isinstance(timestep_value_raw,str): #if equidistant timeseries
                        timestep_value = int(timestep_value_raw)
                        timestep_unit = data_meta_pd.loc[id_mincontent,6]
                        if timestep_unit != &#39;min&#39;:
                            raise Exception(&#39;ERROR: time unit from TYD is in unknown format (not &#34;min&#34;)&#39;)
                    else: #when nan
                        timestep_value = timestep_value_raw
                    diablocks_pd.loc[block_id,&#39;tstart&#39;] = datestart
                    diablocks_pd.loc[block_id,&#39;tstop&#39;] = datestop
                    diablocks_pd.loc[block_id,&#39;timestep_min&#39;] = timestep_value
            
    print_cols = [&#39;block_starts&#39;, &#39;station&#39;, &#39;parameter&#39;, &#39;tstart&#39;, &#39;tstop&#39;]
    print(&#39;blocks in diafile:\n%s&#39;%(diablocks_pd[print_cols]))    
    return diablocks_pd










def convertcoordinates(coordx_in, coordy_in, epsg_in, epsg_out=28992):
    from pyproj import Transformer

    epsg_dict = {&#39;RD&#39;:28992,&#39;W84&#39;:4326,&#39;E50&#39;:4230}
    
    if isinstance(epsg_in,str):
        if not epsg_in in epsg_dict.keys():
            raise Exception(&#39;when providing epsg_in as a string, the options are: %s&#39;%(list(epsg_dict.keys())))
        else:
            epsgcode_in = epsg_dict[epsg_in]
    else:
        epsgcode_in = epsg_in
    
    if isinstance(epsg_out,str):
        if not epsg_out in epsg_dict.keys():
            raise Exception(&#39;when providing epsg_out as a string, the options are: %s&#39;%(list(epsg_dict.keys())))
        else:
            epsgcode_out = epsg_dict[epsg_out]
    else:
        epsgcode_out = epsg_out
        
    transformer = Transformer.from_crs(&#39;epsg:%i&#39;%(epsgcode_in), &#39;epsg:%i&#39;%(epsgcode_out), always_xy=True)
    coordx_out, coordy_out = transformer.transform(coordx_in, coordy_in)
    
    return coordx_out, coordy_out










def readts_dia_nonequidistant(filename, diablocks_pd, block_id):
    import numpy as np
    import pandas as pd

    data_nrows = diablocks_pd.loc[block_id,&#39;data_ends&#39;] - diablocks_pd.loc[block_id,&#39;data_starts&#39;]
    data_pd_HWLW = pd.read_csv(filename,skiprows=diablocks_pd.loc[block_id,&#39;data_starts&#39;],nrows=data_nrows, header=None, names=[&#39;date&#39;,&#39;time&#39;,&#39;HWLWcode/qualitycode&#39;,&#39;valuecm:&#39;], sep=&#39;;&#39;, parse_dates={&#39;times&#39;:[0,1]})
    
    #convert HWLW+quality code to separate columns
    data_pd_HWLWtemp = data_pd_HWLW.loc[:,&#39;HWLWcode/qualitycode&#39;].str.split(&#39;/&#39;, expand=True)
    data_pd_HWLW[&#39;HWLWcode&#39;] = data_pd_HWLWtemp.iloc[:,0].astype(&#39;int&#39;)
    data_pd_HWLW[&#39;qualitycode&#39;] = data_pd_HWLWtemp.iloc[:,1].astype(&#39;int&#39;)
    data_pd_HWLW = data_pd_HWLW.drop(&#39;HWLWcode/qualitycode&#39;,axis=&#39;columns&#39;)

    #convert value from cm to m
    data_pd_HWLW[&#39;values&#39;] = data_pd_HWLW[&#39;valuecm:&#39;].str.strip(&#39;:&#39;).astype(&#39;int&#39;)/100
    data_pd_HWLW = data_pd_HWLW.drop(&#39;valuecm:&#39;,axis=&#39;columns&#39;)
    
    bool_hiaat = data_pd_HWLW[&#39;qualitycode&#39;] == 99
    data_pd_HWLW.loc[bool_hiaat,&#39;values&#39;] = np.nan
    
    data_pd = data_pd_HWLW
    data_pd = data_pd.set_index(&#39;times&#39;)
    
    return data_pd






def readts_dia_equidistant(filename, diablocks_pd_extra, block_id):
    import numpy as np
    import pandas as pd
    
    diablocks_pd = diablocks_pd_extra
    
    datestart = diablocks_pd_extra.loc[block_id,&#39;tstart&#39;]
    datestop = diablocks_pd_extra.loc[block_id,&#39;tstop&#39;]
    timestep_min = diablocks_pd_extra.loc[block_id,&#39;timestep_min&#39;]
    times_fromfile = pd.date_range(start=datestart,end=datestop,freq=&#39;%dmin&#39;%(timestep_min))
    
    #get data for station
    data_nrows = diablocks_pd.loc[block_id,&#39;data_ends&#39;] - diablocks_pd.loc[block_id,&#39;data_starts&#39;]
    data_pd = pd.read_csv(filename,skiprows=diablocks_pd.loc[block_id,&#39;data_starts&#39;],nrows=data_nrows, header=None)
    data_pdser = data_pd[0].str.strip()
    data = data_pdser.str.cat()
    data = data.strip(&#39;:&#39;) #remove first and/or last colon if present
    data = data.split(&#39;:&#39;)
    
    if len(times_fromfile) != len(data):
        raise Exception(&#39;ERROR: times and values ts are not of equal length\nlen(times_fromfile): %d\nlen(data): %d&#39;%(len(times_fromfile),len(data)))
    data_pd = pd.DataFrame({&#39;times&#39;:times_fromfile,&#39;valuecm/qualitycode&#39;:data})
    
    #convert HWLW+quality code to separate columns
    data_pd_temp = data_pd.loc[:,&#39;valuecm/qualitycode&#39;].str.split(&#39;/&#39;, expand=True)
    data_pd[&#39;values&#39;] = data_pd_temp.iloc[:,0].astype(&#39;int&#39;)/100
    data_pd[&#39;qualitycode&#39;] = data_pd_temp.iloc[:,1].astype(&#39;int&#39;)
    data_pd = data_pd.drop(&#39;valuecm/qualitycode&#39;,axis=&#39;columns&#39;)

    bool_hiaat = data_pd[&#39;qualitycode&#39;] == 99
    data_pd.loc[bool_hiaat,&#39;values&#39;] = np.nan
    data_pd = data_pd.set_index(&#39;times&#39;)
    
    return data_pd





def readts_dia(filename, station=None, block_ids=None):
    &#34;&#34;&#34;
    Reads an equidistant or non-equidistant dia file, or a list of dia files. Also works for diafiles containing multiple blocks for one station.

    Parameters
    ----------
    filename : TYPE
        DESCRIPTION.
    station : TYPE
        DESCRIPTION. The default is None.
    block_ids : int, list of int or &#39;allstation&#39;, optional
        DESCRIPTION. The default is None.

    Raises
    ------
    Exception
        DESCRIPTION.

    Returns
    -------
    data_pd : pandas.core.frame.DataFrame
        DataFrame with a &#39;values&#39; column and a pd.DatetimeIndex as index in case of an equidistant file, or more columns in case of a non-equidistant file.

    &#34;&#34;&#34;
 

    import pandas as pd
    import numpy as np
    
    if type(filename) is list:
        filename_list = filename
        data_pd_all = pd.DataFrame()
        for iF, filename_one in enumerate(filename_list):
            data_pd_one = readts_dia(filename=filename_one, station=station) #call itself with one file from list
            #append to allyears dataset
            data_pd_all = data_pd_all.append(data_pd_one, ignore_index=False)
        #check overlapping timesteps
        if len(data_pd_all) != len(data_pd_all.index.unique()):
            raise Exception(&#39;ERROR: merged datasets have duplicate/overlapping timesteps, clean up your input data or provide one file instead of a list&#39;)
        data_pd = data_pd_all

    else:
        diablocks_pd = get_diablocks(filename)
        str_getdiablockspd = &#39;A summary of the available blocks is printed above, obtain a full DataFrame of available diablocks with &#34;diablocks_pd=Timeseries.get_diablocks(filename)&#34;&#39;
        #get equidistant timeseries from metadata
        if block_ids is None or block_ids==&#39;allstation&#39;:
            if station is None:
                raise Exception(&#39;ERROR: if block_ids argument is not provided (or None) or is &#34;allstation&#34;, station argument should be provided.&#39;)
            bool_station = diablocks_pd[&#39;station&#39;]==station
            ids_station = diablocks_pd[bool_station].index.tolist()
            if len(ids_station)&lt;1:
                raise Exception(&#39;ERROR: no data block with requested station (%s) present in dia file. %s&#39;%(station, str_getdiablockspd))
            elif len(ids_station)&gt;1 and block_ids is None:
                    raise Exception(&#39;ERROR: more than one data block with requested station (%s) present in dia file. Provide block_ids argument to readts_dia() (int, list of int or &#34;allstation&#34;). %s&#39;%(station, str_getdiablockspd))
            else: #exactly one occurrence or block_ids is provided
                block_ids = ids_station
        
        elif isinstance(block_ids,int):
            block_ids = [block_ids]
        elif isinstance(block_ids,list):
            pass #this is a valid input type
        else:
            raise Exception(&#39;ERROR: invalid type for block_ids (should be int, list of int or &#34;allstation&#34;)&#39;)
        
        #check validity of blockids of type listlist
        if not all(isinstance(x, int) for x in block_ids):
            raise Exception(&#39;ERROR: invalid type in block_ids list, should all be of type int&#39;)
        if np.max(block_ids)&gt;len(diablocks_pd)-1:
            raise Exception(&#39;ERROR: invalid values in block_ids list, possible are %s&#39;%(diablocks_pd.index.tolist()))
        if np.min(block_ids)&lt;0:
            raise Exception(&#39;ERROR: values in block_ids list should all be positive&#39;)
            
        if station is not None:
            if not isinstance(station,str):
                raise Exception(&#39;ERROR: station argument should be of type string&#39;)
            bool_samestation = diablocks_pd.loc[block_ids,&#39;station&#39;]==station
            if not bool_samestation.all():
                raise Exception(&#39;ERROR: both the arguments station and block_ids are provided, but at least one of the requested block_ids corresponds to a different station. %s&#39;%(str_getdiablockspd))
            
        data_pd_allblocks = pd.DataFrame()
        for block_id in block_ids:
            if np.isnan(diablocks_pd.loc[block_id,&#39;timestep_min&#39;]): #non-equidistant
                data_pd_oneblock = readts_dia_nonequidistant(filename, diablocks_pd, block_id)
            else: #equidistant
                data_pd_oneblock = readts_dia_equidistant(filename, diablocks_pd, block_id)
            check_ts(data_pd_oneblock)
            data_pd_allblocks = data_pd_allblocks.append(data_pd_oneblock, ignore_index=False)
        data_pd = data_pd_allblocks

    #sort values on time
    data_pd = data_pd.sort_index(axis=0)
    
    check_ts(data_pd)
    return data_pd






def readts_dia_HWLW(filename, station):
    &#34;&#34;&#34;
    Reads a non-equidistant dia file (wrapper around readts_dia). This definition will be phased out.

    &#34;&#34;&#34;
    raise Exception(&#39;ERROR: readts_dia_HWLW() was phased out, use readts_dia() instead&#39;)









def readts_noos(filename, datetime_format=&#39;%Y%m%d%H%M&#39;, na_values=None):
    &#34;&#34;&#34;
    Reads a noos file

    Parameters
    ----------
    filename : TYPE
        DESCRIPTION.
    datetime_format : TYPE, optional
        DESCRIPTION. The default is &#39;%Y%m%d%H%M&#39;.
    na_values : TYPE, optional
        DESCRIPTION. The default is None.

    Returns
    -------
    data_pd : TYPE
        DESCRIPTION.

    &#34;&#34;&#34;
    import pandas as pd
    
    print(&#39;-&#39;*100)
    print(&#39;reading file: %s&#39;%(filename))
    noosheader = []
    noosheader_dict = {}
    with open(filename) as f:
        for linenum, line in enumerate(f, 0):
            if &#39;#&#39; in line:
                noosheader.append(line)
                comment_stripped = line.strip(&#39;#&#39;).strip().split(&#39;: &#39;)
                if len(comment_stripped) == 1:
                    if comment_stripped[0] != &#39;&#39;:
                        noosheader_dict[comment_stripped[0]] = &#39;&#39;
                else:
                    noosheader_dict[comment_stripped[0].strip()] = comment_stripped[1].strip()
            else:
                startdata = linenum
                break
    
    content_pd = pd.read_csv(filename,header=startdata-1,delim_whitespace=True,names=[&#39;times_str&#39;,&#39;values&#39;], na_values=na_values)
    noos_datetime = pd.to_datetime(content_pd[&#39;times_str&#39;],format=datetime_format)
    data_pd = pd.DataFrame({&#39;values&#39;:content_pd[&#39;values&#39;].values},index=noos_datetime)
    
    check_ts(data_pd)
    return data_pd</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="hatyan.timeseries.calc_HWLW"><code class="name flex">
<span>def <span class="ident">calc_HWLW</span></span>(<span>ts, calc_HWLW345=False, calc_HWLW345_cleanup1122=True, debug=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculates extremes (high and low waters) for the provided timeseries.
This definition uses scipy.signal.find_peaks() with arguments 'distance' and 'prominence'.
The minimal 'distance' between two high or low water peaks is based on the M2 period: 12.42/1.5=8.28 hours for HW and 12.42/1.7=7.30 hours for LW (larger because of aggers).
Based on tests with several stations the 'prominence' is set to 0.1 to avoid local dips around high water to be seen as low waters.
The prominence for local extremes is set to 0.01m, to filter out very minor dips in the timeseries.
If there are two equal high or low water values, the first one is taken.
This function can deal with gaps. Since scipy.signal.find_peaks() warns about nan values, those are removed first.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>ts</code></strong> :&ensp;<code>pandas.DataFrame</code></dt>
<dd>The DataFrame should contain a 'values' column and a pd.DatetimeIndex as index, it contains the timeseries with a tidal prediction or water level measurements.</dd>
<dt><strong><code>calc_HWLW345</code></strong> :&ensp;<code>boolean</code>, optional</dt>
<dd>Whether to also calculate local extremes, first/second low waters and 'aggers'.
The default is False, in which case only extremes per tidal period are calculated.
When first/second low waters and aggers are calculated, the local extremes around highwater (eg double highwaters and dips) are filtered out first.</dd>
<dt><strong><code>calc_HWLW345_cleanup1122</code></strong> :&ensp;<code>boolean</code>, optional</dt>
<dd>Whether to remove HWLWcodes 11 and 22 from DataFrame. The default is True.</dd>
<dt><strong><code>debug</code></strong> :&ensp;<code>boolean</code>, optional</dt>
<dd>Whether to print debug information. The default is False.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>Exception</code></dt>
<dd>DESCRIPTION.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>data_pd_HWLW</code></strong> :&ensp;<code>pandas.DataFrame</code></dt>
<dd>The DataFrame contains colums 'times', 'values' and 'HWLWcode', it contains the times, values and codes of the timeseries that are extremes.
1 (high water) and 2 (low water). And if calc_HWLW345=True also 3 (first low water), 4 (agger) and 5 (second low water).</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calc_HWLW(ts, calc_HWLW345=False, calc_HWLW345_cleanup1122=True, debug=False):
    &#34;&#34;&#34;
    
    Calculates extremes (high and low waters) for the provided timeseries. 
    This definition uses scipy.signal.find_peaks() with arguments &#39;distance&#39; and &#39;prominence&#39;. 
    The minimal &#39;distance&#39; between two high or low water peaks is based on the M2 period: 12.42/1.5=8.28 hours for HW and 12.42/1.7=7.30 hours for LW (larger because of aggers). 
    Based on tests with several stations the &#39;prominence&#39; is set to 0.1 to avoid local dips around high water to be seen as low waters.
    The prominence for local extremes is set to 0.01m, to filter out very minor dips in the timeseries.
    If there are two equal high or low water values, the first one is taken. 
    This function can deal with gaps. Since scipy.signal.find_peaks() warns about nan values, those are removed first.
    
    Parameters
    ----------
    ts : pandas.DataFrame
        The DataFrame should contain a &#39;values&#39; column and a pd.DatetimeIndex as index, it contains the timeseries with a tidal prediction or water level measurements.
    calc_HWLW345 : boolean, optional
        Whether to also calculate local extremes, first/second low waters and &#39;aggers&#39;. 
        The default is False, in which case only extremes per tidal period are calculated.
        When first/second low waters and aggers are calculated, the local extremes around highwater (eg double highwaters and dips) are filtered out first.
    calc_HWLW345_cleanup1122 : boolean, optional
        Whether to remove HWLWcodes 11 and 22 from DataFrame. The default is True.
    debug : boolean, optional
        Whether to print debug information. The default is False.
    
    Raises
    ------
    Exception
        DESCRIPTION.
    
    Returns
    -------
    data_pd_HWLW : pandas.DataFrame
        The DataFrame contains colums &#39;times&#39;, &#39;values&#39; and &#39;HWLWcode&#39;, it contains the times, values and codes of the timeseries that are extremes.
        1 (high water) and 2 (low water). And if calc_HWLW345=True also 3 (first low water), 4 (agger) and 5 (second low water).

    &#34;&#34;&#34;
    import numpy as np
    import scipy.signal as ssig

    from hatyan.hatyan_core import get_hatyan_freqs
    
    #calculate the amount of steps in a M2 period, based on the most occurring timestep
    M2_period_min = get_hatyan_freqs([&#39;M2&#39;]).loc[&#39;M2&#39;,&#39;period [hr]&#39;]*60
    ts_steps_min_most = np.argmax(np.bincount((ts.index.to_series().diff().iloc[1:].dt.total_seconds()/60).astype(int).values))
    if ts_steps_min_most &gt; 1:
        print(&#39;WARNING: the timestep of the series for which to calculate extremes/HWLW is %i minutes, but 1 minute is recommended&#39;%(ts_steps_min_most))
    M2period_numsteps = M2_period_min/ts_steps_min_most #now based on M2 period (was called ts_poscrossing_moststeps before)
    
    ts = ts.copy()
    ts[&#39;times&#39;] = ts.index
    ts = ts.reset_index(drop=True)
    #create empty HWLW dataframe
    if ts[&#39;values&#39;].isnull().any():
        data_pd_HWLW = ts[~ts[&#39;values&#39;].isnull()]
        print(&#39;WARNING: the provided ts for extreme/HWLW calculation contained NaN values. To avoid unexpected results from scipy.signal.find_peaks(), the %i NaN values were removed from the ts (%.2f%%) before calculating extremes/HWLW.&#39;%(len(ts)-len(data_pd_HWLW), (len(ts)-len(data_pd_HWLW))/len(ts)*100))
    else:
        data_pd_HWLW = ts.copy()
    data_pd_HWLW[&#39;HWLWcode&#39;] = np.nan
    
    if calc_HWLW345:
        #get all local extremes, including aggers and second high waters (1/2/11/22)
        LWid_all, LWid_all_properties = ssig.find_peaks(-ts[&#39;values&#39;].values, distance=None, #takes first value of two equal lower values
                                                        prominence=(0.01,None), width=(None,None)) #prominence naar 0.01 om matige aggers uit te sluiten
        HWid_all, HWid_all_properties = ssig.find_peaks(ts[&#39;values&#39;].values, distance=None, #takes first value of two equal peaks
                                                        prominence=(0.01,None), width=(None,None)) #prominence naar 0.01 om matige aggers uit te sluiten
        LWid_all_toindex = ts.index[LWid_all]
        HWid_all_toindex = ts.index[HWid_all]
        data_pd_HWLW.loc[LWid_all_toindex,&#39;HWLWcode&#39;] = 22 #all LW
        data_pd_HWLW.loc[HWid_all_toindex,&#39;HWLWcode&#39;] = 11 #all HW


    #get HWLW (extremes per tidal period)
    LWid_main,LWid_main_properties = ssig.find_peaks(-ts[&#39;values&#39;].values, distance=M2period_numsteps/1.7, #most stations work with factor 1.4. 1.5 results in all LW values for HoekvanHolland for 2000, 1.7 results in all LW values for Rotterdam for 2000 (also for 1999-2002)
                                                     prominence=(0.1,None), width=(None,None)) #prominence van 0.1 om de echte piek te isoleren
    HWid_main,HWid_main_properties = ssig.find_peaks(ts[&#39;values&#39;].values, distance=M2period_numsteps/1.5, #most stations work with factor 1.4. 1.5 value results in all HW values for DenHelder for year 2000 (also for 1999-2002)
                                                     prominence=(0.1,None), width=(None,None)) #prominence van 0.1 om de echte piek te isoleren
    LWid_main_toindex = ts.index[LWid_main]
    HWid_main_toindex = ts.index[HWid_main]
    data_pd_HWLW.loc[LWid_main_toindex,&#39;HWLWcode&#39;] = 2
    data_pd_HWLW.loc[HWid_main_toindex,&#39;HWLWcode&#39;] = 1
    data_pd_HWLW = data_pd_HWLW[-data_pd_HWLW[&#39;HWLWcode&#39;].isnull()] #minus: not nan
    
    #convert HWLWcode column to integers
    data_pd_HWLW[&#39;HWLWcode&#39;] = data_pd_HWLW[&#39;HWLWcode&#39;].astype(int)
    
    if debug: #debug statistics
        prop_list = [&#39;prominences&#39;,&#39;widths&#39;]
        for prop in prop_list:
            data_pd_HWLW.loc[data_pd_HWLW[&#39;HWLWcode&#39;]==2,prop] = LWid_main_properties[prop]
        print(&#39;LW values:\n%s\n&#39;%(data_pd_HWLW[data_pd_HWLW[&#39;HWLWcode&#39;]==2]))
        
        for prop in prop_list:
            data_pd_HWLW.loc[data_pd_HWLW[&#39;HWLWcode&#39;]==1,prop] = HWid_main_properties[prop]
        print(&#39;HW values:\n%s\n&#39;%(data_pd_HWLW[data_pd_HWLW[&#39;HWLWcode&#39;]==1]))
        
        if 22 in data_pd_HWLW[&#39;HWLWcode&#39;].values:
            LW_local_bool = ~np.in1d(LWid_all, LWid_main)
            for prop in prop_list:
                data_pd_HWLW.loc[data_pd_HWLW[&#39;HWLWcode&#39;]==22,prop] = LWid_all_properties[prop][LW_local_bool]
            print(&#39;LW_local values:\n%s\n&#39;%(data_pd_HWLW[data_pd_HWLW[&#39;HWLWcode&#39;]==22]))
            
        if 11 in data_pd_HWLW[&#39;HWLWcode&#39;].values:
            HW_local_bool = ~np.in1d(HWid_all, HWid_main)
            for prop in prop_list:
                data_pd_HWLW.loc[data_pd_HWLW[&#39;HWLWcode&#39;]==11,prop] = HWid_all_properties[prop][HW_local_bool]
            print(&#39;HW_local values:\n%s\n&#39;%(data_pd_HWLW[data_pd_HWLW[&#39;HWLWcode&#39;]==11]))
        
    if not (data_pd_HWLW[&#39;HWLWcode&#39;].iloc[[0,-1]] == 1).all():
        print(&#39;WARNING: ts does not start and end with HW (HWLWcode=1), HW very close to start/end of ts might be missed because of too low prominence and 1stLW/agger/2ndLW is not calculated if not between two HWs (if calc_HWLW345=True). Check if begin/end HWLWcodes are correct and extend ts if necessary:\n%s&#39;%(data_pd_HWLW))

    if calc_HWLW345: #recalculate local LW/HWs between two main HWs to firstLW/agger/secondLW
        print(&#39;calculating 1stLW/agger/2ndLW for all tidalperiods...&#39;)
        for iTide, dummy in enumerate(HWid_main[:-1]):
            data_pd_HWLW_1tide = data_pd_HWLW.loc[HWid_main[iTide]:HWid_main[iTide+1],:]
            
            if 0: #remove only HW (not local values around HW)
                data_pd_HWLW_1tide_noHWs = data_pd_HWLW_1tide.iloc[1:-1]
            else: #filter local extremes around HW (only interested in aggers, so LW), this is necessary for eg DENHDR and PETTZD, otherwise second HW is seen as first LW
                data_pd_HWLW_1tide_minHW = data_pd_HWLW_1tide.loc[data_pd_HWLW_1tide[&#39;HWLWcode&#39;]==1,[&#39;values&#39;]].min()[0]
                data_pd_HWLW_1tide_min = data_pd_HWLW_1tide[&#39;values&#39;].min()
                data_pd_HWLW_1tide_mid = np.mean([data_pd_HWLW_1tide_minHW,data_pd_HWLW_1tide_min])
                bool_LWs = data_pd_HWLW_1tide[&#39;values&#39;]&lt;data_pd_HWLW_1tide_mid
                data_pd_HWLW_1tide_noHWs = data_pd_HWLW_1tide[bool_LWs]
            
            if len(data_pd_HWLW_1tide_noHWs) &gt; 3: #(attempt to) reduce to three values between two HWs
                print(&#39;WARNING: more than 3 values between HWs, removing part of them&#39;)
                #print(data_pd_HWLW_1tide)
                agger35_prim = data_pd_HWLW_1tide_noHWs[data_pd_HWLW_1tide_noHWs[&#39;HWLWcode&#39;]==2]
                if len(agger35_prim)&gt;1:
                    raise Exception(&#39;should be only one HWLWcode=2 per tide period&#39;)
                agger35_prim_loc = agger35_prim.index[0]
                agger35_sec_loc = data_pd_HWLW_1tide_noHWs.loc[data_pd_HWLW_1tide_noHWs[&#39;HWLWcode&#39;]==22,&#39;values&#39;].idxmin()
                agger35_loc = np.sort([agger35_prim_loc,agger35_sec_loc])
                data_pd_HWLW_1tide_noHWs = data_pd_HWLW_1tide_noHWs.loc[agger35_loc.min():agger35_loc.max(),:]
                agger4_loc = data_pd_HWLW_1tide_noHWs[&#39;values&#39;].idxmax()
                data_pd_HWLW_1tide_noHWs = data_pd_HWLW_1tide_noHWs.loc[[agger35_loc.min(),agger4_loc,agger35_loc.max()],:]
            
            if len(data_pd_HWLW_1tide_noHWs) == 1: #primary low water already has code 2
                if data_pd_HWLW_1tide_noHWs[&#39;HWLWcode&#39;].iloc[0] != 2:
                    raise Exception(&#39;Only 1 LW value but does not have HWLWcode 2&#39;)
            elif len(data_pd_HWLW_1tide_noHWs) == 3:
                if not data_pd_HWLW_1tide_noHWs[&#39;values&#39;].argmax() == 1:
                    raise Exception(&#39;3 values between two HW values, but center one is not the largest:\n%s&#39;%(data_pd_HWLW_1tide_noHWs))
                agger345_loc = data_pd_HWLW_1tide_noHWs.index
                if not (data_pd_HWLW.loc[agger345_loc[0],&#39;HWLWcode&#39;] in [2,22] and data_pd_HWLW.loc[agger345_loc[1],&#39;HWLWcode&#39;] in [11] and data_pd_HWLW.loc[agger345_loc[2],&#39;HWLWcode&#39;] in [2,22]):
                    raise Exception(&#39;3 values between two HW values, but do not correspond to LW/agger/LW:\n%s&#39;%(data_pd_HWLW_1tide_noHWs))
                data_pd_HWLW.loc[agger345_loc,&#39;HWLWcode&#39;] = [3,4,5]
            else:
                raise Exception(&#39;unexpected number of values between two HWs (0, 2 or more than 3):\n%s&#39;%(data_pd_HWLW_1tide_noHWs))
                
        #remove remaining 11 and 22 values from array
        if calc_HWLW345_cleanup1122:
            data_pd_HWLW = data_pd_HWLW.drop(data_pd_HWLW[data_pd_HWLW[&#39;HWLWcode&#39;]==11].index)
            data_pd_HWLW = data_pd_HWLW.drop(data_pd_HWLW[data_pd_HWLW[&#39;HWLWcode&#39;]==22].index)
        print(&#39;finished calculating 1stLW/agger/2ndLW for all tidalperiods&#39;)
    #return to normal time-index
    data_pd_HWLW = data_pd_HWLW.set_index(&#39;times&#39;)
    return data_pd_HWLW</code></pre>
</details>
</dd>
<dt id="hatyan.timeseries.calc_HWLWnumbering"><code class="name flex">
<span>def <span class="ident">calc_HWLWnumbering</span></span>(<span>ts_ext, station=None, corr_tideperiods=None)</span>
</code></dt>
<dd>
<div class="desc"><p>For calculation of the extremes numbering, w.r.t. the first high water at Cadzand in 2000 (occurred on 1-1-2000 at approximately 9:45).
The number of every high and low water is calculated by taking the time difference between itself and the first high water at Cadzand, correcting it with the station phase difference (M2phasediff).
Low waters are searched for half an M2 period from the high waters.
By adding a search window of half the period of M2 (searchwindow_hr), even strong time variance between consecutive high or low waters should be caputered. </p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>ts_ext</code></strong> :&ensp;<code>pandas.DataFrame</code></dt>
<dd>The DataFrame should contain a 'values' and 'HWLWcode' column and a pd.DatetimeIndex as index, it contains the times, values and codes of the timeseries that are extremes.</dd>
<dt><strong><code>station</code></strong> :&ensp;<code>string</code>, optional</dt>
<dd>The station for which the M2 phase difference should be retrieved from data_M2phasediff_perstation.txt.
This value is the phase difference in degrees of the occurrence of the high water generated by the same tidal wave as the first high water in 2000 at Cadzand (actually difference between M2 phases of stations).
This value is used to correct the search window of high/low water numbering. The default is None.</dd>
<dt><strong><code>corr_tideperiods</code></strong> :&ensp;<code>integer</code>, optional</dt>
<dd>Test keyword to derive HWLWnumbering with a n*360 degrees offset only, but this does not work properly. The default is None.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>Exception</code></dt>
<dd>DESCRIPTION.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>ts_ext</code></strong> :&ensp;<code>pandas.DataFrame</code></dt>
<dd>The input DataFrame with the column 'HWLWno' added, which contains the numbers of the extremes.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calc_HWLWnumbering(ts_ext, station=None, corr_tideperiods=None):
    &#34;&#34;&#34;
    For calculation of the extremes numbering, w.r.t. the first high water at Cadzand in 2000 (occurred on 1-1-2000 at approximately 9:45). 
    The number of every high and low water is calculated by taking the time difference between itself and the first high water at Cadzand, correcting it with the station phase difference (M2phasediff). 
    Low waters are searched for half an M2 period from the high waters. 
    By adding a search window of half the period of M2 (searchwindow_hr), even strong time variance between consecutive high or low waters should be caputered. 
    
    Parameters
    ----------
    ts_ext : pandas.DataFrame
        The DataFrame should contain a &#39;values&#39; and &#39;HWLWcode&#39; column and a pd.DatetimeIndex as index, it contains the times, values and codes of the timeseries that are extremes.
    station: string, optional
        The station for which the M2 phase difference should be retrieved from data_M2phasediff_perstation.txt.
        This value is the phase difference in degrees of the occurrence of the high water generated by the same tidal wave as the first high water in 2000 at Cadzand (actually difference between M2 phases of stations).
        This value is used to correct the search window of high/low water numbering. The default is None.
    corr_tideperiods : integer, optional
        Test keyword to derive HWLWnumbering with a n*360 degrees offset only, but this does not work properly. The default is None.

    Raises
    ------
    Exception
        DESCRIPTION.

    Returns
    -------
    ts_ext : pandas.DataFrame
        The input DataFrame with the column &#39;HWLWno&#39; added, which contains the numbers of the extremes.

    &#34;&#34;&#34;
    import os
    import pandas as pd
    import numpy as np
    import datetime as dt
    
    from hatyan.hatyan_core import get_hatyan_freqs
    
    M2_period_hr = get_hatyan_freqs([&#39;M2&#39;]).loc[&#39;M2&#39;,&#39;period [hr]&#39;]
    firstHWcadz_fixed = dt.datetime(2000, 1, 1, 9, 45)
    searchwindow_hr = M2_period_hr/2
    
    if not all((ts_ext[&#39;HWLWcode&#39;]==1) | (ts_ext[&#39;HWLWcode&#39;]==2) | (ts_ext[&#39;HWLWcode&#39;]==3) | (ts_ext[&#39;HWLWcode&#39;]==4) | (ts_ext[&#39;HWLWcode&#39;]==5)):
        raise Exception(&#39;calc_HWLWnumbering() not implemented for HWLWcode other than 1,2,3,4,5 (so no HWLWcode 11 or 22 supported), provide extreme timeseries derived with Timeseries.calc_HWLW(calc_HWLW345=False) or Timeseries.calc_HWLW(calc_HWLW345=True, calc_HWLW345_cleanup1122=True)&#39;)
    ts_ext = ts_ext.copy()
    
    HW_bool = ts_ext[&#39;HWLWcode&#39;]==1
    HW_tdiff_cadzdraw = (ts_ext.loc[HW_bool].index.to_series()-firstHWcadz_fixed).dt.total_seconds()/3600
    if station is None:
        HW_tdiff_cadzdraw_M2remainders = (HW_tdiff_cadzdraw)%M2_period_hr
        M2phasediff_hr = (HW_tdiff_cadzdraw_M2remainders).mean()
        M2phasediff_deg = M2phasediff_hr/M2_period_hr*360
        print(&#39;no value or None for argument M2phasediff provided, automatically calculated correction w.r.t. Cadzand is %.2f hours (%.2f degrees)&#39;%(M2phasediff_hr, M2phasediff_deg))
        if corr_tideperiods is not None:
            M2phasediff_deg = M2phasediff_deg+corr_tideperiods
            M2phasediff_hr = M2phasediff_deg/360*M2_period_hr
            print(&#39;additional tideperiod correction provided via corr_tideperiods of %.1f degrees, new correction w.r.t. Cadzand is %.2f hours (%.2f degrees)&#39;%(corr_tideperiods, M2phasediff_hr, M2phasediff_deg))
    else:
        dir_scriptfile = os.path.realpath(__file__) #F9 doesnt work, only F5 (F5 also only method to reload external definition scripts)
        file_M2phasediff = os.path.join(dir_scriptfile,os.pardir,&#39;data_M2phasediff_perstation.txt&#39;)
        stations_M2phasediff = pd.read_csv(file_M2phasediff, names=[&#39;M2phasediff&#39;], comment=&#39;#&#39;, delim_whitespace=True)
        stat_M2phasediff = stations_M2phasediff.loc[station,&#39;M2phasediff&#39;]
        M2phasediff_hr = stat_M2phasediff/360*M2_period_hr
    HW_tdiff_cadzd = HW_tdiff_cadzdraw - M2phasediff_hr + searchwindow_hr
    HW_tdiff_div, HW_tdiff_mod_searchwindow = np.divmod(HW_tdiff_cadzd.values, M2_period_hr)
    HW_tdiff_mod = HW_tdiff_mod_searchwindow - searchwindow_hr
    if not all(np.diff(HW_tdiff_div) &gt; 0):
        raise Exception(&#39;tidal wave numbering: HW numbers not always increasing&#39;)
    if not all(np.abs(HW_tdiff_mod)&lt;searchwindow_hr):
        raise Exception(&#39;tidal wave numbering: not all HW fall into hardcoded search window&#39;)
    ts_ext.loc[HW_bool,&#39;HWLWno&#39;] = HW_tdiff_div
    
    for LWcode_2345 in [2,3,4,5]:
        LW_bool = ts_ext[&#39;HWLWcode&#39;]==LWcode_2345
        LW_tdiff_cadzdraw = (ts_ext.loc[LW_bool].index.to_series()-firstHWcadz_fixed).dt.total_seconds()/3600
        LW_tdiff_cadzd = LW_tdiff_cadzdraw - M2phasediff_hr + searchwindow_hr - M2_period_hr/2
        LW_tdiff_div, LW_tdiff_mod_searchwindow = np.divmod(LW_tdiff_cadzd.values, M2_period_hr)
        LW_tdiff_mod = LW_tdiff_mod_searchwindow - searchwindow_hr
        if not all(np.diff(LW_tdiff_div) &gt; 0):
            raise Exception(&#39;tidal wave numbering: LW numbers not always increasing&#39;)
        if not all(np.abs(LW_tdiff_mod)&lt;searchwindow_hr):
            raise Exception(&#39;tidal wave numbering: not all LW fall into defined search window&#39;)
        ts_ext.loc[LW_bool,&#39;HWLWno&#39;] = LW_tdiff_div
    
    #check if LW is after HW
    ts_ext_checkfirst = ts_ext[ts_ext[&#39;HWLWno&#39;]==np.min(HW_tdiff_div)]
    tdiff_firstHWLW = (ts_ext_checkfirst.index.to_series().diff().dt.total_seconds()/3600).values[1]
    if (tdiff_firstHWLW&lt;0) or (tdiff_firstHWLW&gt;M2_period_hr):
        raise Exception(&#39;tidal wave numbering: first LW does not match first HW&#39;)
    
    ts_ext[&#39;HWLWno&#39;] = ts_ext[&#39;HWLWno&#39;].astype(int)
    
    return ts_ext</code></pre>
</details>
</dd>
<dt id="hatyan.timeseries.timeseries_fft"><code class="name flex">
<span>def <span class="ident">timeseries_fft</span></span>(<span>ts_residue, prominence=1000, plot_fft=True)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def timeseries_fft(ts_residue, prominence=10**3, plot_fft=True):
    import matplotlib.pyplot as plt
    import numpy as np
    from scipy.fft import fft, fftfreq
    import scipy.signal as ssig
    from hatyan.hatyan_core import get_hatyan_freqs
    
    print(&#39;analyzing timeseries with fft and fftfreq&#39;)
    
    y = ts_residue[&#39;values&#39;].values
    N = len(y)
    T = np.unique((ts_residue.index[1:]-ts_residue.index[:-1])).astype(float)/1e9/3600 #timestep in hours.
    if len(T)!=1:
        raise Exception(&#39;timestep of supplied timeseries should be constant for fourier analysis&#39;)
    yf = fft(y)
    power = np.abs(yf)
    freq = fftfreq(N, T[0])
    peaks = ssig.find_peaks(power[freq &gt;=0], prominence=prominence)[0]
    peak_freq =  freq[peaks]
    peak_power = power[peaks]
    
    if plot_fft:
        fig,ax = plt.subplots()
        ax.plot(freq[:N//2], power[:N//2])
        ax.plot(peak_freq, peak_power, &#39;ro&#39;)
        ax.grid()
        ax.set_xlim(0,0.5)
    
    hatyan_freqs = get_hatyan_freqs(const_list=&#39;all&#39;)[[&#39;freq&#39;]]
    const_match = []
    const_closest = []
    for peak_freq_one in peak_freq:
        hatyan_freqs_match = hatyan_freqs[np.abs(hatyan_freqs[&#39;freq&#39;]-peak_freq_one)&lt;4e-5]
        #print(peak_freq_one)
        #print(hatyan_freqs_match)
        hatyan_freqs_match_list = [x for x in hatyan_freqs_match.index if &#39;_IHO&#39; not in x]
        const_match = const_match+hatyan_freqs_match_list
        hatyan_freqs_closest = hatyan_freqs.iloc[np.argmin(np.abs(hatyan_freqs-peak_freq_one)),:]
        const_closest.append(hatyan_freqs_closest.name)
    hatyan_freqs_matches = get_hatyan_freqs(const_list=const_match)[[&#39;freq&#39;,&#39;period [hr]&#39;]]
    hatyan_freqs_suggestions = get_hatyan_freqs(const_list=const_closest)[[&#39;freq&#39;,&#39;period [hr]&#39;]]
    hatyan_freqs_suggestions[&#39;peak_freq&#39;] = peak_freq
    hatyan_freqs_suggestions[&#39;peak_power&#39;] = peak_power
    print(&#39;dominant freqs from fft:\n%s&#39;%(peak_freq))
    print(&#39;suggested constituents+freqs from hatyan:\n%s&#39;%(hatyan_freqs_suggestions))
    
    return peak_freq, hatyan_freqs_suggestions, hatyan_freqs_matches</code></pre>
</details>
</dd>
<dt id="hatyan.timeseries.plot_timeseries"><code class="name flex">
<span>def <span class="ident">plot_timeseries</span></span>(<span>ts, ts_validation=None, ts_ext=None, ts_ext_validation=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Creates a plot with the provided timeseries</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>ts</code></strong> :&ensp;<code>pandas.DataFrame</code></dt>
<dd>The DataFrame should contain a 'values' column and a pd.DatetimeIndex as index, it contains the timeseries.</dd>
<dt><strong><code>ts_validation</code></strong> :&ensp;<code>pandas.DataFrame</code>, optional</dt>
<dd>The DataFrame should contain a 'values' column and a pd.DatetimeIndex as index, it contains the timeseries. The default is None.</dd>
<dt><strong><code>ts_ext</code></strong> :&ensp;<code>pandas.DataFrame</code>, optional</dt>
<dd>The DataFrame should contain a 'values' and 'HWLW_code' column and a pd.DatetimeIndex as index, it contains the times, values and codes of the timeseries that are extremes. The default is None.</dd>
<dt><strong><code>ts_ext_validation</code></strong> :&ensp;<code>pandas.DataFrame</code>, optional</dt>
<dd>The DataFrame should contain a 'values' and 'HWLW_code' column and a pd.DatetimeIndex as index, it contains the times, values and codes of the timeseries that are extremes. The default is None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>fig</code></strong> :&ensp;<code>matplotlib.figure.Figure</code></dt>
<dd>The generated figure handle, with which the figure can be adapted and saved.</dd>
<dt><strong><code>axs</code></strong> :&ensp;<code>(tuple of) matplotlib.axes._subplots.AxesSubplot</code></dt>
<dd>The generated axis handle, whith which the figure can be adapted.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_timeseries(ts, ts_validation=None, ts_ext=None, ts_ext_validation=None):
    &#34;&#34;&#34;
    Creates a plot with the provided timeseries

    Parameters
    ----------
    ts : pandas.DataFrame
        The DataFrame should contain a &#39;values&#39; column and a pd.DatetimeIndex as index, it contains the timeseries.
    ts_validation : pandas.DataFrame, optional
        The DataFrame should contain a &#39;values&#39; column and a pd.DatetimeIndex as index, it contains the timeseries. The default is None.
    ts_ext : pandas.DataFrame, optional
        The DataFrame should contain a &#39;values&#39; and &#39;HWLW_code&#39; column and a pd.DatetimeIndex as index, it contains the times, values and codes of the timeseries that are extremes. The default is None.
    ts_ext_validation : pandas.DataFrame, optional
        The DataFrame should contain a &#39;values&#39; and &#39;HWLW_code&#39; column and a pd.DatetimeIndex as index, it contains the times, values and codes of the timeseries that are extremes. The default is None.

    Returns
    -------
    fig : matplotlib.figure.Figure
        The generated figure handle, with which the figure can be adapted and saved.
    axs : (tuple of) matplotlib.axes._subplots.AxesSubplot
        The generated axis handle, whith which the figure can be adapted.

    &#34;&#34;&#34;
    
    import numpy as np
    import matplotlib.pyplot as plt
        
    size_figure = (15,9)
    size_line_ts = 0.7
    size_marker_ts = 1
    figure_ylim_ts = [-3,3]
    figure_ylim_tsdiff = [-0.02,0.02]
    
    if ts_validation is not None:
        times_predval_ext = [min(min(ts_validation.index),min(ts.index)), max(max(ts_validation.index),max(ts.index))]

    else:
        times_predval_ext = [min(ts.index), max(ts.index)]    

    fig, (ax1, ax2) = plt.subplots(2,1,figsize=size_figure, sharex=True, gridspec_kw={&#39;height_ratios&#39;:[2,1]})
    
    ax1.set_title(&#39;hatyan timeseries&#39;)
    ax1.plot(ts.index, ts[&#39;values&#39;],&#39;o-&#39;,linewidth=size_line_ts,markersize=size_marker_ts, label=&#39;ts&#39;)
    if ts_validation is not None:
        #overlap between timeseries for difference plots
        times_id_validationinpred = np.where(ts_validation.index.isin(ts.index))[0]
        times_id_predinvalidation = np.where(ts.index.isin(ts_validation.index))[0]
        ax1.plot(ts_validation.index, ts_validation[&#39;values&#39;],&#39;o-&#39;,linewidth=size_line_ts,markersize=size_marker_ts, label=&#39;ts_validation&#39;, alpha=0.7)
        ax1.plot(ts.index[times_id_predinvalidation], ts[&#39;values&#39;].iloc[times_id_predinvalidation].values-ts_validation[&#39;values&#39;].iloc[times_id_validationinpred].values,&#39;go-&#39;,linewidth=size_line_ts,markersize=size_marker_ts, label=&#39;difference&#39;, alpha=0.7)
    ax1.plot(times_predval_ext,[0,0],&#39;-k&#39;,linewidth=size_line_ts)
    ts_mean = np.mean(ts[&#39;values&#39;])
    ax1.plot(ts.index[[0,-1]],[ts_mean,ts_mean],&#39;-r&#39;,linewidth=size_line_ts,label=&#39;mean of ts&#39;)
    if ts_ext is not None:
        HWLW_codesnames = {1:&#39;HW (1)&#39;,
                           2:&#39;LW (2)&#39;,
                           3:&#39;LW1 (3)&#39;,
                           4:&#39;topagger (4)&#39;,
                           5:&#39;LW2 (5)&#39;,
                           11:&#39;HW_local (11)&#39;,
                           22:&#39;LW_local (22)&#39;}
        for HWLW_code in HWLW_codesnames.keys():
            iExt = ts_ext[&#39;HWLWcode&#39;]==HWLW_code
            if iExt.any():
                HWLW_name = HWLW_codesnames[HWLW_code]
                HWLW_markersize=10
                if HWLW_code in [4,11,22]:
                    HWLW_markersize=5
                ax1.plot(ts_ext.index[iExt],ts_ext[&#39;values&#39;][iExt],&#39;x&#39;,markersize=HWLW_markersize,label=HWLW_name)
    if ts_ext_validation is not None:
        vali_codes = [1,2,3,4,5]
        vali_codenames = [&#39;vali_HW&#39;,&#39;vali_LW&#39;,&#39;vali_LW1&#39;,&#39;vali_topagger&#39;,&#39;vali_LW2&#39;]
        for vali_code, vali_codename in zip(vali_codes,vali_codenames):
            vali_code_ids = ts_ext_validation[&#39;HWLWcode&#39;].values==vali_code
            if any(vali_code_ids): #only plot vali_code in legend if present in HWLW_timeseries
                ax1.plot(ts_ext_validation.index[vali_code_ids],ts_ext_validation[&#39;values&#39;][vali_code_ids],&#39;1&#39;,markersize=10,label=vali_codename)
        #print HWLW statistics
        try:
            plot_HWLW_validatestats(ts_ext=ts_ext, ts_ext_validation=ts_ext_validation, create_plot=False)        
        except:
            print(&#39;WARNING: plot_HWLW_validatestats() failed, probably due to missing HWLWno where autocalculation failed. Consider adding HWLWno to ts_ext and ts_ext_validation with calc_HWLWnumbering() before plotting.&#39;)
    ax1.set_ylim(figure_ylim_ts)
    ax2.set_xlabel(&#39;Time&#39;)
    ax1.set_ylabel(&#39;waterlevel [m]&#39;)
    ax1.legend(loc=&#39;lower right&#39;)
    ax1.grid()
    if ts_validation is not None:
        ax2.plot(ts.index[times_id_predinvalidation], ts[&#39;values&#39;].iloc[times_id_predinvalidation].values-ts_validation[&#39;values&#39;].iloc[times_id_validationinpred].values,&#39;go-&#39;,linewidth=size_line_ts,markersize=size_marker_ts, label=&#39;difference&#39;)
    ax2.plot(times_predval_ext,[0,0],&#39;-k&#39;,linewidth=size_line_ts)
    ax2.set_ylim(figure_ylim_tsdiff)
    rmse = np.nan
    if ts_validation is not None:
        overlapdiff = ts[&#39;values&#39;].iloc[times_id_predinvalidation].values-ts_validation[&#39;values&#39;].iloc[times_id_validationinpred].values
        if len(overlapdiff) != 0:
            rmse = np.sqrt(np.nanmean(overlapdiff ** 2))
    ax2.set_ylabel(&#39;timeseries difference [m], RMSE = %.5f&#39;%(rmse))
    ax2.legend(loc=&#39;lower right&#39;)
    ax2.grid()
    fig.tight_layout()
    
    axs = (ax1,ax2)
    return fig, axs</code></pre>
</details>
</dd>
<dt id="hatyan.timeseries.plot_HWLW_validatestats"><code class="name flex">
<span>def <span class="ident">plot_HWLW_validatestats</span></span>(<span>ts_ext, ts_ext_validation, create_plot=True)</span>
</code></dt>
<dd>
<div class="desc"><p>This definition calculates (and plots and prints) some statistics when comparing extreme values.
This is done by calculating the extreme number (sort of relative to Cadzand 1jan2000, but see 'warning') and subtracting the ts_ext and ts_ext_validation dataframes based on these numbers (and HWLWcode).
It will only result in values for the overlapping extremes, other values will be NaN and are not considered for the statistics.
Warning: the calculated extreme numbers in this definition are not corrected for the real phase difference with the M2phasediff argument, the calculated extreme are fine for internal use (to match corresponding extremes) but the absolute number might be incorrect.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>ts_ext</code></strong> :&ensp;<code>pandas.DataFrame</code></dt>
<dd>The DataFrame should contain a 'values' and 'HWLW_code' column and a pd.DatetimeIndex as index, it contains the times, values and codes of the timeseries that are extremes.</dd>
<dt><strong><code>ts_ext_validation</code></strong> :&ensp;<code>pandas.DataFrame</code></dt>
<dd>The DataFrame should contain a 'values' and 'HWLW_code' column and a pd.DatetimeIndex as index, values and codes of the timeseries that are extremes.</dd>
<dt><strong><code>create_plot</code></strong> :&ensp;<code>boolean</code>, optional</dt>
<dd>Whether to plot the time/value differences or only print the statistics. The default is True.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>fig</code></strong> :&ensp;<code>matplotlib.figure.Figure</code></dt>
<dd>The generated figure handle, with which the figure can be adapted and saved.</dd>
<dt><strong><code>axs</code></strong> :&ensp;<code>(tuple of) matplotlib.axes._subplots.AxesSubplot</code></dt>
<dd>The generated axis handle, whith which the figure can be adapted.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_HWLW_validatestats(ts_ext, ts_ext_validation, create_plot=True):
    &#34;&#34;&#34;
    This definition calculates (and plots and prints) some statistics when comparing extreme values.
    This is done by calculating the extreme number (sort of relative to Cadzand 1jan2000, but see &#39;warning&#39;) and subtracting the ts_ext and ts_ext_validation dataframes based on these numbers (and HWLWcode).
    It will only result in values for the overlapping extremes, other values will be NaN and are not considered for the statistics.
    Warning: the calculated extreme numbers in this definition are not corrected for the real phase difference with the M2phasediff argument, the calculated extreme are fine for internal use (to match corresponding extremes) but the absolute number might be incorrect.

    Parameters
    ----------
    ts_ext : pandas.DataFrame
        The DataFrame should contain a &#39;values&#39; and &#39;HWLW_code&#39; column and a pd.DatetimeIndex as index, it contains the times, values and codes of the timeseries that are extremes.
    ts_ext_validation : pandas.DataFrame
        The DataFrame should contain a &#39;values&#39; and &#39;HWLW_code&#39; column and a pd.DatetimeIndex as index, values and codes of the timeseries that are extremes.
    create_plot : boolean, optional
        Whether to plot the time/value differences or only print the statistics. The default is True.

    Returns
    -------
    fig : matplotlib.figure.Figure
        The generated figure handle, with which the figure can be adapted and saved.
    axs : (tuple of) matplotlib.axes._subplots.AxesSubplot
        The generated axis handle, whith which the figure can be adapted.

    &#34;&#34;&#34;
    import numpy as np
    import matplotlib.pyplot as plt
    
    print(&#39;Calculating comparison statistics for extremes&#39;)
    if not &#39;HWLWno&#39; in ts_ext.columns or not &#39;HWLWno&#39; in ts_ext_validation.columns:
        print(&#39;HWLWno is not present in ts_ext or ts_ext_validation, trying to automatically derive it without M2phasediff argument (this might fail)&#39;)
        try:
            ts_ext_nrs = calc_HWLWnumbering(ts_ext=ts_ext)
            ts_ext_validation_nrs = calc_HWLWnumbering(ts_ext=ts_ext_validation)
        except:
            raise Exception(&#39;ERROR: deriving HWLWno failed, so HWLW statistics cannot be calculated. Add HWLWno with calc_HWLWnumbering() before calling plot_HWLW_validatestats().&#39;)
    else:
        ts_ext_nrs = ts_ext.copy()
        ts_ext_validation_nrs = ts_ext_validation.copy()

    #set HWLWcode and HWLWno as index, to make easy subtraction possible
    ts_ext_nrs[&#39;times&#39;] = ts_ext_nrs.index
    ts_ext_nrs = ts_ext_nrs.set_index([&#39;HWLWcode&#39;,&#39;HWLWno&#39;],drop=False)
    ts_ext_validation_nrs[&#39;times&#39;] = ts_ext_validation_nrs.index
    ts_ext_validation_nrs = ts_ext_validation_nrs.set_index([&#39;HWLWcode&#39;,&#39;HWLWno&#39;],drop=False)
    HWLW_diff = ts_ext_nrs.sub(ts_ext_validation_nrs)
    
    tdiff_minutes = HWLW_diff[&#39;times&#39;].dt.total_seconds()/60
    vdiff_cm = HWLW_diff[&#39;values&#39;]*100
    print(&#39;Time differences [minutes]&#39;)
    print(&#39;    RMSE: %.2f&#39;%(np.sqrt(np.mean(tdiff_minutes**2))))
    print(&#39;    std: %.2f&#39;%(tdiff_minutes.std()))
    print(&#39;    abs max: %.2f&#39;%(tdiff_minutes.abs().max()))
    print(&#39;    abs mean: %.2f&#39;%(tdiff_minutes.abs().mean()))
    print(&#39;    #NaN: %i of %i&#39;%(tdiff_minutes.isnull().sum(),len(vdiff_cm)))
    print(&#39;Value differences [cm]&#39;)
    print(&#39;    RMSE: %.2f&#39;%(np.sqrt(np.mean(vdiff_cm**2))))
    print(&#39;    std: %.2f&#39;%(vdiff_cm.std()))
    print(&#39;    abs max: %.2f&#39;%(vdiff_cm.abs().max()))
    print(&#39;    abs mean: %.2f&#39;%(vdiff_cm.abs().mean()))
    print(&#39;    #NaN: %i of %i&#39;%(vdiff_cm.isnull().sum(),len(vdiff_cm)))
    
    if create_plot:
        fig, ax1 = plt.subplots()
        ax1.plot(HWLW_diff.loc[1,&#39;times&#39;].dt.total_seconds()/60,HWLW_diff.loc[1,&#39;values&#39;]*100,&#39;+&#39;,label=&#39;HWdiff&#39;)
        ax1.plot(HWLW_diff.loc[2,&#39;times&#39;].dt.total_seconds()/60,HWLW_diff.loc[2,&#39;values&#39;]*100,&#39;.&#39;,label=&#39;LWdiff&#39;)
        ax1.set_xlabel(&#39;Time difference [minutes]&#39;)
        ax1.set_ylabel(&#39;Value difference [cm]&#39;)
        ax1.legend(loc=1)
        ax1.grid()
    
        axs = (ax1)
        return fig, axs</code></pre>
</details>
</dd>
<dt id="hatyan.timeseries.write_tsnetcdf"><code class="name flex">
<span>def <span class="ident">write_tsnetcdf</span></span>(<span>ts, station, vertref, filename, ts_ext=None, tzone_hr=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Writes the timeseries to a netCDF file</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>ts</code></strong> :&ensp;<code>pandas.DataFrame</code></dt>
<dd>The DataFrame should contain a 'values' column and a pd.DatetimeIndex as index, it contains the timeseries.</dd>
<dt><strong><code>station</code></strong> :&ensp;<code>str</code></dt>
<dd>DESCRIPTION.</dd>
<dt><strong><code>vertref</code></strong> :&ensp;<code>str</code></dt>
<dd>DESCRIPTION.</dd>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code></dt>
<dd>The filename of the netCDF file that will be written.</dd>
<dt><strong><code>ts_ext</code></strong> :&ensp;<code>pandas.DataFrame</code>, optional</dt>
<dd>The DataFrame should contain a 'values' and 'HWLW_code' column and a pd.DatetimeIndex as index, it contains the times, values and codes of the timeseries that are extremes. The default is None.</dd>
<dt><strong><code>tzone_hr</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The timezone (GMT+tzone_hr) that applies to the data. The default is 1 (MET).</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def write_tsnetcdf(ts, station, vertref, filename, ts_ext=None, tzone_hr=1):
    &#34;&#34;&#34;
    Writes the timeseries to a netCDF file

    Parameters
    ----------
    ts : pandas.DataFrame
        The DataFrame should contain a &#39;values&#39; column and a pd.DatetimeIndex as index, it contains the timeseries.
    station : str
        DESCRIPTION.
    vertref : str
        DESCRIPTION.
    filename : str
        The filename of the netCDF file that will be written.
    ts_ext : pandas.DataFrame, optional
        The DataFrame should contain a &#39;values&#39; and &#39;HWLW_code&#39; column and a pd.DatetimeIndex as index, it contains the times, values and codes of the timeseries that are extremes. The default is None.
    tzone_hr : int, optional
        The timezone (GMT+tzone_hr) that applies to the data. The default is 1 (MET).

    Returns
    -------
    None.

    &#34;&#34;&#34;

    #import os
    import datetime as dt
    from netCDF4 import Dataset, date2num, stringtoarr#, num2date
    import hatyan
    version_no = hatyan.__version__
    
    
    times_all = ts.index
    timeseries = ts[&#39;values&#39;]
    times_stepmin = (ts.index[1]-ts.index[0]).total_seconds()/60
    dt_analysistime = dt.datetime.now()
    data_nc = Dataset(filename, &#39;w&#39;, format=&#34;NETCDF3_CLASSIC&#34;)
    attr_dict = {&#39;title&#39;: &#39;tidal prediction for %s to %s&#39;%(times_all[0].strftime(&#39;%Y-%m-%d %H:%M:%S&#39;), times_all[-1].strftime(&#39;%Y-%m-%d %H:%M:%S&#39;)),
                 &#39;institution&#39;: &#39;Rijkswaterstaat&#39;,
                 &#39;source&#39;: &#39;hatyan-%s tidal analysis program of Rijkswaterstaat&#39;%(version_no),
                 &#39;timestep_min&#39;: times_stepmin}
    for ncattrname in list(attr_dict.keys()):
        data_nc.setncattr(ncattrname, attr_dict[ncattrname])

    ncvarlist = list(data_nc.variables.keys())
    ncdimlist = list(data_nc.dimensions.keys())
    statname_len = 64
    
    if &#39;stations&#39; not in ncdimlist:
        data_nc.createDimension(&#39;stations&#39;,None)
    if &#39;statname_len&#39; not in ncdimlist:
        data_nc.createDimension(&#39;statname_len&#39;,statname_len)
    if &#39;time&#39; not in ncdimlist:
        data_nc.createDimension(&#39;time&#39;,len(times_all.tolist()))
    if &#39;analysis_time&#39; not in ncdimlist:
        data_nc.createDimension(&#39;analysis_time&#39;,1)

    refdate_tz = dt.datetime(1900,1,1,tzinfo=dt.timezone(dt.timedelta(hours=tzone_hr)))
    dict_statattr = {&#39;cf_role&#39;: &#39;timeseries_id&#39;}
    dict_anatimattr = {&#39;units&#39;: &#39;minutes since %s&#39;%(refdate_tz.strftime(&#39;%Y-%m-%d %H:%M:%S %z&#39;)), &#39;standard_name&#39;:&#39;forecast_reference_time&#39;, &#39;long_name&#39;:&#39;forecast_reference_time&#39;}
    dict_timattr = {&#39;units&#39;: &#39;minutes since %s&#39;%(refdate_tz.strftime(&#39;%Y-%m-%d %H:%M:%S %z&#39;))}
    dict_wlattr = {&#39;units&#39;:&#39;m&#39;, &#39;vertical_reference&#39;: vertref, &#39;standard_name&#39;: &#39;sea_surface_height_above_geopotential_datum&#39;, &#39;long_name&#39;: &#39;astronomical prediction of water level above reference level&#39;}
    dict_HWattr = {&#39;units&#39;:&#39;m&#39;, &#39;vertical_reference&#39;: vertref, &#39;standard_name&#39;: &#39;sea_surface_height_above_geopotential_datum&#39;, &#39;long_name&#39;: &#39;astronomical prediction of high water extremes above reference level&#39;}
    dict_LWattr = {&#39;units&#39;:&#39;m&#39;, &#39;vertical_reference&#39;: vertref, &#39;standard_name&#39;: &#39;sea_surface_height_above_geopotential_datum&#39;, &#39;long_name&#39;: &#39;astronomical prediction of low water extremes above reference level&#39;}
    #dict_HWrowsizeattr = {&#39;long_name&#39;:&#39;number of observations for this station&#39;, &#39;sample_dimension&#39;:&#39;obs_raggedHW&#39;}
    if not &#39;stations&#39; in ncvarlist: #create empty variables if not yet present
        nc_newvar = data_nc.createVariable(&#39;stations&#39;,&#39;S1&#39;,(&#39;stations&#39;,&#39;statname_len&#39;,))
        for attrname in list(dict_statattr.keys()):
            nc_newvar.setncattr(attrname, dict_statattr[attrname])
    
    if not &#39;analysis_time&#39; in ncvarlist:
        nc_newvar = data_nc.createVariable(&#39;analysis_time&#39;,&#39;f8&#39;,(&#39;analysis_time&#39;,))
        for attrname in list(dict_anatimattr.keys()):
            nc_newvar.setncattr(attrname, dict_anatimattr[attrname])
        data_nc.variables[&#39;analysis_time&#39;][0] = date2num([dt_analysistime], units=data_nc.variables[&#39;analysis_time&#39;].units)   
    
    #current length is used as index
    nstat = data_nc.variables[&#39;stations&#39;].shape[0]
    #append current data to netcdf files
    data_nc.variables[&#39;stations&#39;][nstat,:] = stringtoarr(station, statname_len, dtype=&#39;S&#39;)
    
    
    #general prediction
    if not &#39;time&#39; in ncvarlist:
        nc_newvar = data_nc.createVariable(&#39;time&#39;,&#39;f8&#39;,(&#39;time&#39;,))
        for attrname in list(dict_timattr.keys()):
            nc_newvar.setncattr(attrname, dict_timattr[attrname])
        #set time contents upon creation of variable, is constant over loop
        data_nc.variables[&#39;time&#39;][:] = date2num(times_all.tolist(),units=data_nc.variables[&#39;time&#39;].units)
    if not &#39;waterlevel_astro&#39; in ncvarlist:
        nc_newvar = data_nc.createVariable(&#39;waterlevel_astro&#39;,&#39;f8&#39;,(&#39;stations&#39;,&#39;time&#39;,))
        for attrname in list(dict_wlattr.keys()):
            nc_newvar.setncattr(attrname, dict_wlattr[attrname])
    data_nc.variables[&#39;waterlevel_astro&#39;][nstat,:] = timeseries
    
    #HWLW prediction
    if ts_ext is not None:
        data_HWLW = ts_ext.copy()
        data_HWLW = data_HWLW.sort_index(axis=0)
        data_HW = data_HWLW[data_HWLW[&#39;HWLWcode&#39;]==1]
        data_LW = data_HWLW[data_HWLW[&#39;HWLWcode&#39;]==2]
        #create empty variables if not yet present

        #HW
        if &#39;time_HW&#39; not in ncdimlist:
            data_nc.createDimension(&#39;time_HW&#39;,len(data_HW))
        if not &#39;time_HW&#39; in ncvarlist:
            nc_newvar = data_nc.createVariable(&#39;time_HW&#39;,&#39;f8&#39;,(&#39;time_HW&#39;,))
            for attrname in list(dict_timattr.keys()):
                nc_newvar.setncattr(attrname, dict_timattr[attrname])
        data_nc.variables[&#39;time_HW&#39;][:] = date2num(data_HW.index.tolist(),units=data_nc.variables[&#39;time_HW&#39;].units)
        if not &#39;waterlevel_astro_HW&#39; in ncvarlist:
            nc_newvar = data_nc.createVariable(&#39;waterlevel_astro_HW&#39;,&#39;f8&#39;,(&#39;stations&#39;,&#39;time_HW&#39;,))
            for attrname in list(dict_HWattr.keys()):
                nc_newvar.setncattr(attrname, dict_HWattr[attrname])
        data_nc.variables[&#39;waterlevel_astro_HW&#39;][nstat,:] = data_HW[&#39;values&#39;]
        
        #LW
        if &#39;time_LW&#39; not in ncdimlist:
            data_nc.createDimension(&#39;time_LW&#39;,len(data_LW))
        if not &#39;time_LW&#39; in ncvarlist:
            nc_newvar = data_nc.createVariable(&#39;time_LW&#39;,&#39;f8&#39;,(&#39;time_LW&#39;,))
            for attrname in list(dict_timattr.keys()):
                nc_newvar.setncattr(attrname, dict_timattr[attrname])
        data_nc.variables[&#39;time_LW&#39;][:] = date2num(data_LW.index.tolist(),units=data_nc.variables[&#39;time_LW&#39;].units)
        if not &#39;waterlevel_astro_LW&#39; in ncvarlist:
            nc_newvar = data_nc.createVariable(&#39;waterlevel_astro_LW&#39;,&#39;f8&#39;,(&#39;stations&#39;,&#39;time_LW&#39;,))
            for attrname in list(dict_LWattr.keys()):
                nc_newvar.setncattr(attrname, dict_LWattr[attrname])
        data_nc.variables[&#39;waterlevel_astro_LW&#39;][nstat,:] = data_LW[&#39;values&#39;]
        
        #HWLW numbering
        if &#39;HWLWno&#39; in ts_ext.columns:
            if not &#39;waterlevel_astro_HW_numbers&#39; in ncvarlist:
                nc_newvar = data_nc.createVariable(&#39;waterlevel_astro_HW_numbers&#39;,&#39;i4&#39;,(&#39;stations&#39;,&#39;time_HW&#39;,))
                #for attrname in list(dict_HWattr.keys()):
                #    nc_newvar.setncattr(attrname, dict_HWattr[attrname])
            data_nc.variables[&#39;waterlevel_astro_HW_numbers&#39;][nstat,:] = data_HW[&#39;HWLWno&#39;]
            if not &#39;waterlevel_astro_LW_numbers&#39; in ncvarlist:
                nc_newvar = data_nc.createVariable(&#39;waterlevel_astro_LW_numbers&#39;,&#39;i4&#39;,(&#39;stations&#39;,&#39;time_LW&#39;,))
                #for attrname in list(dict_LWattr.keys()):
                #    nc_newvar.setncattr(attrname, dict_LWattr[attrname])
            data_nc.variables[&#39;waterlevel_astro_LW_numbers&#39;][nstat,:] = data_LW[&#39;HWLWno&#39;]
            

    else:
        print(&#39;no HWLW prediction written&#39;)

        
    data_nc.close()</code></pre>
</details>
</dd>
<dt id="hatyan.timeseries.write_tsdia"><code class="name flex">
<span>def <span class="ident">write_tsdia</span></span>(<span>ts, station, vertref, filename)</span>
</code></dt>
<dd>
<div class="desc"><p>Writes the timeseries to an equidistant dia file</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>ts</code></strong> :&ensp;<code>pandas.DataFrame</code></dt>
<dd>The DataFrame should contain a 'values' column and a pd.DatetimeIndex as index, it contains the timeseries.</dd>
<dt><strong><code>station</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>DESCRIPTION.</dd>
<dt><strong><code>vertref</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>DESCRIPTION.</dd>
<dt><strong><code>filename</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>DESCRIPTION.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>Exception</code></dt>
<dd>DESCRIPTION.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def write_tsdia(ts, station, vertref, filename):
    &#34;&#34;&#34;
    Writes the timeseries to an equidistant dia file

    Parameters
    ----------
    ts : pandas.DataFrame
        The DataFrame should contain a &#39;values&#39; column and a pd.DatetimeIndex as index, it contains the timeseries.
    station : TYPE
        DESCRIPTION.
    vertref : TYPE
        DESCRIPTION.
    filename : TYPE
        DESCRIPTION.

    Raises
    ------
    Exception
        DESCRIPTION.

    Returns
    -------
    None.

    &#34;&#34;&#34;
    import io
    import datetime as dt
    
    if vertref == &#39;NAP&#39;:
        waarnemingssoort = 18
    elif vertref == &#39;MSL&#39;:
        waarnemingssoort = 55
    else:
        raise Exception(&#39;ERROR: currently only vertref=&#34;NAP&#34; and vertref=&#34;MSL&#34; are supported for writing diafiles&#39;)

    ts_times = ts.index
    ts_values = ts[&#39;values&#39;]

    with io.open(filename,&#39;w&#39;, newline=&#39;\n&#39;) as f:
        #f.write(&#39;#### created by Python prototype of HATYAN 2.0 ####\n&#39;)
        f.write(&#39;[IDT;*DIF*;A;CENT;%6s]\n&#39;%(dt.datetime.today().strftime(&#39;%Y%m%d&#39;)))
        f.write(&#39;[W3H]\n&#39;)
        f.write(&#39;WNS;%i\n&#39;%(waarnemingssoort))
        f.write(&#39;PAR;WATHTBRKD;;;\n&#39;) #parameter, gelijk voor waarnemingssoorten 18 en 55
        f.write(&#39;CPM;10\n&#39;) #compartiment, gelijk voor waarnemingssoorten 18 en 55
        f.write(&#39;EHD;I;cm\n&#39;) #eenheid, gelijk voor waarnemingssoorten 18 en 55
        f.write(&#39;HDH;%s\n&#39;%(vertref))
        f.write(&#39;ANI;RIKZITSDHG\n&#39;)
        f.write(&#39;BHI;RIKZITSDHG\n&#39;)
        f.write(&#39;BMI;NVT\n&#39;)
        f.write(&#39;OGI;RIKZMON_WAT\n&#39;)
        f.write(&#39;LOC;%s\n&#39;%(station))
        f.write(&#39;ANA;F012\n&#39;)
        f.write(&#39;BEM;NVT\n&#39;)
        f.write(&#39;BEW;NVT\n&#39;)
        f.write(&#39;VAT;NVT\n&#39;)
        f.write(&#39;TYP;TE\n&#39;)
        f.write(&#39;[TPS]\n&#39;)
        f.write(&#39;STA;%6s;%4s;%6s;%4s;O\n&#39;%(ts_times[0].strftime(&#39;%Y%m%d&#39;),ts_times[0].strftime(&#39;%H%M&#39;),ts_times[-1].strftime(&#39;%Y%m%d&#39;),ts_times[-1].strftime(&#39;%H%M&#39;)))
        f.write(&#39;[RKS]\n&#39;)
        f.write(&#39;TYD;%6s;%4s;%6s;%4s;%i;min\n&#39;%(ts_times[0].strftime(&#39;%Y%m%d&#39;),ts_times[0].strftime(&#39;%H%M&#39;),ts_times[-1].strftime(&#39;%Y%m%d&#39;),ts_times[-1].strftime(&#39;%H%M&#39;), (ts_times[1]-ts_times[0]).total_seconds()/60))
        f.write(&#39;[WRD]\n&#39;)

        linestr = &#39;&#39;
        filelim = len(ts_values)
        for iV, ts_value in enumerate(ts_values):
            blocklength = 720
            linestr_add = &#34;%i/0:&#34;%(ts_value*100)
            if len(linestr+linestr_add)&lt;=120:
                linestr = linestr + linestr_add
                if iV==filelim-1 or iV%blocklength==blocklength-1:
                    f.write(linestr+&#39;\n&#39;)
                    linestr = &#39;&#39;
            else:
                f.write(linestr+&#39;\n&#39;)
                linestr = linestr_add</code></pre>
</details>
</dd>
<dt id="hatyan.timeseries.write_tsdia_HWLW"><code class="name flex">
<span>def <span class="ident">write_tsdia_HWLW</span></span>(<span>ts_ext, station, vertref, filename)</span>
</code></dt>
<dd>
<div class="desc"><p>writes the extremes timeseries to a non-equidistant dia file</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>ts_ext</code></strong> :&ensp;<code>pandas.DataFrame</code></dt>
<dd>The DataFrame should contain a 'values' and 'HWLW_code' column and a pd.DatetimeIndex as index, it contains the times, values and codes of the timeseries that are extremes.</dd>
<dt><strong><code>station</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>DESCRIPTION.</dd>
<dt><strong><code>vertref</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>DESCRIPTION.</dd>
<dt><strong><code>filename</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>DESCRIPTION.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>Exception</code></dt>
<dd>DESCRIPTION.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def write_tsdia_HWLW(ts_ext, station, vertref, filename):
    &#34;&#34;&#34;
    writes the extremes timeseries to a non-equidistant dia file

    Parameters
    ----------
    ts_ext : pandas.DataFrame
        The DataFrame should contain a &#39;values&#39; and &#39;HWLW_code&#39; column and a pd.DatetimeIndex as index, it contains the times, values and codes of the timeseries that are extremes.
    station : TYPE
        DESCRIPTION.
    vertref : TYPE
        DESCRIPTION.
    filename : TYPE
        DESCRIPTION.

    Raises
    ------
    Exception
        DESCRIPTION.

    Returns
    -------
    None.

    &#34;&#34;&#34;
    import io
    import datetime as dt
    
    if vertref == &#39;NAP&#39;:
        waarnemingssoort = 18
        vertreflong = &#39;T.o.v. Normaal Amsterdams Peil&#39;
        parameter = &#39;GETETBRKD2&#39;
        parameterlong = &#39;Getijextreem berekend&#39;
    elif vertref == &#39;MSL&#39;:
        waarnemingssoort = 55
        vertreflong = &#39;T.o.v. Mean Sea Level&#39;
        parameter = &#39;GETETBRKDMSL2&#39;
        parameterlong = &#39;Getijextreem berekend t.o.v. MSL&#39;
    else:
        raise Exception(&#39;ERROR: currently only vertref=&#34;NAP&#34; and vertref=&#34;MSL&#34; are supported for writing diafiles&#39;)
            
    data_HWLW = ts_ext.copy()
    if 11 in data_HWLW[&#39;HWLWcode&#39;].values or 22 in data_HWLW[&#39;HWLWcode&#39;].values:
        raise Exception(&#39;ERROR: invalid HWLWcodes in provided extreme timeseries (11 and/or 22)&#39;)
    
    with io.open(filename,&#39;w&#39;, newline=&#39;\n&#39;) as f:
        f.write(&#39;[IDT;*DIF*;A;;%6s]\n&#39;%(dt.datetime.today().strftime(&#39;%Y%m%d&#39;)))
        f.write(&#39;[W3H]\n&#39;)
        f.write(&#39;MUX;%s;%s\n&#39;%(parameter, parameterlong))
        f.write(&#39;ANI;RIKZITSDHG;RIKZ - afdeling ZDI te Den Haag\n&#39;)
        f.write(&#39;BHI;RIKZITSDHG;RIKZ - afdeling ZDI te Den Haag\n&#39;)
        f.write(&#39;BMI;NVT;Niet van toepassing\n&#39;)
        f.write(&#39;OGI;RIKZMON_WAT;RIKZ - Landelijke monitoring waterhoogten gegevens\n&#39;)
        f.write(&#39;LOC;%s\n&#39;%(station))
        f.write(&#39;ANA;F012;Waterhoogte astronomisch mbv harmonische analyse\n&#39;) #HW en LW uit 1 min. waterhoogten gefilterd uit 10 min. gem.
        f.write(&#39;BEM;NVT;Niet van toepassing\n&#39;)
        f.write(&#39;BEW;NVT;Niet van toepassing\n&#39;)
        f.write(&#39;VAT;NVT;Niet van toepassing\n&#39;)
        f.write(&#39;TYP;TN\n&#39;)
        f.write(&#39;[MUX]\n&#39;)
        f.write(&#39;MXW;1;15\n&#39;)
        f.write(&#39;MXP;1;GETETCDE;Getijextreem code;J\n&#39;)
        f.write(&#39;MXC;1;10;Oppervlaktewater\n&#39;)
        f.write(&#39;MXE;1;T;DIMSLS\n&#39;)
        f.write(&#39;MXH;1;NVT;Niet van toepassing\n&#39;)
        f.write(&#39;MXO;1;NVT;Niet van toepassing\n&#39;)
        f.write(&#39;MXS;1;NVT\n&#39;)
        f.write(&#39;MXW;2;%i\n&#39;%(waarnemingssoort))
        f.write(&#39;MXP;2;WATHTBRKD;Waterhoogte berekend;J\n&#39;)
        f.write(&#39;MXC;2;10;Oppervlaktewater\n&#39;)
        f.write(&#39;MXE;2;I;cm\n&#39;)
        f.write(&#39;MXH;2;%s;%s\n&#39;%(vertref, vertreflong))
        f.write(&#39;MXO;2;NVT;Niet van toepassing\n&#39;)
        f.write(&#39;MXS;2;NVT\n&#39;)
        f.write(&#39;[TYP]\n&#39;)
        f.write(&#39;TVL;1;1;hoogwater\n&#39;)
        f.write(&#39;TVL;1;2;laagwater\n&#39;)
        f.write(&#39;TVL;1;3;laagwater 1\n&#39;)
        f.write(&#39;TVL;1;4;topagger\n&#39;)
        f.write(&#39;TVL;1;5;laagwater 2\n&#39;)
        f.write(&#39;[RKS]\n&#39;)
        f.write(&#39;TYD;%6s;%4s;%6s;%4s\n&#39;%(data_HWLW.index[0].strftime(&#39;%Y%m%d&#39;),data_HWLW.index[0].strftime(&#39;%H%M&#39;),data_HWLW.index[-1].strftime(&#39;%Y%m%d&#39;),data_HWLW.index[-1].strftime(&#39;%H%M&#39;)))
        f.write(&#39;SYS;CENT\n&#39;)
        f.write(&#39;[TPS]\n&#39;)
        f.write(&#39;STA;%6s;%4s;%6s;%4s;O\n&#39;%(data_HWLW.index[0].strftime(&#39;%Y%m%d&#39;),data_HWLW.index[0].strftime(&#39;%H%M&#39;),data_HWLW.index[-1].strftime(&#39;%Y%m%d&#39;),data_HWLW.index[-1].strftime(&#39;%H%M&#39;)))
        f.write(&#39;[WRD]\n&#39;)

        for index,data_pd_row in data_HWLW.iterrows():
            f.write(&#39;%6s;%4s;%d/0;%d:\n&#39;%(index.strftime(&#39;%Y%m%d&#39;), index.strftime(&#39;%H%M&#39;), data_pd_row[&#39;HWLWcode&#39;], data_pd_row[&#39;values&#39;]*100))</code></pre>
</details>
</dd>
<dt id="hatyan.timeseries.crop_timeseries"><code class="name flex">
<span>def <span class="ident">crop_timeseries</span></span>(<span>ts, times_ext)</span>
</code></dt>
<dd>
<div class="desc"><p>Crops the provided timeseries</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>ts</code></strong> :&ensp;<code>pandas.DataFrame</code></dt>
<dd>The DataFrame should contain a 'values' column and a pd.DatetimeIndex as index, it contains the timeseries.</dd>
<dt><strong><code>times_ext</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>DESCRIPTION.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>Exception</code></dt>
<dd>DESCRIPTION.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>ts_pd_out</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>DESCRIPTION.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def crop_timeseries(ts, times_ext):
    &#34;&#34;&#34;
    Crops the provided timeseries

    Parameters
    ----------
    ts : pandas.DataFrame
        The DataFrame should contain a &#39;values&#39; column and a pd.DatetimeIndex as index, it contains the timeseries.
    times_ext : TYPE
        DESCRIPTION.

    Raises
    ------
    Exception
        DESCRIPTION.

    Returns
    -------
    ts_pd_out : TYPE
        DESCRIPTION.

    &#34;&#34;&#34;
    ts_pd_in = ts
    
    print(&#39;-&#39;*100)
    print(&#39;cropping timeseries&#39;)
    if not times_ext[0]&lt;times_ext[1]:
        raise Exception(&#39;ERROR: the two times times_ext should be increasing, but they are not: %s.&#39;%(times_ext))
    if (times_ext[0] &lt; ts_pd_in.index[0]) or (times_ext[-1] &gt; ts_pd_in.index[-1]):
        raise Exception(&#39;ERROR: imported timeseries is not available within entire requested period:\nrequested period:    %s to %s\nimported timeseries: %s to %s\nNOTE: if te requested period does not correspond with the one provided in the configfile, try setting analysis_peryear=None&#39;%(times_ext[0],times_ext[-1],ts_pd_in.index.iloc[0],ts_pd_in.index.iloc[-1]))
    
    times_selected_bool = (ts_pd_in.index &gt;= times_ext[0]) &amp; (ts_pd_in.index &lt;= times_ext[-1])
    ts_pd_out = ts_pd_in.loc[times_selected_bool]
    
    check_ts(ts_pd_out)
    return ts_pd_out</code></pre>
</details>
</dd>
<dt id="hatyan.timeseries.resample_timeseries"><code class="name flex">
<span>def <span class="ident">resample_timeseries</span></span>(<span>ts, timestep_min)</span>
</code></dt>
<dd>
<div class="desc"><p>resamples the provided timeseries, only overlapping timesteps are selected, so no interpolation</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>ts</code></strong> :&ensp;<code>pandas.DataFrame</code></dt>
<dd>The DataFrame should contain a 'values' and 'HWLW_code' column and a pd.DatetimeIndex as index, it contains the timeseries to be resampled.</dd>
<dt><strong><code>timestep_min</code></strong> :&ensp;<code>int</code></dt>
<dd>the amount of minutes with which to resample the timeseries.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>data_pd_resample</code></strong> :&ensp;<code>pandas.DataFrame with a 'values' column and a pd.DatetimeIndex as index</code></dt>
<dd>the resampled timeseries.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def resample_timeseries(ts, timestep_min):
    &#34;&#34;&#34;
    resamples the provided timeseries, only overlapping timesteps are selected, so no interpolation

    Parameters
    ----------
    ts : pandas.DataFrame
        The DataFrame should contain a &#39;values&#39; and &#39;HWLW_code&#39; column and a pd.DatetimeIndex as index, it contains the timeseries to be resampled.
    timestep_min : int
        the amount of minutes with which to resample the timeseries.

    Returns
    -------
    data_pd_resample : pandas.DataFrame with a &#39;values&#39; column and a pd.DatetimeIndex as index
        the resampled timeseries.

    &#34;&#34;&#34;
    
    import pandas as pd
    import numpy as np
    
    print(&#39;-&#39;*100)
    print(&#39;resampling timeseries to %i mintues&#39;%(timestep_min))
    data_pd_resample = pd.DataFrame({},index=pd.date_range(ts.index[0],ts.index[-1],freq=&#39;%dmin&#39;%(timestep_min)))
    data_pd_resample[&#39;values&#39;] = np.nan
    id_allinmeas = ts.index.isin(data_pd_resample.index)
    id_measinall = data_pd_resample.index.isin(ts.index)
    data_pd_resample.loc[id_measinall,&#39;values&#39;] = ts.loc[id_allinmeas,&#39;values&#39;].values
    
    
    check_ts(data_pd_resample)
    return data_pd_resample</code></pre>
</details>
</dd>
<dt id="hatyan.timeseries.check_ts"><code class="name flex">
<span>def <span class="ident">check_ts</span></span>(<span>ts)</span>
</code></dt>
<dd>
<div class="desc"><p>prints several statistics of the provided timeseries</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>ts</code></strong> :&ensp;<code>pandas.DataFrame</code></dt>
<dd>The DataFrame should contain a 'values' column and a pd.DatetimeIndex as index, it contains the timeseries to be checked.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>print_statement</code></strong> :&ensp;<code>str</code></dt>
<dd>For printing as a substring of another string.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_ts(ts):
    &#34;&#34;&#34;
    prints several statistics of the provided timeseries

    Parameters
    ----------
    ts : pandas.DataFrame
        The DataFrame should contain a &#39;values&#39; column and a pd.DatetimeIndex as index, it contains the timeseries to be checked.

    Returns
    -------
    print_statement: str
        For printing as a substring of another string.

    &#34;&#34;&#34;
    import numpy as np
    
    timesteps_min_all = ts.index.to_series().diff()[1:].dt.total_seconds()/60
    bool_int = (timesteps_min_all-timesteps_min_all.round(0))&lt;1e-9
    if bool_int.all():
        timesteps_min_all = timesteps_min_all.astype(int)
    else: #in case of non integer minute timesteps (eg seconds)
        timesteps_min_all[bool_int] = timesteps_min_all[bool_int].round(0)
    timesteps_min = set(timesteps_min_all)
    #print(timesteps_min)
    if len(timesteps_min)&lt;=100:
        timesteps_min_print = timesteps_min
    else:
        timesteps_min_print = &#39;too much unique timesteps (&gt;100) to display all of them, %i timesteps ranging from %i to %i minutes&#39;%(len(timesteps_min),np.min(list(timesteps_min)),np.max(list(timesteps_min)))
    if (timesteps_min_all&gt;0).all():
        timesteps_incr_print = &#39;all timesteps are in increasing order and are never equal&#39;
    else:
        timesteps_incr_print = &#39;the times-order of ts is not always increasing (duplicate values or wrong order)&#39;
        
    list_statements = [&#39;timeseries contents:\n%s&#39;%(ts),
                       &#39;timeseries # unique timesteps: %i&#39;%(len(timesteps_min)),
                       &#39;timeseries unique timesteps (minutes):\n%s&#39;%(timesteps_min_print),
                       &#39;timeseries validity: %s&#39;%(timesteps_incr_print),
                       &#39;timeseries length: %i&#39;%(len(ts)),
                       &#39;timeseries # nonan: %i&#39;%(ts[&#39;values&#39;].count()),
                       &#39;timeseries %% nonan: %.1f%%&#39;%(ts[&#39;values&#39;].count()/len(ts)*100),
                       &#39;timeseries # nan: %i&#39;%(len(ts)-ts[&#39;values&#39;].count()),
                       &#39;timeseries %% nan: %.1f%%&#39;%((len(ts)-ts[&#39;values&#39;].count())/len(ts)*100)]
    print_statement = &#39;\n&#39;.join(list_statements)
    print(print_statement)
    
    return print_statement</code></pre>
</details>
</dd>
<dt id="hatyan.timeseries.get_diablocks_startstopstation"><code class="name flex">
<span>def <span class="ident">get_diablocks_startstopstation</span></span>(<span>filename)</span>
</code></dt>
<dd>
<div class="desc"><p>Gets information about the data blocks present in a dia file</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filename</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>DESCRIPTION.</dd>
<dt><strong><code>station</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>DESCRIPTION.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>Exception</code></dt>
<dd>DESCRIPTION.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>block_starts</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>DESCRIPTION.</dd>
<dt><strong><code>data_starts</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>DESCRIPTION.</dd>
<dt><strong><code>data_ends</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>DESCRIPTION.</dd>
<dt><strong><code>block_stations</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>DESCRIPTION.</dd>
<dt><strong><code>block_id</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>DESCRIPTION.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_diablocks_startstopstation(filename):
    &#34;&#34;&#34;
    Gets information about the data blocks present in a dia file

    Parameters
    ----------
    filename : TYPE
        DESCRIPTION.
    station : TYPE
        DESCRIPTION.

    Raises
    ------
    Exception
        DESCRIPTION.

    Returns
    -------
    block_starts : TYPE
        DESCRIPTION.
    data_starts : TYPE
        DESCRIPTION.
    data_ends : TYPE
        DESCRIPTION.
    block_stations : TYPE
        DESCRIPTION.
    block_id : TYPE
        DESCRIPTION.

    &#34;&#34;&#34;
    import pandas as pd
    
    #get list of starts/ends of datasets in diafile
    print(&#39;-&#39;*100)
    print(&#39;reading file: %s&#39;%(filename))
    linenum_colnames = [&#39;block_starts&#39;,&#39;data_starts&#39;,&#39;data_ends&#39;]
    diablocks_pd_startstopstation = pd.DataFrame({},columns=linenum_colnames)
    
    with open(filename, encoding=&#39;latin1&#39;) as f: #&#39;latin1 is nodig om predictie diafile die rechtstreeks uit hatyan komen in te lezen (validatietijdserie met op regel 4 (PAR) ongeldige tekens aan het einde)
        block_id = -1
        for linenum, line in enumerate(f, 1):
            if linenum == 1:
                if not &#39;[IDT;*DIF*;A;&#39; in line:
                    raise Exception(&#39;ERROR: not a valid dia-file, first line should contain &#34;[IDT;*DIF*;A;&#34;&#39;)
            if &#39;[W3H]&#39; in line:
                block_id += 1
                diablocks_pd_startstopstation.loc[block_id,&#39;block_starts&#39;] = linenum
            elif &#39;[WRD]&#39; in line:
                diablocks_pd_startstopstation.loc[block_id,&#39;data_starts&#39;] = linenum
            elif &#39;LOC&#39; in line:
                diablocks_pd_startstopstation.loc[block_id,&#39;station&#39;] = line.rstrip().split(&#39;;&#39;)[1]
    diablocks_pd_startstopstation[&#39;data_ends&#39;] = (diablocks_pd_startstopstation[&#39;block_starts&#39;]-1).tolist()[1:]+[linenum]
    if diablocks_pd_startstopstation.isnull().any().any():
        raise Exception(&#39;ERROR: multiple blocks in diafile, but unequal amount of start/end/datastart/stationnames&#39;)
    
    #convert columns with line numbers to integers
    diablocks_pd_startstopstation[linenum_colnames] = diablocks_pd_startstopstation[linenum_colnames].astype(int)
        
    return diablocks_pd_startstopstation</code></pre>
</details>
</dd>
<dt id="hatyan.timeseries.get_diablocks"><code class="name flex">
<span>def <span class="ident">get_diablocks</span></span>(<span>filename)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_diablocks(filename):
    import datetime as dt
    import numpy as np
    import pandas as pd
    
    mincontent_equidistant = [&#39;PAR&#39;,&#39;LOC&#39;,&#39;HDH&#39;,&#39;TYD&#39;]
    mincontent_nonequidistant = [&#39;MUX&#39;,&#39;LOC&#39;,&#39;MXH;2&#39;]
    getpossible = mincontent_equidistant+mincontent_nonequidistant
    
    diablocks_pd_startstopstation = get_diablocks_startstopstation(filename)
    diablocks_pd = diablocks_pd_startstopstation.copy()
    for block_id in diablocks_pd.index.tolist():
        data_meta_nrows = diablocks_pd.loc[block_id,&#39;data_starts&#39;] - diablocks_pd.loc[block_id,&#39;block_starts&#39;]
        data_meta_pd = pd.read_csv(filename,skiprows=diablocks_pd.loc[block_id,&#39;block_starts&#39;],nrows=data_meta_nrows,sep=&#39;;&#39;,names=range(7),header=None)
        for get_content_sel in getpossible:
            bool_mincontent = data_meta_pd[0]==get_content_sel
            if bool_mincontent.any(): #if get_content_sel available in diafile
                id_mincontent = np.where(bool_mincontent)[0][0]
                if get_content_sel in [&#39;PAR&#39;,&#39;MUX&#39;]:
                    pardef = data_meta_pd.loc[id_mincontent,0]
                    file_parametername = data_meta_pd.loc[id_mincontent,1]
                    if pardef == &#39;PAR&#39;:
                        valid_parameternames = [&#39;WATHTE&#39;,&#39;WATHTBRKD&#39;]
                    else:
                        valid_parameternames = [&#39;GETETBRKD2&#39;,&#39;GETETBRKDMSL2&#39;,&#39;GETETM2&#39;]
                    if not file_parametername in valid_parameternames:
                        raise Exception(&#39;ERROR: parameter name (%s) should be in %s but is %s&#39;%(pardef, valid_parameternames, file_parametername))
                    diablocks_pd.loc[block_id,&#39;parameter&#39;] = file_parametername
                elif get_content_sel in [&#39;LOC&#39;]:
                    file_station_coord_pd = data_meta_pd.loc[id_mincontent,4:6]
                    if file_station_coord_pd.isnull().any():
                        print(&#39;no coordinate data available in LOC line of dia file&#39;)
                    else:
                        file_station_coord = file_station_coord_pd.tolist()
                        if file_station_coord[0] == &#39;RD&#39;:
                            epsg_in = 28992
                            factor = 100
                        elif file_station_coord[0] == &#39;W84&#39;:
                            print(&#39;WARNING: diafile contains W84(epsg:4326) coordinate, correctness is unsure&#39;)
                            epsg_in = 4326
                            factor = 1000000
                        elif file_station_coord[0] == &#39;E50&#39;:
                            print(&#39;WARNING: diafile contains E50(epsg:4230) coordinate, correctness is unsure&#39;)
                            epsg_in = 4230
                            factor = 1000000
                        else:
                            raise Exception(&#39;unknown coordinate system in diafile&#39;)
                        diablocks_pd.loc[block_id,&#39;x&#39;] = int(file_station_coord[1])/factor
                        diablocks_pd.loc[block_id,&#39;y&#39;] = int(file_station_coord[2])/factor
                        diablocks_pd.loc[block_id,&#39;coordsys&#39;] = file_station_coord[0]
                        diablocks_pd.loc[block_id,&#39;epsg&#39;] = epsg_in
                elif get_content_sel in [&#39;HDH&#39;,&#39;MXH;2&#39;]:
                    if get_content_sel in [&#39;HDH&#39;]:
                        file_vertref = data_meta_pd.loc[id_mincontent,1]
                    else:
                        file_vertref = data_meta_pd.loc[id_mincontent,2]
                    diablocks_pd.loc[block_id,&#39;vertref&#39;] = file_vertref
                    print(&#39;the vertical reference level in the imported file is: %s&#39;%(file_vertref))
                    if not isinstance(file_vertref,str): #in case of nan value
                        raise Exception(&#39;ERROR: the imported file does not have a vertical reference in the metadata&#39;)
                elif get_content_sel in [&#39;TYD&#39;]:
                    datestart = dt.datetime.strptime(data_meta_pd.loc[id_mincontent,1:2].str.cat(), &#34;%Y%m%d%H%M&#34;)
                    datestop = dt.datetime.strptime(data_meta_pd.loc[id_mincontent,3:4].str.cat(), &#34;%Y%m%d%H%M&#34;)
                    timestep_value_raw = data_meta_pd.loc[id_mincontent,5]
                    if isinstance(timestep_value_raw,str): #if equidistant timeseries
                        timestep_value = int(timestep_value_raw)
                        timestep_unit = data_meta_pd.loc[id_mincontent,6]
                        if timestep_unit != &#39;min&#39;:
                            raise Exception(&#39;ERROR: time unit from TYD is in unknown format (not &#34;min&#34;)&#39;)
                    else: #when nan
                        timestep_value = timestep_value_raw
                    diablocks_pd.loc[block_id,&#39;tstart&#39;] = datestart
                    diablocks_pd.loc[block_id,&#39;tstop&#39;] = datestop
                    diablocks_pd.loc[block_id,&#39;timestep_min&#39;] = timestep_value
            
    print_cols = [&#39;block_starts&#39;, &#39;station&#39;, &#39;parameter&#39;, &#39;tstart&#39;, &#39;tstop&#39;]
    print(&#39;blocks in diafile:\n%s&#39;%(diablocks_pd[print_cols]))    
    return diablocks_pd</code></pre>
</details>
</dd>
<dt id="hatyan.timeseries.convertcoordinates"><code class="name flex">
<span>def <span class="ident">convertcoordinates</span></span>(<span>coordx_in, coordy_in, epsg_in, epsg_out=28992)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def convertcoordinates(coordx_in, coordy_in, epsg_in, epsg_out=28992):
    from pyproj import Transformer

    epsg_dict = {&#39;RD&#39;:28992,&#39;W84&#39;:4326,&#39;E50&#39;:4230}
    
    if isinstance(epsg_in,str):
        if not epsg_in in epsg_dict.keys():
            raise Exception(&#39;when providing epsg_in as a string, the options are: %s&#39;%(list(epsg_dict.keys())))
        else:
            epsgcode_in = epsg_dict[epsg_in]
    else:
        epsgcode_in = epsg_in
    
    if isinstance(epsg_out,str):
        if not epsg_out in epsg_dict.keys():
            raise Exception(&#39;when providing epsg_out as a string, the options are: %s&#39;%(list(epsg_dict.keys())))
        else:
            epsgcode_out = epsg_dict[epsg_out]
    else:
        epsgcode_out = epsg_out
        
    transformer = Transformer.from_crs(&#39;epsg:%i&#39;%(epsgcode_in), &#39;epsg:%i&#39;%(epsgcode_out), always_xy=True)
    coordx_out, coordy_out = transformer.transform(coordx_in, coordy_in)
    
    return coordx_out, coordy_out</code></pre>
</details>
</dd>
<dt id="hatyan.timeseries.readts_dia_nonequidistant"><code class="name flex">
<span>def <span class="ident">readts_dia_nonequidistant</span></span>(<span>filename, diablocks_pd, block_id)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def readts_dia_nonequidistant(filename, diablocks_pd, block_id):
    import numpy as np
    import pandas as pd

    data_nrows = diablocks_pd.loc[block_id,&#39;data_ends&#39;] - diablocks_pd.loc[block_id,&#39;data_starts&#39;]
    data_pd_HWLW = pd.read_csv(filename,skiprows=diablocks_pd.loc[block_id,&#39;data_starts&#39;],nrows=data_nrows, header=None, names=[&#39;date&#39;,&#39;time&#39;,&#39;HWLWcode/qualitycode&#39;,&#39;valuecm:&#39;], sep=&#39;;&#39;, parse_dates={&#39;times&#39;:[0,1]})
    
    #convert HWLW+quality code to separate columns
    data_pd_HWLWtemp = data_pd_HWLW.loc[:,&#39;HWLWcode/qualitycode&#39;].str.split(&#39;/&#39;, expand=True)
    data_pd_HWLW[&#39;HWLWcode&#39;] = data_pd_HWLWtemp.iloc[:,0].astype(&#39;int&#39;)
    data_pd_HWLW[&#39;qualitycode&#39;] = data_pd_HWLWtemp.iloc[:,1].astype(&#39;int&#39;)
    data_pd_HWLW = data_pd_HWLW.drop(&#39;HWLWcode/qualitycode&#39;,axis=&#39;columns&#39;)

    #convert value from cm to m
    data_pd_HWLW[&#39;values&#39;] = data_pd_HWLW[&#39;valuecm:&#39;].str.strip(&#39;:&#39;).astype(&#39;int&#39;)/100
    data_pd_HWLW = data_pd_HWLW.drop(&#39;valuecm:&#39;,axis=&#39;columns&#39;)
    
    bool_hiaat = data_pd_HWLW[&#39;qualitycode&#39;] == 99
    data_pd_HWLW.loc[bool_hiaat,&#39;values&#39;] = np.nan
    
    data_pd = data_pd_HWLW
    data_pd = data_pd.set_index(&#39;times&#39;)
    
    return data_pd</code></pre>
</details>
</dd>
<dt id="hatyan.timeseries.readts_dia_equidistant"><code class="name flex">
<span>def <span class="ident">readts_dia_equidistant</span></span>(<span>filename, diablocks_pd_extra, block_id)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def readts_dia_equidistant(filename, diablocks_pd_extra, block_id):
    import numpy as np
    import pandas as pd
    
    diablocks_pd = diablocks_pd_extra
    
    datestart = diablocks_pd_extra.loc[block_id,&#39;tstart&#39;]
    datestop = diablocks_pd_extra.loc[block_id,&#39;tstop&#39;]
    timestep_min = diablocks_pd_extra.loc[block_id,&#39;timestep_min&#39;]
    times_fromfile = pd.date_range(start=datestart,end=datestop,freq=&#39;%dmin&#39;%(timestep_min))
    
    #get data for station
    data_nrows = diablocks_pd.loc[block_id,&#39;data_ends&#39;] - diablocks_pd.loc[block_id,&#39;data_starts&#39;]
    data_pd = pd.read_csv(filename,skiprows=diablocks_pd.loc[block_id,&#39;data_starts&#39;],nrows=data_nrows, header=None)
    data_pdser = data_pd[0].str.strip()
    data = data_pdser.str.cat()
    data = data.strip(&#39;:&#39;) #remove first and/or last colon if present
    data = data.split(&#39;:&#39;)
    
    if len(times_fromfile) != len(data):
        raise Exception(&#39;ERROR: times and values ts are not of equal length\nlen(times_fromfile): %d\nlen(data): %d&#39;%(len(times_fromfile),len(data)))
    data_pd = pd.DataFrame({&#39;times&#39;:times_fromfile,&#39;valuecm/qualitycode&#39;:data})
    
    #convert HWLW+quality code to separate columns
    data_pd_temp = data_pd.loc[:,&#39;valuecm/qualitycode&#39;].str.split(&#39;/&#39;, expand=True)
    data_pd[&#39;values&#39;] = data_pd_temp.iloc[:,0].astype(&#39;int&#39;)/100
    data_pd[&#39;qualitycode&#39;] = data_pd_temp.iloc[:,1].astype(&#39;int&#39;)
    data_pd = data_pd.drop(&#39;valuecm/qualitycode&#39;,axis=&#39;columns&#39;)

    bool_hiaat = data_pd[&#39;qualitycode&#39;] == 99
    data_pd.loc[bool_hiaat,&#39;values&#39;] = np.nan
    data_pd = data_pd.set_index(&#39;times&#39;)
    
    return data_pd</code></pre>
</details>
</dd>
<dt id="hatyan.timeseries.readts_dia"><code class="name flex">
<span>def <span class="ident">readts_dia</span></span>(<span>filename, station=None, block_ids=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Reads an equidistant or non-equidistant dia file, or a list of dia files. Also works for diafiles containing multiple blocks for one station.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filename</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>DESCRIPTION.</dd>
<dt><strong><code>station</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>DESCRIPTION. The default is None.</dd>
<dt><strong><code>block_ids</code></strong> :&ensp;<code>int, list</code> of <code>int</code> or <code>'allstation'</code>, optional</dt>
<dd>DESCRIPTION. The default is None.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>Exception</code></dt>
<dd>DESCRIPTION.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>data_pd</code></strong> :&ensp;<code>pandas.core.frame.DataFrame</code></dt>
<dd>DataFrame with a 'values' column and a pd.DatetimeIndex as index in case of an equidistant file, or more columns in case of a non-equidistant file.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def readts_dia(filename, station=None, block_ids=None):
    &#34;&#34;&#34;
    Reads an equidistant or non-equidistant dia file, or a list of dia files. Also works for diafiles containing multiple blocks for one station.

    Parameters
    ----------
    filename : TYPE
        DESCRIPTION.
    station : TYPE
        DESCRIPTION. The default is None.
    block_ids : int, list of int or &#39;allstation&#39;, optional
        DESCRIPTION. The default is None.

    Raises
    ------
    Exception
        DESCRIPTION.

    Returns
    -------
    data_pd : pandas.core.frame.DataFrame
        DataFrame with a &#39;values&#39; column and a pd.DatetimeIndex as index in case of an equidistant file, or more columns in case of a non-equidistant file.

    &#34;&#34;&#34;
 

    import pandas as pd
    import numpy as np
    
    if type(filename) is list:
        filename_list = filename
        data_pd_all = pd.DataFrame()
        for iF, filename_one in enumerate(filename_list):
            data_pd_one = readts_dia(filename=filename_one, station=station) #call itself with one file from list
            #append to allyears dataset
            data_pd_all = data_pd_all.append(data_pd_one, ignore_index=False)
        #check overlapping timesteps
        if len(data_pd_all) != len(data_pd_all.index.unique()):
            raise Exception(&#39;ERROR: merged datasets have duplicate/overlapping timesteps, clean up your input data or provide one file instead of a list&#39;)
        data_pd = data_pd_all

    else:
        diablocks_pd = get_diablocks(filename)
        str_getdiablockspd = &#39;A summary of the available blocks is printed above, obtain a full DataFrame of available diablocks with &#34;diablocks_pd=Timeseries.get_diablocks(filename)&#34;&#39;
        #get equidistant timeseries from metadata
        if block_ids is None or block_ids==&#39;allstation&#39;:
            if station is None:
                raise Exception(&#39;ERROR: if block_ids argument is not provided (or None) or is &#34;allstation&#34;, station argument should be provided.&#39;)
            bool_station = diablocks_pd[&#39;station&#39;]==station
            ids_station = diablocks_pd[bool_station].index.tolist()
            if len(ids_station)&lt;1:
                raise Exception(&#39;ERROR: no data block with requested station (%s) present in dia file. %s&#39;%(station, str_getdiablockspd))
            elif len(ids_station)&gt;1 and block_ids is None:
                    raise Exception(&#39;ERROR: more than one data block with requested station (%s) present in dia file. Provide block_ids argument to readts_dia() (int, list of int or &#34;allstation&#34;). %s&#39;%(station, str_getdiablockspd))
            else: #exactly one occurrence or block_ids is provided
                block_ids = ids_station
        
        elif isinstance(block_ids,int):
            block_ids = [block_ids]
        elif isinstance(block_ids,list):
            pass #this is a valid input type
        else:
            raise Exception(&#39;ERROR: invalid type for block_ids (should be int, list of int or &#34;allstation&#34;)&#39;)
        
        #check validity of blockids of type listlist
        if not all(isinstance(x, int) for x in block_ids):
            raise Exception(&#39;ERROR: invalid type in block_ids list, should all be of type int&#39;)
        if np.max(block_ids)&gt;len(diablocks_pd)-1:
            raise Exception(&#39;ERROR: invalid values in block_ids list, possible are %s&#39;%(diablocks_pd.index.tolist()))
        if np.min(block_ids)&lt;0:
            raise Exception(&#39;ERROR: values in block_ids list should all be positive&#39;)
            
        if station is not None:
            if not isinstance(station,str):
                raise Exception(&#39;ERROR: station argument should be of type string&#39;)
            bool_samestation = diablocks_pd.loc[block_ids,&#39;station&#39;]==station
            if not bool_samestation.all():
                raise Exception(&#39;ERROR: both the arguments station and block_ids are provided, but at least one of the requested block_ids corresponds to a different station. %s&#39;%(str_getdiablockspd))
            
        data_pd_allblocks = pd.DataFrame()
        for block_id in block_ids:
            if np.isnan(diablocks_pd.loc[block_id,&#39;timestep_min&#39;]): #non-equidistant
                data_pd_oneblock = readts_dia_nonequidistant(filename, diablocks_pd, block_id)
            else: #equidistant
                data_pd_oneblock = readts_dia_equidistant(filename, diablocks_pd, block_id)
            check_ts(data_pd_oneblock)
            data_pd_allblocks = data_pd_allblocks.append(data_pd_oneblock, ignore_index=False)
        data_pd = data_pd_allblocks

    #sort values on time
    data_pd = data_pd.sort_index(axis=0)
    
    check_ts(data_pd)
    return data_pd</code></pre>
</details>
</dd>
<dt id="hatyan.timeseries.readts_dia_HWLW"><code class="name flex">
<span>def <span class="ident">readts_dia_HWLW</span></span>(<span>filename, station)</span>
</code></dt>
<dd>
<div class="desc"><p>Reads a non-equidistant dia file (wrapper around readts_dia). This definition will be phased out.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def readts_dia_HWLW(filename, station):
    &#34;&#34;&#34;
    Reads a non-equidistant dia file (wrapper around readts_dia). This definition will be phased out.

    &#34;&#34;&#34;
    raise Exception(&#39;ERROR: readts_dia_HWLW() was phased out, use readts_dia() instead&#39;)</code></pre>
</details>
</dd>
<dt id="hatyan.timeseries.readts_noos"><code class="name flex">
<span>def <span class="ident">readts_noos</span></span>(<span>filename, datetime_format='%Y%m%d%H%M', na_values=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Reads a noos file</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filename</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>DESCRIPTION.</dd>
<dt><strong><code>datetime_format</code></strong> :&ensp;<code>TYPE</code>, optional</dt>
<dd>DESCRIPTION. The default is '%Y%m%d%H%M'.</dd>
<dt><strong><code>na_values</code></strong> :&ensp;<code>TYPE</code>, optional</dt>
<dd>DESCRIPTION. The default is None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>data_pd</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>DESCRIPTION.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def readts_noos(filename, datetime_format=&#39;%Y%m%d%H%M&#39;, na_values=None):
    &#34;&#34;&#34;
    Reads a noos file

    Parameters
    ----------
    filename : TYPE
        DESCRIPTION.
    datetime_format : TYPE, optional
        DESCRIPTION. The default is &#39;%Y%m%d%H%M&#39;.
    na_values : TYPE, optional
        DESCRIPTION. The default is None.

    Returns
    -------
    data_pd : TYPE
        DESCRIPTION.

    &#34;&#34;&#34;
    import pandas as pd
    
    print(&#39;-&#39;*100)
    print(&#39;reading file: %s&#39;%(filename))
    noosheader = []
    noosheader_dict = {}
    with open(filename) as f:
        for linenum, line in enumerate(f, 0):
            if &#39;#&#39; in line:
                noosheader.append(line)
                comment_stripped = line.strip(&#39;#&#39;).strip().split(&#39;: &#39;)
                if len(comment_stripped) == 1:
                    if comment_stripped[0] != &#39;&#39;:
                        noosheader_dict[comment_stripped[0]] = &#39;&#39;
                else:
                    noosheader_dict[comment_stripped[0].strip()] = comment_stripped[1].strip()
            else:
                startdata = linenum
                break
    
    content_pd = pd.read_csv(filename,header=startdata-1,delim_whitespace=True,names=[&#39;times_str&#39;,&#39;values&#39;], na_values=na_values)
    noos_datetime = pd.to_datetime(content_pd[&#39;times_str&#39;],format=datetime_format)
    data_pd = pd.DataFrame({&#39;values&#39;:content_pd[&#39;values&#39;].values},index=noos_datetime)
    
    check_ts(data_pd)
    return data_pd</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="hatyan" href="index.html">hatyan</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="hatyan.timeseries.calc_HWLW" href="#hatyan.timeseries.calc_HWLW">calc_HWLW</a></code></li>
<li><code><a title="hatyan.timeseries.calc_HWLWnumbering" href="#hatyan.timeseries.calc_HWLWnumbering">calc_HWLWnumbering</a></code></li>
<li><code><a title="hatyan.timeseries.timeseries_fft" href="#hatyan.timeseries.timeseries_fft">timeseries_fft</a></code></li>
<li><code><a title="hatyan.timeseries.plot_timeseries" href="#hatyan.timeseries.plot_timeseries">plot_timeseries</a></code></li>
<li><code><a title="hatyan.timeseries.plot_HWLW_validatestats" href="#hatyan.timeseries.plot_HWLW_validatestats">plot_HWLW_validatestats</a></code></li>
<li><code><a title="hatyan.timeseries.write_tsnetcdf" href="#hatyan.timeseries.write_tsnetcdf">write_tsnetcdf</a></code></li>
<li><code><a title="hatyan.timeseries.write_tsdia" href="#hatyan.timeseries.write_tsdia">write_tsdia</a></code></li>
<li><code><a title="hatyan.timeseries.write_tsdia_HWLW" href="#hatyan.timeseries.write_tsdia_HWLW">write_tsdia_HWLW</a></code></li>
<li><code><a title="hatyan.timeseries.crop_timeseries" href="#hatyan.timeseries.crop_timeseries">crop_timeseries</a></code></li>
<li><code><a title="hatyan.timeseries.resample_timeseries" href="#hatyan.timeseries.resample_timeseries">resample_timeseries</a></code></li>
<li><code><a title="hatyan.timeseries.check_ts" href="#hatyan.timeseries.check_ts">check_ts</a></code></li>
<li><code><a title="hatyan.timeseries.get_diablocks_startstopstation" href="#hatyan.timeseries.get_diablocks_startstopstation">get_diablocks_startstopstation</a></code></li>
<li><code><a title="hatyan.timeseries.get_diablocks" href="#hatyan.timeseries.get_diablocks">get_diablocks</a></code></li>
<li><code><a title="hatyan.timeseries.convertcoordinates" href="#hatyan.timeseries.convertcoordinates">convertcoordinates</a></code></li>
<li><code><a title="hatyan.timeseries.readts_dia_nonequidistant" href="#hatyan.timeseries.readts_dia_nonequidistant">readts_dia_nonequidistant</a></code></li>
<li><code><a title="hatyan.timeseries.readts_dia_equidistant" href="#hatyan.timeseries.readts_dia_equidistant">readts_dia_equidistant</a></code></li>
<li><code><a title="hatyan.timeseries.readts_dia" href="#hatyan.timeseries.readts_dia">readts_dia</a></code></li>
<li><code><a title="hatyan.timeseries.readts_dia_HWLW" href="#hatyan.timeseries.readts_dia_HWLW">readts_dia_HWLW</a></code></li>
<li><code><a title="hatyan.timeseries.readts_noos" href="#hatyan.timeseries.readts_noos">readts_noos</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>