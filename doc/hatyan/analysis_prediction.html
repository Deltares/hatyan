<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>hatyan.analysis_prediction API documentation</title>
<meta name="description" content="analysis_prediction.py contains hatyan definitions related to tidal analysis and prediction â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>hatyan.analysis_prediction</code></h1>
</header>
<section id="section-intro">
<p>analysis_prediction.py contains hatyan definitions related to tidal analysis and prediction. </p>
<p>hatyan is a Python program for tidal analysis and prediction, based on the FORTRAN version.
Copyright (C) 2019-2021 Rijkswaterstaat.
Maintained by Deltares, contact: Jelmer Veenstra (jelmer.veenstra@deltares.nl).
Source code available at: <a href="https://github.com/Deltares/hatyan">https://github.com/Deltares/hatyan</a></p>
<p>This program is free software: you can redistribute it and/or modify
it under the terms of the GNU Lesser General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.</p>
<p>This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
See the
GNU Lesser General Public License for more details.</p>
<p>You should have received a copy of the GNU Lesser General Public License
along with this program.
If not, see <a href="https://www.gnu.org/licenses/">https://www.gnu.org/licenses/</a>.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># -*- coding: utf-8 -*-
&#34;&#34;&#34;
analysis_prediction.py contains hatyan definitions related to tidal analysis and prediction. 

hatyan is a Python program for tidal analysis and prediction, based on the FORTRAN version. 
Copyright (C) 2019-2021 Rijkswaterstaat.  Maintained by Deltares, contact: Jelmer Veenstra (jelmer.veenstra@deltares.nl). 
Source code available at: https://github.com/Deltares/hatyan

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU Lesser General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU Lesser General Public License for more details.

You should have received a copy of the GNU Lesser General Public License
along with this program.  If not, see &lt;https://www.gnu.org/licenses/&gt;.

&#34;&#34;&#34;


def vectoravg(A_all, phi_deg_all):
    &#34;&#34;&#34;
    calculates the vector average of A and phi per constituent, 
    it vector averages over values resulting from multiple periods.
    A regular average is calculated for the amplitude of A0 (middenstand)
    
    Parameters
    ----------
    A_i_all : TYPE
        DESCRIPTION.
    phi_i_deg_all : TYPE
        DESCRIPTION.

    Returns
    -------
    A_i_mean : TYPE
        DESCRIPTION.
    phi_i_deg_mean : TYPE
        DESCRIPTION.

    &#34;&#34;&#34;
    
    import numpy as np
    
    phi_rad_all = np.deg2rad(phi_deg_all)
    v_cos = A_all*np.cos(phi_rad_all)
    v_sin = A_all*np.sin(phi_rad_all)
    mean_v_cos = np.mean(v_cos,axis=1)
    mean_v_sin = np.mean(v_sin,axis=1)
    A_mean = np.sqrt(mean_v_cos**2 + mean_v_sin**2)
    phi_rad_mean = np.arctan2(mean_v_sin,mean_v_cos)
    phi_rad_mean[phi_rad_mean&lt;0] = phi_rad_mean[phi_rad_mean&lt;0]+(2*np.pi)
    
    #if phases of all years are exactly 0, it is the A0 component. Overwrite this A0 with mean amplitude and zero phase if present, otherwise negative values will become positive with 180 phase
    idx_A0 = np.where((phi_deg_all==0).any(axis=1))[0]
    A_mean[idx_A0] = np.mean(A_all[idx_A0,:])
    phi_rad_mean[idx_A0] = 0
    
    phi_deg_mean = np.rad2deg(phi_rad_mean)
    
    return A_mean, phi_deg_mean









def get_components_from_ts(ts, const_list, nodalfactors=True, xfac=False, fu_alltimes=True, CS_comps=None, analysis_peryear=False, analysis_permonth=False, return_allyears=False, source=&#39;schureman&#39;):
    &#34;&#34;&#34;
    Wrapper around the analysis() function, 
    it optionally processes a timeseries per year and vector averages the results afterwards, 
    passes the rest of the arguments on to analysis function
    The timezone of the timeseries, will also be reflected in the phases of the resulting component set, so the resulting component set can be used to make a prediction in the original timezone.
    
    Parameters
    ----------
    ts : pandas.DataFrame
        The DataFrame should contain a &#39;values&#39; column and a pd.DatetimeIndex as index, it contains the timeseries to be analysed, as obtained from e.g. readts_*.
    const_list : list, pandas.Series or str
        list or pandas.Series: contains the tidal constituent names for which to analyse the provided timeseries ts. 
        str: a predefined name of a component set for hatyan_core.get_const_list_hatyan()
    nodalfactors : bool/int, optional
        Whether or not to apply nodal factors. The default is True.
    xfac : bool/int, optional
        Whether or not to apply x-factors. The default is False.
    fu_alltimes : bool/int, optional
        determines whether to calculate nodal factors in middle of analysis period (default) or on every timestep. The default is True.
    analysis_peryear : bool/int, optional
        DESCRIPTION. The default is False.
    analysis_permonth : bool/int, optional
        caution, it tries to analyse each month, but skips it if it fails. analysis_peryear argument has priority. The default is False.
    return_allyears : bool/int, optional
        DESCRIPTION. The default is False.
    CS_comps : pandas.DataFrame, optional
        contains the from/derive component lists for components splitting, as well as the amplitude factor and the increase in degrees. The default is None.

    Raises
    ------
    Exception
        DESCRIPTION.

    Returns
    -------
    COMP_mean_pd : pandas.DataFrame
        The DataFrame contains the component data with component names as index, and colums &#39;A&#39; and &#39;phi_deg&#39;.
    COMP_all_pd : pandas.DataFrame, optional
        The same as COMP_mean_pd, but with all years added with MultiIndex
    &#34;&#34;&#34;
    ts_pd = ts
    
    import pandas as pd
    import numpy as np
    
    from hatyan.analysis_prediction import analysis
    from hatyan.analysis_prediction import vectoravg
    from hatyan.hatyan_core import get_const_list_hatyan
       
    print(&#39;-&#39;*100)
    print(&#39;running: get_components_from_ts&#39;)
    
    if type(const_list) is str:
        const_list = get_const_list_hatyan(const_list)
    elif type(const_list) is not list:
        const_list = const_list.tolist()
    n_const = len(const_list)

    if analysis_peryear or analysis_permonth:
        if analysis_peryear:
            print(&#39;analysis_peryear=True, separate years are automatically determined from unique calendar years in timeseries&#39;)
            ts_years_dt = ts_pd.index.year.unique()
            ts_years = ts_pd.index.year.unique()
        else:
            print(&#39;analysis_permonth=True, separate month/year combinations are automatically determined from unique calendar months/years in timeseries&#39;)
            ts_years_dt = pd.date_range(start=ts_pd.index.iloc[0], end=ts_pd.index.iloc[-1], freq=&#39;M&#39;)
            ts_years = [&#39;%d-%02d&#39;%(x.year,x.month) for x in ts_years_dt]

        n_years = len(ts_years)
        A_i_all = np.zeros((n_const,n_years))
        phi_i_deg_all = np.zeros((n_const,n_years))
        for iY, year_dt in enumerate(ts_years_dt):
            if analysis_peryear:
                print(&#39;analyzing %d of sequence %s&#39;%(year_dt,ts_years))
                ts_oneyear_pd = ts_pd[ts_pd.index.year==year_dt]
                COMP_one = analysis(ts_oneyear_pd, const_list=const_list, nodalfactors=nodalfactors, xfac=xfac, fu_alltimes=fu_alltimes, CS_comps=CS_comps, source=source)
                A_i_all[:,iY] = COMP_one.loc[:,&#39;A&#39;]
                phi_i_deg_all[:,iY] = COMP_one.loc[:,&#39;phi_deg&#39;]
            else:
                print(&#39;analyzing %d-%02d of sequence [%s]&#39;%(year_dt.year, year_dt.month, &#39;, &#39;.join(ts_years)))
                ts_oneyear_pd = ts_pd[(ts_pd.index.dt.year==year_dt.year) &amp; (ts_pd.index.dt.month==year_dt.month)]
                try:
                    COMP_one = analysis(ts_oneyear_pd, const_list=const_list, nodalfactors=nodalfactors, xfac=xfac, fu_alltimes=fu_alltimes, CS_comps=CS_comps, source=source)
                    A_i_all[:,iY] = COMP_one.loc[:,&#39;A&#39;]
                    phi_i_deg_all[:,iY] = COMP_one.loc[:,&#39;phi_deg&#39;]
                except Exception as e:
                    print(&#39;WARNING: analysis of %d-%02d failed, error message: &#34;%s&#39;%(year_dt.year,year_dt.month,e))
        
        COMP_all_pd = pd.DataFrame(data=np.hstack([A_i_all,phi_i_deg_all]), columns=pd.MultiIndex.from_product([[&#39;A&#39;,&#39;phi_deg&#39;],ts_years]), index=COMP_one.index)
        print(&#39;vector averaging analysis results&#39;)
        A_i_mean, phi_i_deg_mean = vectoravg(A_all=A_i_all, phi_deg_all=phi_i_deg_all)
        COMP_mean_pd = pd.DataFrame({ &#39;A&#39;: A_i_mean, &#39;phi_deg&#39;: phi_i_deg_mean},index=COMP_one.index)

    else: #dummy values, COMP_years should be equal to COMP_mean
        COMP_mean_pd = analysis(ts_pd, const_list=const_list, nodalfactors=nodalfactors, xfac=xfac, fu_alltimes=fu_alltimes, CS_comps=CS_comps, source=source)
        COMP_all_pd = None
    
    if return_allyears:
        return COMP_mean_pd, COMP_all_pd
    else:
        return COMP_mean_pd




def analysis(ts, const_list, nodalfactors=True, xfac=False, fu_alltimes=True, CS_comps=None, return_prediction=False, source=&#39;schureman&#39;):
    &#34;&#34;&#34;
    harmonic analysis with matrix transformations (least squares fit), optionally with component splitting
    for details about arguments and return variables, see get_components_from_ts() definition
    
    return_prediction : bool/int, optional
        Whether to generate a prediction for the ts time array. The default is False.
    &#34;&#34;&#34;
    
    import numpy as np
    import pandas as pd
    import datetime as dt
    
    from hatyan.hatyan_core import get_hatyan_freqs, get_hatyan_v0, get_hatyan_u, get_hatyan_f, get_const_list_hatyan, robust_timedelta_sec
    from hatyan.foreman_core import get_foreman_v0_freq, get_foreman_nodalfactors
    from hatyan.timeseries import check_ts
    
    #drop duplicate times
    ts_pd = ts[~ts.index.duplicated(keep=&#39;first&#39;)]
    print(&#39;-&#39;*100)
    print(&#39;ANALYSIS initializing&#39;)
    print(&#39;%-20s = %s&#39;%(&#39;nodalfactors&#39;,nodalfactors))
    print(&#39;%-20s = %s&#39;%(&#39;xfac&#39;,xfac))
    print(&#39;%-20s = %s&#39;%(&#39;fu_alltimes&#39;,fu_alltimes))
    if CS_comps is not None:
        print(&#39;%-20s = %s&#39;%(&#39;CS_comps derive&#39;,CS_comps[&#39;CS_comps_derive&#39;].tolist()))
        print(&#39;%-20s = %s&#39;%(&#39;CS_comps from&#39;,CS_comps[&#39;CS_comps_from&#39;].tolist()))
    else:
        print(&#39;%-20s = %s&#39;%(&#39;CS_comps&#39;, CS_comps))
        
    if len(ts_pd) != len(ts):
        print(&#39;WARNING: %i duplicate times of the input timeseries were dropped prior to the analysis&#39;%(len(ts)-len(ts_pd)))
    
    if type(const_list) is str:
        const_list = get_const_list_hatyan(const_list)
    elif type(const_list) is not list:
        const_list = const_list.tolist()
    
    print(&#39;%-20s = %s&#39;%(&#39;components analyzed&#39;,len(const_list)))
    print(&#39;%-20s = %s&#39;%(&#39;#timesteps&#39;,len(ts)))
    print(&#39;%-20s = %s&#39;%(&#39;tstart&#39;,ts.index[0].strftime(&#39;%Y-%m-%d %H:%M:%S&#39;)))
    print(&#39;%-20s = %s&#39;%(&#39;tstop&#39;,ts.index[-1].strftime(&#39;%Y-%m-%d %H:%M:%S&#39;)))
    if hasattr(ts.index,&#39;freq&#39;):
        print(&#39;%-20s = %s&#39;%(&#39;timestep&#39;,ts.index.freq))
    
    #check for duplicate components (results in singular matrix)
    if len(const_list) != len(np.unique(const_list)):
        const_list_uniq, const_list_uniq_counts = np.unique(const_list,return_counts=True)
        bool_nonuniq = const_list_uniq_counts&gt;1
        const_list_dupl = pd.DataFrame({&#39;constituent&#39;:const_list_uniq[bool_nonuniq],&#39;occurences&#39;:const_list_uniq_counts[bool_nonuniq]})
        raise Exception(&#39;remove duplicate constituents from const_list:\n%s&#39;%(const_list_dupl))
    
    dood_date_mid = pd.Index([ts_pd.index[len(ts_pd.index)//2]]) #middle of analysis period (2july in case of 1jan-1jan), zoals bij hatyan
    dood_date_start = ts_pd.index[:1] #first date (for v0, also freq?)
    
    ts_pd_nonan = ts_pd[~ts_pd[&#39;values&#39;].isna()]
    times_pred_all_pdDTI = pd.DatetimeIndex(ts_pd_nonan.index)
    percentage_nan = 100-len(ts_pd_nonan[&#39;values&#39;])/len(ts_pd[&#39;values&#39;])*100
    print(&#39;percentage_nan in values_meas_sel: %.2f%%&#39;%(percentage_nan))

    #retrieve const_list and frequency in correct order
    t_const_freq_pd = get_hatyan_freqs(const_list)
    const_list = t_const_freq_pd.index.tolist()
    #retrieve again but now with sorted const_list
    t_const_freq_pd, t_const_speed_all = get_hatyan_freqs(const_list, dood_date=dood_date_mid, return_allraw=True)
    t_const_freq = t_const_freq_pd[&#39;freq&#39;]
            
    #check Rayleigh
    freq_diffs = np.diff(t_const_freq)
    rayleigh_tresh = 0.99
    rayleigh = len(ts_pd[&#39;values&#39;])*freq_diffs
    freq_diff_min = rayleigh_tresh/len(ts_pd[&#39;values&#39;])
    rayleigh_bool = rayleigh&gt;rayleigh_tresh
    rayleigh_bool_id = np.where(~rayleigh_bool)[0]
    
    if rayleigh_bool.all():
        print(&#39;Rayleigh criterion OK (always&gt;%.2f, minimum is %.2f)&#39;%(rayleigh_tresh, np.min(rayleigh)))
        print(&#39;Frequencies are far enough apart (always &gt;%.6f, minimum is %.6f)&#39;%(freq_diff_min,np.min(freq_diffs)))
    else:
        print(&#39;Rayleigh criterion vandalised (not always&gt;%.2f, minimum is %.2f)&#39;%(rayleigh_tresh, np.min(rayleigh)))
        print(&#39;Frequencies with not enough difference (not always &gt;%.6f, minimum is %.6f)&#39;%(freq_diff_min,np.min(freq_diffs)))
        for ray_id in rayleigh_bool_id:
            print(t_const_freq.iloc[[ray_id,ray_id+1]])
    
    #get f and v, only needed after matrix calculations
    if source.lower()==&#39;schureman&#39;:
        print(&#39;v0 is calculated for start of period: %s&#39;%(dood_date_start[0]))
        v_0i_rad = get_hatyan_v0(const_list, dood_date_start).T #at start of timeseries
    elif source.lower()==&#39;foreman&#39;:
        print(&#39;v0 is calculated for start of period: %s&#39;%(dood_date_start[0]))
        v_0i_rad, dummy = get_foreman_v0_freq(const_list=const_list, dood_date=dood_date_start)
        v_0i_rad = v_0i_rad.T
    else:
        raise Exception(&#39;invalid source value (schureman or foreman)&#39;)
    
    if nodalfactors:
        if fu_alltimes:
            print(&#39;nodal factors (f and u) are calculated for all timesteps&#39;)
            dood_date_fu = times_pred_all_pdDTI
        else:
            print(&#39;nodal factors (fu) are calculated for center of period: %s&#39;%(dood_date_mid[0]))
            dood_date_fu = dood_date_mid
        if source.lower()==&#39;schureman&#39;:
            f_i = get_hatyan_f(xfac=xfac, const_list=const_list, dood_date=dood_date_fu).T
            u_i_rad = get_hatyan_u(const_list=const_list, dood_date=dood_date_fu).T
        elif source.lower()==&#39;foreman&#39;:
            f_i, u_i_rad = get_foreman_nodalfactors(const_list=const_list, dood_date=dood_date_fu)
            f_i, u_i_rad = f_i.T, u_i_rad.T
    else:
        print(&#39;no nodal factors (fu) are calculated for (f=1, u=0)&#39;)
        f_i = pd.DataFrame(np.ones(len(const_list)),index=const_list).T
        u_i_rad = pd.DataFrame(np.zeros(len(const_list)),index=const_list).T

    v_u = np.add(v_0i_rad.values,u_i_rad.values)
    
    #### TIMESERIES ANALYSIS
    N = len(const_list)
    print(&#39;ANALYSIS start (for %i constituents)&#39;%(N))
    
    #times_from0_s = (pd.DatetimeIndex(ts_pd_nonan.index)-dood_date_start[0]).total_seconds().values
    times_from0_s, fancy_pddt = robust_timedelta_sec(ts_pd_nonan.index,refdate_dt=dood_date_start[0])
    times_from0_s = np.transpose(times_from0_s[np.newaxis])
    
    m = len(ts_pd_nonan[&#39;values&#39;])
    
    # get xmat and make dot product
    xmat = np.zeros((m,2*N))
    omega_i_rads = t_const_speed_all.T/3600 #angular frequency, 2pi/T, in rad/s, https://en.wikipedia.org/wiki/Angular_frequency (2*np.pi)/(1/x*3600) = 2*np.pi*x/3600
    
    xmat[:,:N] = np.multiply(f_i.values,np.cos(np.multiply(omega_i_rads,times_from0_s)+v_u))
    xmat[:,N:] = np.multiply(f_i.values,np.sin(np.multiply(omega_i_rads,times_from0_s)+v_u))
    xmat_len = xmat.shape[1]
    
    xTmat = xmat.T
    print(&#39;calculating xTx matrix&#39;)
    tic = dt.datetime.now()
    xTxmat = np.dot(xTmat,xmat)
    print(&#39;xTx matrix calculated&#39;)
    if &#39;A0&#39; in const_list: #correct center value for better matrix condition
        xTxmat_condition = np.linalg.cond(xTxmat)
        print(&#39;condition of xTx matrix before center adjustment for A0: %.2f&#39;%(xTxmat_condition))
        xTxmat[xmat_len//2,xmat_len//2] = m
    xTxmat_condition = np.linalg.cond(xTxmat)
    print(&#39;condition of xTx matrix: %.2f&#39;%(xTxmat_condition))
    if xTxmat_condition &gt; 10:#100: #random treshold
        raise Exception(&#39;ERROR: condition of xTx matrix is too high (%.2f), check your timeseries length, try different (shorter) component set or componentsplitting.\nAnalysed %s&#39;%(xTxmat_condition, check_ts(ts_pd)))
    xTymat = np.dot(xTmat,ts_pd_nonan[&#39;values&#39;].values)
    
    #solve matrix to get beta_roof_mat (and thus a, b)
    beta_roof_mat = np.linalg.solve(xTxmat,xTymat)
    toc = dt.datetime.now()-tic
    print(&#39;matrix system solved, elapsed time: %s&#39;%(toc))

    arctan_ab = np.arctan2(beta_roof_mat[N:],beta_roof_mat[:N]) #(a,b)
    phi_i_rad = arctan_ab
    
    sqsqrt_ab = np.sqrt(np.add(beta_roof_mat[N:]**2,beta_roof_mat[:N]**2)) #(a,b)
    A_i = sqsqrt_ab.flatten()
    phi_i_deg_str = np.rad2deg(phi_i_rad.flatten()%(2*np.pi))
    
    COMP_pd = pd.DataFrame({&#39;A&#39;: A_i, &#39;phi_deg&#39;: phi_i_deg_str}, index=const_list)
    if &#39;A0&#39; in COMP_pd.index: #correct 180 degrees A0 phase by making amplitude value negative
        if COMP_pd.loc[&#39;A0&#39;,&#39;phi_deg&#39;]==180:
            COMP_pd.loc[&#39;A0&#39;,&#39;A&#39;] = -COMP_pd.loc[&#39;A0&#39;,&#39;A&#39;]
            COMP_pd.loc[&#39;A0&#39;,&#39;phi_deg&#39;] = 0
    
    if CS_comps is not None:
        COMP_pd = split_components(comp=COMP_pd, CS_comps=CS_comps, dood_date_mid=dood_date_mid, xfac=xfac)
        
    print(&#39;ANALYSIS finished&#39;)
    
    if return_prediction:
        print(&#39;immediately generating a prediction for the same time array as the input ts&#39;)
        ts_prediction = prediction(comp=COMP_pd, times_pred_all=ts_pd.index, nodalfactors=nodalfactors, xfac=xfac, fu_alltimes=fu_alltimes, source=source)
        return COMP_pd, ts_prediction
    else:
        return COMP_pd
   





def split_components(comp, CS_comps, dood_date_mid, xfac=False):
    &#34;&#34;&#34;
    component splitting function
    for details about arguments and return variables, see get_components_from_ts() definition

    &#34;&#34;&#34;
    
    import numpy as np
    import pandas as pd
    
    from hatyan.hatyan_core import get_hatyan_v0, get_hatyan_u, get_hatyan_f, get_hatyan_freqs

    const_list_inclCS_raw = comp.index.tolist() + CS_comps[&#39;CS_comps_derive&#39;].tolist()
    #retrieve const_list and frequency in correct order
    t_const_freq_pd = get_hatyan_freqs(const_list_inclCS_raw)
    const_list_inclCS = t_const_freq_pd.index.tolist()
    #retrieve again but now with sorted const_list
    t_const_freq_pd, t_const_speed_all = get_hatyan_freqs(const_list_inclCS, dood_date=dood_date_mid, return_allraw=True)

    const_list = comp.index.tolist()
    A_i = comp[&#39;A&#39;].tolist()
    phi_i_rad_str = np.deg2rad(comp[&#39;phi_deg&#39;].tolist())
    
    #if CS_comps is not None: #component splitting
    A_i_inclCS = np.full(shape=(len(const_list_inclCS)),fill_value=np.nan)
    phi_i_rad_str_inclCS = np.full(shape=(len(const_list_inclCS)),fill_value=np.nan)
    CS_v_0i_rad = get_hatyan_v0(const_list=const_list_inclCS, dood_date=dood_date_mid).T.values #with split_components, v0 is calculated on the same timestep as u and f (middle of original series)
    CS_f_i = get_hatyan_f(xfac=xfac, const_list=const_list_inclCS, dood_date=dood_date_mid).T.values
    CS_u_i_rad = get_hatyan_u(const_list=const_list_inclCS, dood_date=dood_date_mid).T.values
    for iC,comp_sel in enumerate(const_list_inclCS):
        if comp_sel in const_list:
            A_i_inclCS[iC] = A_i[const_list.index(comp_sel)]
            phi_i_rad_str_inclCS[iC] = phi_i_rad_str[const_list.index(comp_sel)]
  
    
    def get_CS_vars(iC_slave, DBETA_in):
        &#34;&#34;&#34;
        Used to calculate values related to component splitting
        
        &#34;&#34;&#34;
        #code from resuda.f, line 440 to 455
        DMU = CS_f_i[0,iC_slave]/CS_f_i[0,iC_main]
        DTHETA = ampfac
        DGAMMA = np.deg2rad(degincr)-DBETA_in-(CS_v_0i_rad[0,iC_slave]+CS_u_i_rad[0,iC_slave])+(CS_v_0i_rad[0,iC_main]+CS_u_i_rad[0,iC_main]) #in FORTRAN code, CS_f_i slave/main is also added, this seems wrong
        DREEEL = 1+DMU*DTHETA*np.cos(DGAMMA)
        DIMAGI = DMU*DTHETA*np.sin(DGAMMA)  
        DALPHA = np.sqrt(DREEEL*DREEEL+DIMAGI*DIMAGI)
        if DALPHA &lt; 1e-50:
            raise Exception(&#39;ERROR: DALPHA too small, component splitting failed?&#39;)
        DBETA = np.arctan2(DIMAGI,DREEEL)
        if np.sign(DIMAGI) == np.sign(DREEEL):
            DBETA = DBETA
        else:
            DBETA = DBETA
        return DTHETA, DALPHA, DBETA
    
    if len(np.unique(CS_comps[&#39;CS_comps_derive&#39;])) != len(CS_comps[&#39;CS_comps_derive&#39;]):
        raise Exception(&#39;ERROR: CS_comps_derive contains duplicate components&#39;)
        
    for comp_main in np.unique(CS_comps[&#39;CS_comps_from&#39;]):
        main_ids = np.where(CS_comps[&#39;CS_comps_from&#39;] == comp_main)[0]
        comp_slave = CS_comps.loc[main_ids,&#39;CS_comps_derive&#39;].tolist()
        print(&#39;splitting component %s into %s&#39;%(comp_main, comp_slave))

        iC_main = const_list_inclCS.index(comp_main)
        iC_slave = const_list_inclCS.index(comp_slave[0])
        idslave_CScomp = CS_comps[&#39;CS_comps_derive&#39;].tolist().index(comp_slave[0])
        degincr = CS_comps[&#39;CS_degincrs&#39;].tolist()[idslave_CScomp]
        ampfac = CS_comps[&#39;CS_ampfacs&#39;].tolist()[idslave_CScomp]
        
        DTHETA, DALPHA, DBETA = get_CS_vars(iC_slave,0)
        A_i_inclCS[iC_main] = A_i_inclCS[iC_main]/DALPHA
        phi_i_rad_str_inclCS[iC_main] = (phi_i_rad_str_inclCS[iC_main]-DBETA)%(2*np.pi)

        if len(comp_slave) == 1:
            A_i_inclCS[iC_slave] = A_i_inclCS[iC_main]*DTHETA
            phi_i_rad_str_inclCS[iC_slave] = (phi_i_rad_str_inclCS[iC_main]+np.deg2rad(degincr))%(2*np.pi)
        elif len(comp_slave) == 2:
            #T2
            iC_slave2 = const_list_inclCS.index(comp_slave[1])
            idslave_CScomp2 = CS_comps[&#39;CS_comps_derive&#39;].tolist().index(comp_slave[1])
            degincr = CS_comps[&#39;CS_degincrs&#39;].tolist()[idslave_CScomp2]
            ampfac = CS_comps[&#39;CS_ampfacs&#39;].tolist()[idslave_CScomp2]
            
            DTHETA, DALPHA, DBETA = get_CS_vars(iC_slave2, DBETA)
            A_i_inclCS[iC_main] = A_i_inclCS[iC_main]/DALPHA
            phi_i_rad_str_inclCS[iC_main] = (phi_i_rad_str_inclCS[iC_main]-DBETA)%(2*np.pi)
            
            A_i_inclCS[iC_slave2] = A_i_inclCS[iC_main]*DTHETA
            phi_i_rad_str_inclCS[iC_slave2] = (phi_i_rad_str_inclCS[iC_main]+np.deg2rad(degincr))%(2*np.pi)
            
            #revert back to K2
            degincr = CS_comps[&#39;CS_degincrs&#39;].tolist()[idslave_CScomp]
            ampfac = CS_comps[&#39;CS_ampfacs&#39;].tolist()[idslave_CScomp]
            A_i_inclCS[iC_slave] = A_i_inclCS[iC_main]*ampfac
            phi_i_rad_str_inclCS[iC_slave] = (phi_i_rad_str_inclCS[iC_main]+np.deg2rad(degincr))%(2*np.pi)
        else:
            raise Exception(&#39;ERROR: length of comp_slave is invalid (%i)&#39;%(len(comp_slave)))

    phi_i_deg_str_inclCS = np.rad2deg(phi_i_rad_str_inclCS)
  
    comp_CS = pd.DataFrame({ &#39;A&#39;: A_i_inclCS, &#39;phi_deg&#39;: phi_i_deg_str_inclCS},index=const_list_inclCS)
    
    return comp_CS
    





    
def prediction(comp, times_pred_all=None, times_ext=None, timestep_min=None, nodalfactors=True, xfac=False, fu_alltimes=True, source=&#39;schureman&#39;):
    &#34;&#34;&#34;
    generates a tidal prediction from a set of components A and phi values.
    The component set has the same timezone as the timeseries used to create it, therefore the resulting prediction will also be in that original timezone.
    
    Parameters
    ----------
    comp : pandas.DataFrame
        The DataFrame contains the component data with component names as index, and colums &#39;A&#39; and &#39;phi_deg&#39;.
    times_pred_all : pandas.DatetimeIndex, optional
        Prediction timeseries. The default is None.
    times_ext : list of datetime.datetime, optional
        Prediction time extents (list of start time and stop time). The default is None.
    timestep_min : int, optional
        Prediction timestep in minutes. The default is None.
    nodalfactors : bool/int, optional
        Whether or not to apply nodal factors. The default is True.
    xfac : bool/int, optional
        Whether or not to apply x-factors. The default is False.
    fu_alltimes : bool/int, optional
        determines whether to calculate nodal factors in middle of the prediction period (default) or on every timestep. The default is True.

    Raises
    ------
    Exception
        DESCRIPTION.

    Returns
    -------
    ts_prediction_pd : pandas.DataFrame
        The DataFrame should contain a &#39;values&#39; column and a pd.DatetimeIndex as index, it contains the prediction times and values.

    &#34;&#34;&#34;
    
    print(&#39;-&#39;*100)
    print(&#39;PREDICTION initializing&#39;)
    print(&#39;%-20s = %s&#39;%(&#39;nodalfactors&#39;,nodalfactors))
    print(&#39;%-20s = %s&#39;%(&#39;xfac&#39;,xfac))
    print(&#39;%-20s = %s&#39;%(&#39;fu_alltimes&#39;,fu_alltimes))

    import numpy as np
    import pandas as pd
    from packaging import version
    from hatyan.hatyan_core import get_hatyan_freqs, get_hatyan_v0, get_hatyan_u, get_hatyan_f, robust_daterange_fromtimesextfreq
    from hatyan.foreman_core import get_foreman_v0_freq, get_foreman_nodalfactors
    
    COMP = comp.copy()
    
    
    if times_pred_all is None:
        if times_ext is None or timestep_min is None:
            raise Exception(&#39;if argument times_pred_all is not provided, the arguments times_ext and timestep_min are obligatory&#39;)
        else:
            times_pred_all = robust_daterange_fromtimesextfreq(times_ext,timestep_min)
    else:
        if times_ext is not None or timestep_min is not None:
            raise Exception(&#39;if argument times_pred_all is provided, the arguments times_ext and timestep_min are not allowed&#39;)

    if not len(times_pred_all) &gt; 1:
        raise Exception(&#39;ERROR: requested prediction period is not more than one timestep_min&#39;)
    
    if isinstance(times_pred_all, pd.core.indexes.datetimes.DatetimeIndex) or isinstance(times_pred_all, pd.core.indexes.base.Index):
        times_pred_all_pdDTI = times_pred_all
    else:
        times_pred_all_pdDTI = pd.DatetimeIndex(times_pred_all)
    
    print(&#39;%-20s = %s&#39;%(&#39;components used&#39;,len(comp)))
    print(&#39;%-20s = %s&#39;%(&#39;tstart&#39;,times_pred_all_pdDTI[0].strftime(&#39;%Y-%m-%d %H:%M:%S&#39;)))
    print(&#39;%-20s = %s&#39;%(&#39;tstop&#39;,times_pred_all_pdDTI[-1].strftime(&#39;%Y-%m-%d %H:%M:%S&#39;)))
    if hasattr(times_pred_all_pdDTI,&#39;freq&#39;):
        print(&#39;%-20s = %s&#39;%(&#39;timestep&#39;,times_pred_all_pdDTI.freq))
    
    dood_date_mid = pd.Index([times_pred_all_pdDTI[len(times_pred_all_pdDTI)//2]]) #middle of analysis period (2july in case of 1jan-1jan), zoals bij hatyan.
    dood_date_start = times_pred_all_pdDTI[:1] #first date (for v0, also freq?)

    #retrieve const_list and frequency in correct order
    t_const_freq_pd = get_hatyan_freqs(COMP.index.tolist())
    const_list = t_const_freq_pd.index.tolist()
    #retrieve again but now with sorted const_list
    t_const_freq_pd, t_const_speed_all = get_hatyan_freqs(const_list, dood_date=dood_date_mid, return_allraw=True)
    COMP[&#39;freq&#39;] = t_const_freq_pd[&#39;freq&#39;]
    COMP = COMP.sort_values(by=&#39;freq&#39;)

    A = np.array(COMP[&#39;A&#39;])
    phi_rad = np.array(np.deg2rad(COMP[&#39;phi_deg&#39;]))
    
    if source.lower()==&#39;schureman&#39;:
        print(&#39;v0 is calculated for start of period: %s&#39;%(dood_date_start[0]))
        v_0i_rad = get_hatyan_v0(const_list, dood_date_start).T #at start of timeseries
    elif source.lower()==&#39;foreman&#39;:
        print(&#39;v0 is calculated for start of period: %s&#39;%(dood_date_start[0]))
        v_0i_rad, dummy = get_foreman_v0_freq(const_list=const_list, dood_date=dood_date_start)
        v_0i_rad = v_0i_rad.T
    else:
        raise Exception(&#39;invalid source value (schureman or foreman)&#39;)
    
    if nodalfactors:
        if fu_alltimes:
            print(&#39;nodal factors (f and u) are calculated for all timesteps&#39;)
            dood_date_fu = times_pred_all_pdDTI
        else:
            print(&#39;nodal factors (fu) are calculated for center of period: %s&#39;%(dood_date_mid[0]))
            dood_date_fu = dood_date_mid
        if source.lower()==&#39;schureman&#39;:
            f_i = get_hatyan_f(xfac=xfac, const_list=const_list, dood_date=dood_date_fu).T
            u_i_rad = get_hatyan_u(const_list=const_list, dood_date=dood_date_fu).T
        elif source.lower()==&#39;foreman&#39;:
            f_i, u_i_rad = get_foreman_nodalfactors(const_list=const_list, dood_date=dood_date_fu)
            f_i, u_i_rad = f_i.T, u_i_rad.T
    else:
        print(&#39;no nodal factors (fu) are calculated for (f=1, u=0)&#39;)
        f_i = pd.DataFrame(np.ones(len(const_list)),index=const_list).T
        u_i_rad = pd.DataFrame(np.zeros(len(const_list)),index=const_list).T


    print(&#39;PREDICTION started&#39;)
    omega_i_rads = t_const_speed_all.T/3600 #angular frequency, 2pi/T, in rad/s, https://en.wikipedia.org/wiki/Angular_frequency (2*np.pi)/(1/x*3600) = 2*np.pi*x/3600
    if version.parse(pd.__version__) &lt; version.parse(&#39;1.2.0&#39;): #fix for non-backwards compatible change in pandas, pandas version 1.1.2 is used for RWS version.
        times_from0allpred_s_orig = (times_pred_all_pdDTI-dood_date_start[0]).total_seconds().values
    else:
        times_from0allpred_s_orig = (times_pred_all_pdDTI-dood_date_start).total_seconds().values
    times_from0allpred_s = np.transpose(times_from0allpred_s_orig[np.newaxis])

    f_A = np.multiply(f_i.values,A)
    omeg_t = np.multiply(times_from0allpred_s,omega_i_rads)#_td)
    v_u_phi = np.subtract(np.add(v_0i_rad.values,u_i_rad.values),phi_rad)
    omeg_t_v_u_phi = np.add(omeg_t,v_u_phi)
    ht_res = np.sum(np.multiply(f_A,np.cos(omeg_t_v_u_phi)),axis=1) #not necessary to add A0, since it is already part of the component list
    
    ts_prediction_pd = pd.DataFrame({&#39;values&#39;: ht_res},index=times_pred_all_pdDTI)
    print(&#39;PREDICTION finished&#39;)
    
    return ts_prediction_pd
        </code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="hatyan.analysis_prediction.vectoravg"><code class="name flex">
<span>def <span class="ident">vectoravg</span></span>(<span>A_all, phi_deg_all)</span>
</code></dt>
<dd>
<div class="desc"><p>calculates the vector average of A and phi per constituent,
it vector averages over values resulting from multiple periods.
A regular average is calculated for the amplitude of A0 (middenstand)</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>A_i_all</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>DESCRIPTION.</dd>
<dt><strong><code>phi_i_deg_all</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>DESCRIPTION.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>A_i_mean</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>DESCRIPTION.</dd>
<dt><strong><code>phi_i_deg_mean</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>DESCRIPTION.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def vectoravg(A_all, phi_deg_all):
    &#34;&#34;&#34;
    calculates the vector average of A and phi per constituent, 
    it vector averages over values resulting from multiple periods.
    A regular average is calculated for the amplitude of A0 (middenstand)
    
    Parameters
    ----------
    A_i_all : TYPE
        DESCRIPTION.
    phi_i_deg_all : TYPE
        DESCRIPTION.

    Returns
    -------
    A_i_mean : TYPE
        DESCRIPTION.
    phi_i_deg_mean : TYPE
        DESCRIPTION.

    &#34;&#34;&#34;
    
    import numpy as np
    
    phi_rad_all = np.deg2rad(phi_deg_all)
    v_cos = A_all*np.cos(phi_rad_all)
    v_sin = A_all*np.sin(phi_rad_all)
    mean_v_cos = np.mean(v_cos,axis=1)
    mean_v_sin = np.mean(v_sin,axis=1)
    A_mean = np.sqrt(mean_v_cos**2 + mean_v_sin**2)
    phi_rad_mean = np.arctan2(mean_v_sin,mean_v_cos)
    phi_rad_mean[phi_rad_mean&lt;0] = phi_rad_mean[phi_rad_mean&lt;0]+(2*np.pi)
    
    #if phases of all years are exactly 0, it is the A0 component. Overwrite this A0 with mean amplitude and zero phase if present, otherwise negative values will become positive with 180 phase
    idx_A0 = np.where((phi_deg_all==0).any(axis=1))[0]
    A_mean[idx_A0] = np.mean(A_all[idx_A0,:])
    phi_rad_mean[idx_A0] = 0
    
    phi_deg_mean = np.rad2deg(phi_rad_mean)
    
    return A_mean, phi_deg_mean</code></pre>
</details>
</dd>
<dt id="hatyan.analysis_prediction.get_components_from_ts"><code class="name flex">
<span>def <span class="ident">get_components_from_ts</span></span>(<span>ts, const_list, nodalfactors=True, xfac=False, fu_alltimes=True, CS_comps=None, analysis_peryear=False, analysis_permonth=False, return_allyears=False, source='schureman')</span>
</code></dt>
<dd>
<div class="desc"><p>Wrapper around the analysis() function,
it optionally processes a timeseries per year and vector averages the results afterwards,
passes the rest of the arguments on to analysis function
The timezone of the timeseries, will also be reflected in the phases of the resulting component set, so the resulting component set can be used to make a prediction in the original timezone.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>ts</code></strong> :&ensp;<code>pandas.DataFrame</code></dt>
<dd>The DataFrame should contain a 'values' column and a pd.DatetimeIndex as index, it contains the timeseries to be analysed, as obtained from e.g. readts_*.</dd>
<dt><strong><code>const_list</code></strong> :&ensp;<code>list, pandas.Series</code> or <code>str</code></dt>
<dd>list or pandas.Series: contains the tidal constituent names for which to analyse the provided timeseries ts.
str: a predefined name of a component set for hatyan_core.get_const_list_hatyan()</dd>
<dt><strong><code>nodalfactors</code></strong> :&ensp;<code>bool/int</code>, optional</dt>
<dd>Whether or not to apply nodal factors. The default is True.</dd>
<dt><strong><code>xfac</code></strong> :&ensp;<code>bool/int</code>, optional</dt>
<dd>Whether or not to apply x-factors. The default is False.</dd>
<dt><strong><code>fu_alltimes</code></strong> :&ensp;<code>bool/int</code>, optional</dt>
<dd>determines whether to calculate nodal factors in middle of analysis period (default) or on every timestep. The default is True.</dd>
<dt><strong><code>analysis_peryear</code></strong> :&ensp;<code>bool/int</code>, optional</dt>
<dd>DESCRIPTION. The default is False.</dd>
<dt><strong><code>analysis_permonth</code></strong> :&ensp;<code>bool/int</code>, optional</dt>
<dd>caution, it tries to analyse each month, but skips it if it fails. analysis_peryear argument has priority. The default is False.</dd>
<dt><strong><code>return_allyears</code></strong> :&ensp;<code>bool/int</code>, optional</dt>
<dd>DESCRIPTION. The default is False.</dd>
<dt><strong><code>CS_comps</code></strong> :&ensp;<code>pandas.DataFrame</code>, optional</dt>
<dd>contains the from/derive component lists for components splitting, as well as the amplitude factor and the increase in degrees. The default is None.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>Exception</code></dt>
<dd>DESCRIPTION.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>COMP_mean_pd</code></strong> :&ensp;<code>pandas.DataFrame</code></dt>
<dd>The DataFrame contains the component data with component names as index, and colums 'A' and 'phi_deg'.</dd>
<dt><strong><code>COMP_all_pd</code></strong> :&ensp;<code>pandas.DataFrame</code>, optional</dt>
<dd>The same as COMP_mean_pd, but with all years added with MultiIndex</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_components_from_ts(ts, const_list, nodalfactors=True, xfac=False, fu_alltimes=True, CS_comps=None, analysis_peryear=False, analysis_permonth=False, return_allyears=False, source=&#39;schureman&#39;):
    &#34;&#34;&#34;
    Wrapper around the analysis() function, 
    it optionally processes a timeseries per year and vector averages the results afterwards, 
    passes the rest of the arguments on to analysis function
    The timezone of the timeseries, will also be reflected in the phases of the resulting component set, so the resulting component set can be used to make a prediction in the original timezone.
    
    Parameters
    ----------
    ts : pandas.DataFrame
        The DataFrame should contain a &#39;values&#39; column and a pd.DatetimeIndex as index, it contains the timeseries to be analysed, as obtained from e.g. readts_*.
    const_list : list, pandas.Series or str
        list or pandas.Series: contains the tidal constituent names for which to analyse the provided timeseries ts. 
        str: a predefined name of a component set for hatyan_core.get_const_list_hatyan()
    nodalfactors : bool/int, optional
        Whether or not to apply nodal factors. The default is True.
    xfac : bool/int, optional
        Whether or not to apply x-factors. The default is False.
    fu_alltimes : bool/int, optional
        determines whether to calculate nodal factors in middle of analysis period (default) or on every timestep. The default is True.
    analysis_peryear : bool/int, optional
        DESCRIPTION. The default is False.
    analysis_permonth : bool/int, optional
        caution, it tries to analyse each month, but skips it if it fails. analysis_peryear argument has priority. The default is False.
    return_allyears : bool/int, optional
        DESCRIPTION. The default is False.
    CS_comps : pandas.DataFrame, optional
        contains the from/derive component lists for components splitting, as well as the amplitude factor and the increase in degrees. The default is None.

    Raises
    ------
    Exception
        DESCRIPTION.

    Returns
    -------
    COMP_mean_pd : pandas.DataFrame
        The DataFrame contains the component data with component names as index, and colums &#39;A&#39; and &#39;phi_deg&#39;.
    COMP_all_pd : pandas.DataFrame, optional
        The same as COMP_mean_pd, but with all years added with MultiIndex
    &#34;&#34;&#34;
    ts_pd = ts
    
    import pandas as pd
    import numpy as np
    
    from hatyan.analysis_prediction import analysis
    from hatyan.analysis_prediction import vectoravg
    from hatyan.hatyan_core import get_const_list_hatyan
       
    print(&#39;-&#39;*100)
    print(&#39;running: get_components_from_ts&#39;)
    
    if type(const_list) is str:
        const_list = get_const_list_hatyan(const_list)
    elif type(const_list) is not list:
        const_list = const_list.tolist()
    n_const = len(const_list)

    if analysis_peryear or analysis_permonth:
        if analysis_peryear:
            print(&#39;analysis_peryear=True, separate years are automatically determined from unique calendar years in timeseries&#39;)
            ts_years_dt = ts_pd.index.year.unique()
            ts_years = ts_pd.index.year.unique()
        else:
            print(&#39;analysis_permonth=True, separate month/year combinations are automatically determined from unique calendar months/years in timeseries&#39;)
            ts_years_dt = pd.date_range(start=ts_pd.index.iloc[0], end=ts_pd.index.iloc[-1], freq=&#39;M&#39;)
            ts_years = [&#39;%d-%02d&#39;%(x.year,x.month) for x in ts_years_dt]

        n_years = len(ts_years)
        A_i_all = np.zeros((n_const,n_years))
        phi_i_deg_all = np.zeros((n_const,n_years))
        for iY, year_dt in enumerate(ts_years_dt):
            if analysis_peryear:
                print(&#39;analyzing %d of sequence %s&#39;%(year_dt,ts_years))
                ts_oneyear_pd = ts_pd[ts_pd.index.year==year_dt]
                COMP_one = analysis(ts_oneyear_pd, const_list=const_list, nodalfactors=nodalfactors, xfac=xfac, fu_alltimes=fu_alltimes, CS_comps=CS_comps, source=source)
                A_i_all[:,iY] = COMP_one.loc[:,&#39;A&#39;]
                phi_i_deg_all[:,iY] = COMP_one.loc[:,&#39;phi_deg&#39;]
            else:
                print(&#39;analyzing %d-%02d of sequence [%s]&#39;%(year_dt.year, year_dt.month, &#39;, &#39;.join(ts_years)))
                ts_oneyear_pd = ts_pd[(ts_pd.index.dt.year==year_dt.year) &amp; (ts_pd.index.dt.month==year_dt.month)]
                try:
                    COMP_one = analysis(ts_oneyear_pd, const_list=const_list, nodalfactors=nodalfactors, xfac=xfac, fu_alltimes=fu_alltimes, CS_comps=CS_comps, source=source)
                    A_i_all[:,iY] = COMP_one.loc[:,&#39;A&#39;]
                    phi_i_deg_all[:,iY] = COMP_one.loc[:,&#39;phi_deg&#39;]
                except Exception as e:
                    print(&#39;WARNING: analysis of %d-%02d failed, error message: &#34;%s&#39;%(year_dt.year,year_dt.month,e))
        
        COMP_all_pd = pd.DataFrame(data=np.hstack([A_i_all,phi_i_deg_all]), columns=pd.MultiIndex.from_product([[&#39;A&#39;,&#39;phi_deg&#39;],ts_years]), index=COMP_one.index)
        print(&#39;vector averaging analysis results&#39;)
        A_i_mean, phi_i_deg_mean = vectoravg(A_all=A_i_all, phi_deg_all=phi_i_deg_all)
        COMP_mean_pd = pd.DataFrame({ &#39;A&#39;: A_i_mean, &#39;phi_deg&#39;: phi_i_deg_mean},index=COMP_one.index)

    else: #dummy values, COMP_years should be equal to COMP_mean
        COMP_mean_pd = analysis(ts_pd, const_list=const_list, nodalfactors=nodalfactors, xfac=xfac, fu_alltimes=fu_alltimes, CS_comps=CS_comps, source=source)
        COMP_all_pd = None
    
    if return_allyears:
        return COMP_mean_pd, COMP_all_pd
    else:
        return COMP_mean_pd</code></pre>
</details>
</dd>
<dt id="hatyan.analysis_prediction.analysis"><code class="name flex">
<span>def <span class="ident">analysis</span></span>(<span>ts, const_list, nodalfactors=True, xfac=False, fu_alltimes=True, CS_comps=None, return_prediction=False, source='schureman')</span>
</code></dt>
<dd>
<div class="desc"><p>harmonic analysis with matrix transformations (least squares fit), optionally with component splitting
for details about arguments and return variables, see get_components_from_ts() definition</p>
<p>return_prediction : bool/int, optional
Whether to generate a prediction for the ts time array. The default is False.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def analysis(ts, const_list, nodalfactors=True, xfac=False, fu_alltimes=True, CS_comps=None, return_prediction=False, source=&#39;schureman&#39;):
    &#34;&#34;&#34;
    harmonic analysis with matrix transformations (least squares fit), optionally with component splitting
    for details about arguments and return variables, see get_components_from_ts() definition
    
    return_prediction : bool/int, optional
        Whether to generate a prediction for the ts time array. The default is False.
    &#34;&#34;&#34;
    
    import numpy as np
    import pandas as pd
    import datetime as dt
    
    from hatyan.hatyan_core import get_hatyan_freqs, get_hatyan_v0, get_hatyan_u, get_hatyan_f, get_const_list_hatyan, robust_timedelta_sec
    from hatyan.foreman_core import get_foreman_v0_freq, get_foreman_nodalfactors
    from hatyan.timeseries import check_ts
    
    #drop duplicate times
    ts_pd = ts[~ts.index.duplicated(keep=&#39;first&#39;)]
    print(&#39;-&#39;*100)
    print(&#39;ANALYSIS initializing&#39;)
    print(&#39;%-20s = %s&#39;%(&#39;nodalfactors&#39;,nodalfactors))
    print(&#39;%-20s = %s&#39;%(&#39;xfac&#39;,xfac))
    print(&#39;%-20s = %s&#39;%(&#39;fu_alltimes&#39;,fu_alltimes))
    if CS_comps is not None:
        print(&#39;%-20s = %s&#39;%(&#39;CS_comps derive&#39;,CS_comps[&#39;CS_comps_derive&#39;].tolist()))
        print(&#39;%-20s = %s&#39;%(&#39;CS_comps from&#39;,CS_comps[&#39;CS_comps_from&#39;].tolist()))
    else:
        print(&#39;%-20s = %s&#39;%(&#39;CS_comps&#39;, CS_comps))
        
    if len(ts_pd) != len(ts):
        print(&#39;WARNING: %i duplicate times of the input timeseries were dropped prior to the analysis&#39;%(len(ts)-len(ts_pd)))
    
    if type(const_list) is str:
        const_list = get_const_list_hatyan(const_list)
    elif type(const_list) is not list:
        const_list = const_list.tolist()
    
    print(&#39;%-20s = %s&#39;%(&#39;components analyzed&#39;,len(const_list)))
    print(&#39;%-20s = %s&#39;%(&#39;#timesteps&#39;,len(ts)))
    print(&#39;%-20s = %s&#39;%(&#39;tstart&#39;,ts.index[0].strftime(&#39;%Y-%m-%d %H:%M:%S&#39;)))
    print(&#39;%-20s = %s&#39;%(&#39;tstop&#39;,ts.index[-1].strftime(&#39;%Y-%m-%d %H:%M:%S&#39;)))
    if hasattr(ts.index,&#39;freq&#39;):
        print(&#39;%-20s = %s&#39;%(&#39;timestep&#39;,ts.index.freq))
    
    #check for duplicate components (results in singular matrix)
    if len(const_list) != len(np.unique(const_list)):
        const_list_uniq, const_list_uniq_counts = np.unique(const_list,return_counts=True)
        bool_nonuniq = const_list_uniq_counts&gt;1
        const_list_dupl = pd.DataFrame({&#39;constituent&#39;:const_list_uniq[bool_nonuniq],&#39;occurences&#39;:const_list_uniq_counts[bool_nonuniq]})
        raise Exception(&#39;remove duplicate constituents from const_list:\n%s&#39;%(const_list_dupl))
    
    dood_date_mid = pd.Index([ts_pd.index[len(ts_pd.index)//2]]) #middle of analysis period (2july in case of 1jan-1jan), zoals bij hatyan
    dood_date_start = ts_pd.index[:1] #first date (for v0, also freq?)
    
    ts_pd_nonan = ts_pd[~ts_pd[&#39;values&#39;].isna()]
    times_pred_all_pdDTI = pd.DatetimeIndex(ts_pd_nonan.index)
    percentage_nan = 100-len(ts_pd_nonan[&#39;values&#39;])/len(ts_pd[&#39;values&#39;])*100
    print(&#39;percentage_nan in values_meas_sel: %.2f%%&#39;%(percentage_nan))

    #retrieve const_list and frequency in correct order
    t_const_freq_pd = get_hatyan_freqs(const_list)
    const_list = t_const_freq_pd.index.tolist()
    #retrieve again but now with sorted const_list
    t_const_freq_pd, t_const_speed_all = get_hatyan_freqs(const_list, dood_date=dood_date_mid, return_allraw=True)
    t_const_freq = t_const_freq_pd[&#39;freq&#39;]
            
    #check Rayleigh
    freq_diffs = np.diff(t_const_freq)
    rayleigh_tresh = 0.99
    rayleigh = len(ts_pd[&#39;values&#39;])*freq_diffs
    freq_diff_min = rayleigh_tresh/len(ts_pd[&#39;values&#39;])
    rayleigh_bool = rayleigh&gt;rayleigh_tresh
    rayleigh_bool_id = np.where(~rayleigh_bool)[0]
    
    if rayleigh_bool.all():
        print(&#39;Rayleigh criterion OK (always&gt;%.2f, minimum is %.2f)&#39;%(rayleigh_tresh, np.min(rayleigh)))
        print(&#39;Frequencies are far enough apart (always &gt;%.6f, minimum is %.6f)&#39;%(freq_diff_min,np.min(freq_diffs)))
    else:
        print(&#39;Rayleigh criterion vandalised (not always&gt;%.2f, minimum is %.2f)&#39;%(rayleigh_tresh, np.min(rayleigh)))
        print(&#39;Frequencies with not enough difference (not always &gt;%.6f, minimum is %.6f)&#39;%(freq_diff_min,np.min(freq_diffs)))
        for ray_id in rayleigh_bool_id:
            print(t_const_freq.iloc[[ray_id,ray_id+1]])
    
    #get f and v, only needed after matrix calculations
    if source.lower()==&#39;schureman&#39;:
        print(&#39;v0 is calculated for start of period: %s&#39;%(dood_date_start[0]))
        v_0i_rad = get_hatyan_v0(const_list, dood_date_start).T #at start of timeseries
    elif source.lower()==&#39;foreman&#39;:
        print(&#39;v0 is calculated for start of period: %s&#39;%(dood_date_start[0]))
        v_0i_rad, dummy = get_foreman_v0_freq(const_list=const_list, dood_date=dood_date_start)
        v_0i_rad = v_0i_rad.T
    else:
        raise Exception(&#39;invalid source value (schureman or foreman)&#39;)
    
    if nodalfactors:
        if fu_alltimes:
            print(&#39;nodal factors (f and u) are calculated for all timesteps&#39;)
            dood_date_fu = times_pred_all_pdDTI
        else:
            print(&#39;nodal factors (fu) are calculated for center of period: %s&#39;%(dood_date_mid[0]))
            dood_date_fu = dood_date_mid
        if source.lower()==&#39;schureman&#39;:
            f_i = get_hatyan_f(xfac=xfac, const_list=const_list, dood_date=dood_date_fu).T
            u_i_rad = get_hatyan_u(const_list=const_list, dood_date=dood_date_fu).T
        elif source.lower()==&#39;foreman&#39;:
            f_i, u_i_rad = get_foreman_nodalfactors(const_list=const_list, dood_date=dood_date_fu)
            f_i, u_i_rad = f_i.T, u_i_rad.T
    else:
        print(&#39;no nodal factors (fu) are calculated for (f=1, u=0)&#39;)
        f_i = pd.DataFrame(np.ones(len(const_list)),index=const_list).T
        u_i_rad = pd.DataFrame(np.zeros(len(const_list)),index=const_list).T

    v_u = np.add(v_0i_rad.values,u_i_rad.values)
    
    #### TIMESERIES ANALYSIS
    N = len(const_list)
    print(&#39;ANALYSIS start (for %i constituents)&#39;%(N))
    
    #times_from0_s = (pd.DatetimeIndex(ts_pd_nonan.index)-dood_date_start[0]).total_seconds().values
    times_from0_s, fancy_pddt = robust_timedelta_sec(ts_pd_nonan.index,refdate_dt=dood_date_start[0])
    times_from0_s = np.transpose(times_from0_s[np.newaxis])
    
    m = len(ts_pd_nonan[&#39;values&#39;])
    
    # get xmat and make dot product
    xmat = np.zeros((m,2*N))
    omega_i_rads = t_const_speed_all.T/3600 #angular frequency, 2pi/T, in rad/s, https://en.wikipedia.org/wiki/Angular_frequency (2*np.pi)/(1/x*3600) = 2*np.pi*x/3600
    
    xmat[:,:N] = np.multiply(f_i.values,np.cos(np.multiply(omega_i_rads,times_from0_s)+v_u))
    xmat[:,N:] = np.multiply(f_i.values,np.sin(np.multiply(omega_i_rads,times_from0_s)+v_u))
    xmat_len = xmat.shape[1]
    
    xTmat = xmat.T
    print(&#39;calculating xTx matrix&#39;)
    tic = dt.datetime.now()
    xTxmat = np.dot(xTmat,xmat)
    print(&#39;xTx matrix calculated&#39;)
    if &#39;A0&#39; in const_list: #correct center value for better matrix condition
        xTxmat_condition = np.linalg.cond(xTxmat)
        print(&#39;condition of xTx matrix before center adjustment for A0: %.2f&#39;%(xTxmat_condition))
        xTxmat[xmat_len//2,xmat_len//2] = m
    xTxmat_condition = np.linalg.cond(xTxmat)
    print(&#39;condition of xTx matrix: %.2f&#39;%(xTxmat_condition))
    if xTxmat_condition &gt; 10:#100: #random treshold
        raise Exception(&#39;ERROR: condition of xTx matrix is too high (%.2f), check your timeseries length, try different (shorter) component set or componentsplitting.\nAnalysed %s&#39;%(xTxmat_condition, check_ts(ts_pd)))
    xTymat = np.dot(xTmat,ts_pd_nonan[&#39;values&#39;].values)
    
    #solve matrix to get beta_roof_mat (and thus a, b)
    beta_roof_mat = np.linalg.solve(xTxmat,xTymat)
    toc = dt.datetime.now()-tic
    print(&#39;matrix system solved, elapsed time: %s&#39;%(toc))

    arctan_ab = np.arctan2(beta_roof_mat[N:],beta_roof_mat[:N]) #(a,b)
    phi_i_rad = arctan_ab
    
    sqsqrt_ab = np.sqrt(np.add(beta_roof_mat[N:]**2,beta_roof_mat[:N]**2)) #(a,b)
    A_i = sqsqrt_ab.flatten()
    phi_i_deg_str = np.rad2deg(phi_i_rad.flatten()%(2*np.pi))
    
    COMP_pd = pd.DataFrame({&#39;A&#39;: A_i, &#39;phi_deg&#39;: phi_i_deg_str}, index=const_list)
    if &#39;A0&#39; in COMP_pd.index: #correct 180 degrees A0 phase by making amplitude value negative
        if COMP_pd.loc[&#39;A0&#39;,&#39;phi_deg&#39;]==180:
            COMP_pd.loc[&#39;A0&#39;,&#39;A&#39;] = -COMP_pd.loc[&#39;A0&#39;,&#39;A&#39;]
            COMP_pd.loc[&#39;A0&#39;,&#39;phi_deg&#39;] = 0
    
    if CS_comps is not None:
        COMP_pd = split_components(comp=COMP_pd, CS_comps=CS_comps, dood_date_mid=dood_date_mid, xfac=xfac)
        
    print(&#39;ANALYSIS finished&#39;)
    
    if return_prediction:
        print(&#39;immediately generating a prediction for the same time array as the input ts&#39;)
        ts_prediction = prediction(comp=COMP_pd, times_pred_all=ts_pd.index, nodalfactors=nodalfactors, xfac=xfac, fu_alltimes=fu_alltimes, source=source)
        return COMP_pd, ts_prediction
    else:
        return COMP_pd</code></pre>
</details>
</dd>
<dt id="hatyan.analysis_prediction.split_components"><code class="name flex">
<span>def <span class="ident">split_components</span></span>(<span>comp, CS_comps, dood_date_mid, xfac=False)</span>
</code></dt>
<dd>
<div class="desc"><p>component splitting function
for details about arguments and return variables, see get_components_from_ts() definition</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def split_components(comp, CS_comps, dood_date_mid, xfac=False):
    &#34;&#34;&#34;
    component splitting function
    for details about arguments and return variables, see get_components_from_ts() definition

    &#34;&#34;&#34;
    
    import numpy as np
    import pandas as pd
    
    from hatyan.hatyan_core import get_hatyan_v0, get_hatyan_u, get_hatyan_f, get_hatyan_freqs

    const_list_inclCS_raw = comp.index.tolist() + CS_comps[&#39;CS_comps_derive&#39;].tolist()
    #retrieve const_list and frequency in correct order
    t_const_freq_pd = get_hatyan_freqs(const_list_inclCS_raw)
    const_list_inclCS = t_const_freq_pd.index.tolist()
    #retrieve again but now with sorted const_list
    t_const_freq_pd, t_const_speed_all = get_hatyan_freqs(const_list_inclCS, dood_date=dood_date_mid, return_allraw=True)

    const_list = comp.index.tolist()
    A_i = comp[&#39;A&#39;].tolist()
    phi_i_rad_str = np.deg2rad(comp[&#39;phi_deg&#39;].tolist())
    
    #if CS_comps is not None: #component splitting
    A_i_inclCS = np.full(shape=(len(const_list_inclCS)),fill_value=np.nan)
    phi_i_rad_str_inclCS = np.full(shape=(len(const_list_inclCS)),fill_value=np.nan)
    CS_v_0i_rad = get_hatyan_v0(const_list=const_list_inclCS, dood_date=dood_date_mid).T.values #with split_components, v0 is calculated on the same timestep as u and f (middle of original series)
    CS_f_i = get_hatyan_f(xfac=xfac, const_list=const_list_inclCS, dood_date=dood_date_mid).T.values
    CS_u_i_rad = get_hatyan_u(const_list=const_list_inclCS, dood_date=dood_date_mid).T.values
    for iC,comp_sel in enumerate(const_list_inclCS):
        if comp_sel in const_list:
            A_i_inclCS[iC] = A_i[const_list.index(comp_sel)]
            phi_i_rad_str_inclCS[iC] = phi_i_rad_str[const_list.index(comp_sel)]
  
    
    def get_CS_vars(iC_slave, DBETA_in):
        &#34;&#34;&#34;
        Used to calculate values related to component splitting
        
        &#34;&#34;&#34;
        #code from resuda.f, line 440 to 455
        DMU = CS_f_i[0,iC_slave]/CS_f_i[0,iC_main]
        DTHETA = ampfac
        DGAMMA = np.deg2rad(degincr)-DBETA_in-(CS_v_0i_rad[0,iC_slave]+CS_u_i_rad[0,iC_slave])+(CS_v_0i_rad[0,iC_main]+CS_u_i_rad[0,iC_main]) #in FORTRAN code, CS_f_i slave/main is also added, this seems wrong
        DREEEL = 1+DMU*DTHETA*np.cos(DGAMMA)
        DIMAGI = DMU*DTHETA*np.sin(DGAMMA)  
        DALPHA = np.sqrt(DREEEL*DREEEL+DIMAGI*DIMAGI)
        if DALPHA &lt; 1e-50:
            raise Exception(&#39;ERROR: DALPHA too small, component splitting failed?&#39;)
        DBETA = np.arctan2(DIMAGI,DREEEL)
        if np.sign(DIMAGI) == np.sign(DREEEL):
            DBETA = DBETA
        else:
            DBETA = DBETA
        return DTHETA, DALPHA, DBETA
    
    if len(np.unique(CS_comps[&#39;CS_comps_derive&#39;])) != len(CS_comps[&#39;CS_comps_derive&#39;]):
        raise Exception(&#39;ERROR: CS_comps_derive contains duplicate components&#39;)
        
    for comp_main in np.unique(CS_comps[&#39;CS_comps_from&#39;]):
        main_ids = np.where(CS_comps[&#39;CS_comps_from&#39;] == comp_main)[0]
        comp_slave = CS_comps.loc[main_ids,&#39;CS_comps_derive&#39;].tolist()
        print(&#39;splitting component %s into %s&#39;%(comp_main, comp_slave))

        iC_main = const_list_inclCS.index(comp_main)
        iC_slave = const_list_inclCS.index(comp_slave[0])
        idslave_CScomp = CS_comps[&#39;CS_comps_derive&#39;].tolist().index(comp_slave[0])
        degincr = CS_comps[&#39;CS_degincrs&#39;].tolist()[idslave_CScomp]
        ampfac = CS_comps[&#39;CS_ampfacs&#39;].tolist()[idslave_CScomp]
        
        DTHETA, DALPHA, DBETA = get_CS_vars(iC_slave,0)
        A_i_inclCS[iC_main] = A_i_inclCS[iC_main]/DALPHA
        phi_i_rad_str_inclCS[iC_main] = (phi_i_rad_str_inclCS[iC_main]-DBETA)%(2*np.pi)

        if len(comp_slave) == 1:
            A_i_inclCS[iC_slave] = A_i_inclCS[iC_main]*DTHETA
            phi_i_rad_str_inclCS[iC_slave] = (phi_i_rad_str_inclCS[iC_main]+np.deg2rad(degincr))%(2*np.pi)
        elif len(comp_slave) == 2:
            #T2
            iC_slave2 = const_list_inclCS.index(comp_slave[1])
            idslave_CScomp2 = CS_comps[&#39;CS_comps_derive&#39;].tolist().index(comp_slave[1])
            degincr = CS_comps[&#39;CS_degincrs&#39;].tolist()[idslave_CScomp2]
            ampfac = CS_comps[&#39;CS_ampfacs&#39;].tolist()[idslave_CScomp2]
            
            DTHETA, DALPHA, DBETA = get_CS_vars(iC_slave2, DBETA)
            A_i_inclCS[iC_main] = A_i_inclCS[iC_main]/DALPHA
            phi_i_rad_str_inclCS[iC_main] = (phi_i_rad_str_inclCS[iC_main]-DBETA)%(2*np.pi)
            
            A_i_inclCS[iC_slave2] = A_i_inclCS[iC_main]*DTHETA
            phi_i_rad_str_inclCS[iC_slave2] = (phi_i_rad_str_inclCS[iC_main]+np.deg2rad(degincr))%(2*np.pi)
            
            #revert back to K2
            degincr = CS_comps[&#39;CS_degincrs&#39;].tolist()[idslave_CScomp]
            ampfac = CS_comps[&#39;CS_ampfacs&#39;].tolist()[idslave_CScomp]
            A_i_inclCS[iC_slave] = A_i_inclCS[iC_main]*ampfac
            phi_i_rad_str_inclCS[iC_slave] = (phi_i_rad_str_inclCS[iC_main]+np.deg2rad(degincr))%(2*np.pi)
        else:
            raise Exception(&#39;ERROR: length of comp_slave is invalid (%i)&#39;%(len(comp_slave)))

    phi_i_deg_str_inclCS = np.rad2deg(phi_i_rad_str_inclCS)
  
    comp_CS = pd.DataFrame({ &#39;A&#39;: A_i_inclCS, &#39;phi_deg&#39;: phi_i_deg_str_inclCS},index=const_list_inclCS)
    
    return comp_CS</code></pre>
</details>
</dd>
<dt id="hatyan.analysis_prediction.prediction"><code class="name flex">
<span>def <span class="ident">prediction</span></span>(<span>comp, times_pred_all=None, times_ext=None, timestep_min=None, nodalfactors=True, xfac=False, fu_alltimes=True, source='schureman')</span>
</code></dt>
<dd>
<div class="desc"><p>generates a tidal prediction from a set of components A and phi values.
The component set has the same timezone as the timeseries used to create it, therefore the resulting prediction will also be in that original timezone.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>comp</code></strong> :&ensp;<code>pandas.DataFrame</code></dt>
<dd>The DataFrame contains the component data with component names as index, and colums 'A' and 'phi_deg'.</dd>
<dt><strong><code>times_pred_all</code></strong> :&ensp;<code>pandas.DatetimeIndex</code>, optional</dt>
<dd>Prediction timeseries. The default is None.</dd>
<dt><strong><code>times_ext</code></strong> :&ensp;<code>list</code> of <code>datetime.datetime</code>, optional</dt>
<dd>Prediction time extents (list of start time and stop time). The default is None.</dd>
<dt><strong><code>timestep_min</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Prediction timestep in minutes. The default is None.</dd>
<dt><strong><code>nodalfactors</code></strong> :&ensp;<code>bool/int</code>, optional</dt>
<dd>Whether or not to apply nodal factors. The default is True.</dd>
<dt><strong><code>xfac</code></strong> :&ensp;<code>bool/int</code>, optional</dt>
<dd>Whether or not to apply x-factors. The default is False.</dd>
<dt><strong><code>fu_alltimes</code></strong> :&ensp;<code>bool/int</code>, optional</dt>
<dd>determines whether to calculate nodal factors in middle of the prediction period (default) or on every timestep. The default is True.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>Exception</code></dt>
<dd>DESCRIPTION.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>ts_prediction_pd</code></strong> :&ensp;<code>pandas.DataFrame</code></dt>
<dd>The DataFrame should contain a 'values' column and a pd.DatetimeIndex as index, it contains the prediction times and values.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def prediction(comp, times_pred_all=None, times_ext=None, timestep_min=None, nodalfactors=True, xfac=False, fu_alltimes=True, source=&#39;schureman&#39;):
    &#34;&#34;&#34;
    generates a tidal prediction from a set of components A and phi values.
    The component set has the same timezone as the timeseries used to create it, therefore the resulting prediction will also be in that original timezone.
    
    Parameters
    ----------
    comp : pandas.DataFrame
        The DataFrame contains the component data with component names as index, and colums &#39;A&#39; and &#39;phi_deg&#39;.
    times_pred_all : pandas.DatetimeIndex, optional
        Prediction timeseries. The default is None.
    times_ext : list of datetime.datetime, optional
        Prediction time extents (list of start time and stop time). The default is None.
    timestep_min : int, optional
        Prediction timestep in minutes. The default is None.
    nodalfactors : bool/int, optional
        Whether or not to apply nodal factors. The default is True.
    xfac : bool/int, optional
        Whether or not to apply x-factors. The default is False.
    fu_alltimes : bool/int, optional
        determines whether to calculate nodal factors in middle of the prediction period (default) or on every timestep. The default is True.

    Raises
    ------
    Exception
        DESCRIPTION.

    Returns
    -------
    ts_prediction_pd : pandas.DataFrame
        The DataFrame should contain a &#39;values&#39; column and a pd.DatetimeIndex as index, it contains the prediction times and values.

    &#34;&#34;&#34;
    
    print(&#39;-&#39;*100)
    print(&#39;PREDICTION initializing&#39;)
    print(&#39;%-20s = %s&#39;%(&#39;nodalfactors&#39;,nodalfactors))
    print(&#39;%-20s = %s&#39;%(&#39;xfac&#39;,xfac))
    print(&#39;%-20s = %s&#39;%(&#39;fu_alltimes&#39;,fu_alltimes))

    import numpy as np
    import pandas as pd
    from packaging import version
    from hatyan.hatyan_core import get_hatyan_freqs, get_hatyan_v0, get_hatyan_u, get_hatyan_f, robust_daterange_fromtimesextfreq
    from hatyan.foreman_core import get_foreman_v0_freq, get_foreman_nodalfactors
    
    COMP = comp.copy()
    
    
    if times_pred_all is None:
        if times_ext is None or timestep_min is None:
            raise Exception(&#39;if argument times_pred_all is not provided, the arguments times_ext and timestep_min are obligatory&#39;)
        else:
            times_pred_all = robust_daterange_fromtimesextfreq(times_ext,timestep_min)
    else:
        if times_ext is not None or timestep_min is not None:
            raise Exception(&#39;if argument times_pred_all is provided, the arguments times_ext and timestep_min are not allowed&#39;)

    if not len(times_pred_all) &gt; 1:
        raise Exception(&#39;ERROR: requested prediction period is not more than one timestep_min&#39;)
    
    if isinstance(times_pred_all, pd.core.indexes.datetimes.DatetimeIndex) or isinstance(times_pred_all, pd.core.indexes.base.Index):
        times_pred_all_pdDTI = times_pred_all
    else:
        times_pred_all_pdDTI = pd.DatetimeIndex(times_pred_all)
    
    print(&#39;%-20s = %s&#39;%(&#39;components used&#39;,len(comp)))
    print(&#39;%-20s = %s&#39;%(&#39;tstart&#39;,times_pred_all_pdDTI[0].strftime(&#39;%Y-%m-%d %H:%M:%S&#39;)))
    print(&#39;%-20s = %s&#39;%(&#39;tstop&#39;,times_pred_all_pdDTI[-1].strftime(&#39;%Y-%m-%d %H:%M:%S&#39;)))
    if hasattr(times_pred_all_pdDTI,&#39;freq&#39;):
        print(&#39;%-20s = %s&#39;%(&#39;timestep&#39;,times_pred_all_pdDTI.freq))
    
    dood_date_mid = pd.Index([times_pred_all_pdDTI[len(times_pred_all_pdDTI)//2]]) #middle of analysis period (2july in case of 1jan-1jan), zoals bij hatyan.
    dood_date_start = times_pred_all_pdDTI[:1] #first date (for v0, also freq?)

    #retrieve const_list and frequency in correct order
    t_const_freq_pd = get_hatyan_freqs(COMP.index.tolist())
    const_list = t_const_freq_pd.index.tolist()
    #retrieve again but now with sorted const_list
    t_const_freq_pd, t_const_speed_all = get_hatyan_freqs(const_list, dood_date=dood_date_mid, return_allraw=True)
    COMP[&#39;freq&#39;] = t_const_freq_pd[&#39;freq&#39;]
    COMP = COMP.sort_values(by=&#39;freq&#39;)

    A = np.array(COMP[&#39;A&#39;])
    phi_rad = np.array(np.deg2rad(COMP[&#39;phi_deg&#39;]))
    
    if source.lower()==&#39;schureman&#39;:
        print(&#39;v0 is calculated for start of period: %s&#39;%(dood_date_start[0]))
        v_0i_rad = get_hatyan_v0(const_list, dood_date_start).T #at start of timeseries
    elif source.lower()==&#39;foreman&#39;:
        print(&#39;v0 is calculated for start of period: %s&#39;%(dood_date_start[0]))
        v_0i_rad, dummy = get_foreman_v0_freq(const_list=const_list, dood_date=dood_date_start)
        v_0i_rad = v_0i_rad.T
    else:
        raise Exception(&#39;invalid source value (schureman or foreman)&#39;)
    
    if nodalfactors:
        if fu_alltimes:
            print(&#39;nodal factors (f and u) are calculated for all timesteps&#39;)
            dood_date_fu = times_pred_all_pdDTI
        else:
            print(&#39;nodal factors (fu) are calculated for center of period: %s&#39;%(dood_date_mid[0]))
            dood_date_fu = dood_date_mid
        if source.lower()==&#39;schureman&#39;:
            f_i = get_hatyan_f(xfac=xfac, const_list=const_list, dood_date=dood_date_fu).T
            u_i_rad = get_hatyan_u(const_list=const_list, dood_date=dood_date_fu).T
        elif source.lower()==&#39;foreman&#39;:
            f_i, u_i_rad = get_foreman_nodalfactors(const_list=const_list, dood_date=dood_date_fu)
            f_i, u_i_rad = f_i.T, u_i_rad.T
    else:
        print(&#39;no nodal factors (fu) are calculated for (f=1, u=0)&#39;)
        f_i = pd.DataFrame(np.ones(len(const_list)),index=const_list).T
        u_i_rad = pd.DataFrame(np.zeros(len(const_list)),index=const_list).T


    print(&#39;PREDICTION started&#39;)
    omega_i_rads = t_const_speed_all.T/3600 #angular frequency, 2pi/T, in rad/s, https://en.wikipedia.org/wiki/Angular_frequency (2*np.pi)/(1/x*3600) = 2*np.pi*x/3600
    if version.parse(pd.__version__) &lt; version.parse(&#39;1.2.0&#39;): #fix for non-backwards compatible change in pandas, pandas version 1.1.2 is used for RWS version.
        times_from0allpred_s_orig = (times_pred_all_pdDTI-dood_date_start[0]).total_seconds().values
    else:
        times_from0allpred_s_orig = (times_pred_all_pdDTI-dood_date_start).total_seconds().values
    times_from0allpred_s = np.transpose(times_from0allpred_s_orig[np.newaxis])

    f_A = np.multiply(f_i.values,A)
    omeg_t = np.multiply(times_from0allpred_s,omega_i_rads)#_td)
    v_u_phi = np.subtract(np.add(v_0i_rad.values,u_i_rad.values),phi_rad)
    omeg_t_v_u_phi = np.add(omeg_t,v_u_phi)
    ht_res = np.sum(np.multiply(f_A,np.cos(omeg_t_v_u_phi)),axis=1) #not necessary to add A0, since it is already part of the component list
    
    ts_prediction_pd = pd.DataFrame({&#39;values&#39;: ht_res},index=times_pred_all_pdDTI)
    print(&#39;PREDICTION finished&#39;)
    
    return ts_prediction_pd</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="hatyan" href="index.html">hatyan</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="hatyan.analysis_prediction.vectoravg" href="#hatyan.analysis_prediction.vectoravg">vectoravg</a></code></li>
<li><code><a title="hatyan.analysis_prediction.get_components_from_ts" href="#hatyan.analysis_prediction.get_components_from_ts">get_components_from_ts</a></code></li>
<li><code><a title="hatyan.analysis_prediction.analysis" href="#hatyan.analysis_prediction.analysis">analysis</a></code></li>
<li><code><a title="hatyan.analysis_prediction.split_components" href="#hatyan.analysis_prediction.split_components">split_components</a></code></li>
<li><code><a title="hatyan.analysis_prediction.prediction" href="#hatyan.analysis_prediction.prediction">prediction</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>