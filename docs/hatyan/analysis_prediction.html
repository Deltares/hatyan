<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>hatyan.analysis_prediction API documentation</title>
<meta name="description" content="analysis_prediction.py contains hatyan definitions related to tidal analysis and prediction â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>hatyan.analysis_prediction</code></h1>
</header>
<section id="section-intro">
<p>analysis_prediction.py contains hatyan definitions related to tidal analysis and prediction. </p>
<p>hatyan is a Python program for tidal analysis and prediction, based on the FORTRAN version.
Copyright (C) 2019-2021 Rijkswaterstaat.
Maintained by Deltares, contact: Jelmer Veenstra (jelmer.veenstra@deltares.nl).
Source code available at: <a href="https://github.com/Deltares/hatyan">https://github.com/Deltares/hatyan</a></p>
<p>This program is free software: you can redistribute it and/or modify
it under the terms of the GNU Lesser General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.</p>
<p>This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
See the
GNU Lesser General Public License for more details.</p>
<p>You should have received a copy of the GNU Lesser General Public License
along with this program.
If not, see <a href="https://www.gnu.org/licenses/">https://www.gnu.org/licenses/</a>.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># -*- coding: utf-8 -*-
&#34;&#34;&#34;
analysis_prediction.py contains hatyan definitions related to tidal analysis and prediction. 

hatyan is a Python program for tidal analysis and prediction, based on the FORTRAN version. 
Copyright (C) 2019-2021 Rijkswaterstaat.  Maintained by Deltares, contact: Jelmer Veenstra (jelmer.veenstra@deltares.nl). 
Source code available at: https://github.com/Deltares/hatyan

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU Lesser General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU Lesser General Public License for more details.

You should have received a copy of the GNU Lesser General Public License
along with this program.  If not, see &lt;https://www.gnu.org/licenses/&gt;.

&#34;&#34;&#34;

import numpy as np
import pandas as pd
import datetime as dt
from packaging import version

from hatyan.hatyan_core import get_const_list_hatyan, sort_const_list, robust_timedelta_sec, robust_daterange_fromtimesextfreq
from hatyan.hatyan_core import get_freqv0_generic, get_uf_generic
from hatyan.timeseries import check_ts, check_rayleigh, Timeseries_Statistics


class HatyanSettings:
    &#34;&#34;&#34;
    Settings class containing default hatyan settings, to be overwritten by input, initiate with:
    hatyan_settings = hatyan.HatyanSettings(nodalfactors=False)

    source : TYPE, optional
        DESCRIPTION. The default is &#39;schureman&#39;.
    nodalfactors : bool/int, optional
        Whether or not to apply nodal factors. The default is True.
    fu_alltimes : bool/int, optional
        Whether to calculate nodal factors in middle of the analysis/prediction period (default) or on every timestep. The default is True.
    xfac : bool/int, optional
        Whether or not to apply x-factors. The default is False.
    
    #following are only for analysis
    CS_comps : pandas.DataFrame, optional
        contains the from/derive component lists for components splitting, as well as the amplitude factor and the increase in degrees. The default is None.
    
    #following are only for get_components_from_ts
    analysis_peryear : bool/int, optional
        DESCRIPTION. The default is False.
    analysis_permonth : bool/int, optional
        caution, it tries to analyse each month, but skips it if it fails. analysis_peryear argument has priority. The default is False.
    return_allyears : bool/int, optional
        DESCRIPTION. The default is False.
    return_prediction : bool/int, optional
        Whether to generate a prediction for the ts time array. The default is False.
    
    &#34;&#34;&#34;
    #TODO: analysis_peryear,analysis_permonth,return_allyears only for get_components_from_ts, return_prediction only for analysis. Merge analysis and get_components_from_ts? Remove some from HatyanSettings class or maybe split? Add const_list to HatyanSettings?
    
    def __init__(self, source=&#39;schureman&#39;, nodalfactors=True, fu_alltimes=True, xfac=False, #prediction/analysis 
                 CS_comps=None, analysis_peryear=False, analysis_permonth=False, return_allyears=False, return_prediction=False,
                 xTxmat_condition_max=10): #analysis only
        if not isinstance(source,str):
            raise Exception(&#39;invalid source type, should be str&#39;)
        source = source.lower()
        if source not in [&#39;schureman&#39;,&#39;foreman&#39;]:
            raise Exception(&#39;invalid source {source}, should be schureman or foreman)&#39;)
        
        for var_in in [nodalfactors,fu_alltimes,xfac,
                       analysis_peryear,analysis_permonth,return_allyears,return_prediction]:
            if not isinstance(var_in,bool):
                raise Exception(f&#39;invalid {var_in} type, should be bool&#39;)
        
        if CS_comps is not None:
            if not isinstance(CS_comps,(dict,pd.DataFrame)):
                raise Exception(&#39;invalid CS_comps type, should be dict&#39;)
            CS_comps = pd.DataFrame(CS_comps) #TODO: convert all to dict or pd.DataFrame
            CS_comps_expectedkeys = [&#39;CS_comps_derive&#39;, &#39;CS_comps_from&#39;, &#39;CS_ampfacs&#39;, &#39;CS_degincrs&#39;]
            for CS_comps_key in CS_comps_expectedkeys:
                if CS_comps_key not in CS_comps.keys():
                    raise Exception(f&#39;CS_comps does not contain {CS_comps_key}&#39;)
            CS_comps_lenvals = [len(CS_comps[key]) for key in CS_comps]
            if len(np.unique(CS_comps_lenvals)) != 1:
                raise Exception(f&#39;CS_comps keys do not have equal lengths:\n{CS_comps}&#39;)
        
        self.source = source
        self.nodalfactors = nodalfactors
        self.fu_alltimes = fu_alltimes
        self.xfac = xfac
        self.CS_comps = CS_comps
        self.analysis_peryear = analysis_peryear
        self.analysis_permonth = analysis_permonth
        self.return_allyears = return_allyears
        self.return_prediction = return_prediction
        self.xTxmat_condition_max = xTxmat_condition_max
        
    def __str__(self):
        self_dict = vars(self)
        str_append = &#39;&#39;
        for key,val in self_dict.items():
            if key==&#39;CS_comps&#39; and self.CS_comps is not None:
                str_append += f&#39;{key:20s} = \n{val}\n&#39;
            else:
                str_append += f&#39;{key:20s} = {val}\n&#39;
        return str_append


def vectoravg(A_all, phi_deg_all):
    &#34;&#34;&#34;
    calculates the vector average of A and phi per constituent, 
    it vector averages over values resulting from multiple periods.
    A regular average is calculated for the amplitude of A0 (middenstand)
    
    Parameters
    ----------
    A_i_all : TYPE
        DESCRIPTION.
    phi_i_deg_all : TYPE
        DESCRIPTION.

    Returns
    -------
    A_i_mean : TYPE
        DESCRIPTION.
    phi_i_deg_mean : TYPE
        DESCRIPTION.

    &#34;&#34;&#34;
        
    phi_rad_all = np.deg2rad(phi_deg_all)
    v_cos = A_all*np.cos(phi_rad_all)
    v_sin = A_all*np.sin(phi_rad_all)
    mean_v_cos = np.mean(v_cos,axis=1)
    mean_v_sin = np.mean(v_sin,axis=1)
    A_mean = np.sqrt(mean_v_cos**2 + mean_v_sin**2)
    phi_rad_mean = np.arctan2(mean_v_sin,mean_v_cos)
    phi_rad_mean[phi_rad_mean&lt;0] = phi_rad_mean[phi_rad_mean&lt;0]+(2*np.pi)
    
    #if phases of all years are exactly 0, it is the A0 component. Overwrite this A0 with mean amplitude and zero phase if present, otherwise negative values will become positive with 180 phase
    idx_A0 = np.where((phi_deg_all==0).any(axis=1))[0]
    A_mean[idx_A0] = np.mean(A_all[idx_A0,:])
    phi_rad_mean[idx_A0] = 0
    
    phi_deg_mean = np.rad2deg(phi_rad_mean)
    
    return A_mean, phi_deg_mean


def get_components_from_ts(ts, const_list, hatyan_settings=None, **kwargs):#nodalfactors=True, xfac=False, fu_alltimes=True, CS_comps=None, analysis_peryear=False, analysis_permonth=False, source=&#39;schureman&#39;):
    &#34;&#34;&#34;
    Wrapper around the analysis() function, 
    it optionally processes a timeseries per year and vector averages the results afterwards, 
    passes the rest of the arguments on to analysis function
    The timezone of the timeseries, will also be reflected in the phases of the resulting component set, so the resulting component set can be used to make a prediction in the original timezone.
    
    Parameters
    ----------
    ts : pandas.DataFrame
        The DataFrame should contain a &#39;values&#39; column and a pd.DatetimeIndex as index, it contains the timeseries to be analysed, as obtained from e.g. readts_*.
    const_list : list, pandas.Series or str
        list or pandas.Series: contains the tidal constituent names for which to analyse the provided timeseries ts. 
        str: a predefined name of a component set for hatyan_core.get_const_list_hatyan()
    hatyan_settings : hatyan.HatyanSettings()
        Contains the used settings

    Raises
    ------
    Exception
        DESCRIPTION.

    Returns
    -------
    COMP_mean_pd : pandas.DataFrame
        The DataFrame contains the component data with component names as index, and colums &#39;A&#39; and &#39;phi_deg&#39;.
    COMP_all_pd : pandas.DataFrame, optional
        The same as COMP_mean_pd, but with all years added with MultiIndex
    &#34;&#34;&#34;
    ts_pd = ts
    
    if hatyan_settings is None:
        hatyan_settings = HatyanSettings(**kwargs)
    elif len(kwargs)&gt;0:
        raise Exception(&#39;both arguments hatyan_settings and other settings (e.g. nodalfactors) are provided, this is not valid&#39;)
    
    print(&#39;-&#39;*50)
    print(&#39;running: get_components_from_ts&#39;)
    
    if type(const_list) is str:
        const_list = get_const_list_hatyan(const_list)
    elif type(const_list) is not list:
        const_list = const_list.tolist()
    if hatyan_settings.CS_comps is None:
        n_const = len(const_list)
    else:
        n_const = len(const_list) + len(hatyan_settings.CS_comps)

    if hatyan_settings.analysis_peryear or hatyan_settings.analysis_permonth:
        if hatyan_settings.analysis_peryear:
            print(&#39;analysis_peryear=True, separate years are automatically determined from unique calendar years in timeseries&#39;)
            ts_years_dt = ts_pd.index.year.unique()
            ts_years = ts_pd.index.year.unique()
        else:
            print(&#39;analysis_permonth=True, separate month/year combinations are automatically determined from unique calendar months/years in timeseries&#39;)
            ts_years_dt = pd.date_range(start=ts_pd.index[0], end=ts_pd.index[-1], freq=&#39;M&#39;)
            ts_years = [&#39;%d-%02d&#39;%(x.year,x.month) for x in ts_years_dt]

        n_years = len(ts_years)
        A_i_all = np.zeros((n_const,n_years))*np.nan
        phi_i_deg_all = np.zeros((n_const,n_years))*np.nan
        for iY, year_dt in enumerate(ts_years_dt):
            if hatyan_settings.analysis_peryear:
                print(&#39;analyzing %d of sequence %s&#39;%(year_dt,ts_years.tolist()))
                ts_oneyear_pd = ts_pd[ts_pd.index.year==year_dt]
                COMP_one = analysis(ts_oneyear_pd, const_list=const_list, hatyan_settings=hatyan_settings)
                A_i_all[:,iY] = COMP_one.loc[:,&#39;A&#39;]
                phi_i_deg_all[:,iY] = COMP_one.loc[:,&#39;phi_deg&#39;]
            else:
                print(&#39;analyzing %d-%02d of sequence [%s]&#39;%(year_dt.year, year_dt.month, &#39;, &#39;.join(ts_years)))
                ts_oneyear_pd = ts_pd[(ts_pd.index.year==year_dt.year) &amp; (ts_pd.index.month==year_dt.month)]
                try:
                    COMP_one = analysis(ts_oneyear_pd, const_list=const_list, hatyan_settings=hatyan_settings)
                    A_i_all[:,iY] = COMP_one.loc[:,&#39;A&#39;]
                    phi_i_deg_all[:,iY] = COMP_one.loc[:,&#39;phi_deg&#39;]
                except Exception as e:
                    print(&#39;WARNING: analysis of %d-%02d failed, error message: &#34;%s&#39;%(year_dt.year,year_dt.month,e))
        if np.isnan(A_i_all).all():
            raise Exception(&#39;analysis peryear or permonth failed for all years/months, check warnings above&#39;)
        
        COMP_all_pd = pd.DataFrame(data=np.hstack([A_i_all,phi_i_deg_all]), columns=pd.MultiIndex.from_product([[&#39;A&#39;,&#39;phi_deg&#39;],ts_years]), index=COMP_one.index)
        print(&#39;vector averaging analysis results&#39;)
        A_i_mean, phi_i_deg_mean = vectoravg(A_all=A_i_all, phi_deg_all=phi_i_deg_all)
        COMP_mean_pd = pd.DataFrame({ &#39;A&#39;: A_i_mean, &#39;phi_deg&#39;: phi_i_deg_mean},index=COMP_one.index)

    else: #dummy values, COMP_years should be equal to COMP_mean
        COMP_mean_pd = analysis(ts_pd, const_list=const_list, hatyan_settings=hatyan_settings)
        COMP_all_pd = None
    
    if hatyan_settings.return_allyears:
        return COMP_mean_pd, COMP_all_pd
    else:
        return COMP_mean_pd


def analysis(ts, const_list, hatyan_settings=None, **kwargs):#nodalfactors=True, xfac=False, fu_alltimes=True, CS_comps=None, return_prediction=False, source=&#39;schureman&#39;):
    &#34;&#34;&#34;
    harmonic analysis with matrix transformations (least squares fit), optionally with component splitting
    for details about arguments and return variables, see get_components_from_ts() definition
    
    &#34;&#34;&#34;
    
    if hatyan_settings is None:
        hatyan_settings = HatyanSettings(**kwargs)
    elif len(kwargs)&gt;0:
        raise Exception(&#39;both arguments hatyan_settings and other settings (e.g. nodalfactors) are provided, this is not valid&#39;)

    print(&#39;-&#39;*50)
    print(&#39;ANALYSIS initializing&#39;)
    print(hatyan_settings)
        
    #drop duplicate times
    ts_pd = ts[~ts.index.duplicated(keep=&#39;first&#39;)]
    if len(ts_pd) != len(ts):
        print(&#39;WARNING: %i duplicate times of the input timeseries were dropped prior to the analysis&#39;%(len(ts)-len(ts_pd)))
    print(f&#39;#timesteps           = {len(ts)}&#39;)
    print(f&#39;tstart               = {ts.index[0].strftime(&#34;%Y-%m-%d %H:%M:%S&#34;)}&#39;)
    print(f&#39;tstop                = {ts.index[-1].strftime(&#34;%Y-%m-%d %H:%M:%S&#34;)}&#39;)
    if hasattr(ts.index,&#39;freq&#39;):
        print(f&#39;timestep             = {ts.index.freq}&#39;)
    
    #retrieving and sorting const_list
    if type(const_list) is str:
        const_list = get_const_list_hatyan(const_list)
    elif type(const_list) is not list:
        const_list = const_list.tolist()
    const_list = sort_const_list(const_list)
    print(f&#39;components analyzed  = {len(const_list)}&#39;)
    
    #check for duplicate components (results in singular matrix)
    if len(const_list) != len(np.unique(const_list)):
        const_list_uniq, const_list_uniq_counts = np.unique(const_list,return_counts=True)
        const_list_counts = pd.DataFrame({&#39;constituent&#39;:const_list_uniq,&#39;occurences&#39;:const_list_uniq_counts})
        raise Exception(&#39;remove duplicate constituents from const_list:\n%s&#39;%(const_list_counts.loc[const_list_counts[&#39;occurences&#39;]&gt;1]))
    
    #remove nans
    ts_pd_nonan = ts_pd[~ts_pd[&#39;values&#39;].isna()]
    if len(ts_pd_nonan)==0:
        raise Exception(&#39;provided timeseries only contains nan values, analysis not possible&#39;)
    times_pred_all_pdDTI = pd.DatetimeIndex(ts_pd_nonan.index)
    percentage_nan = 100-len(ts_pd_nonan[&#39;values&#39;])/len(ts_pd[&#39;values&#39;])*100
    print(f&#39;percentage_nan in values_meas_sel: {percentage_nan:.2f}%&#39;)
    
    #get times and time array
    dood_date_mid = pd.Index([ts_pd.index[len(ts_pd.index)//2]]) #middle of analysis period (2july in case of 1jan-1jan), zoals bij hatyan #TODO: this is incorrect in case of e.g. more missings in first half of year than second half
    dood_date_start = ts_pd.index[[0]] #first date (for v0, also freq?)
    if hatyan_settings.fu_alltimes:
        dood_date_fu = times_pred_all_pdDTI
    else:
        dood_date_fu = dood_date_mid
    #times_from0_s = (pd.DatetimeIndex(ts_pd_nonan.index)-dood_date_start[0]).total_seconds().values
    times_from0_s, fancy_pddt = robust_timedelta_sec(ts_pd_nonan.index,refdate_dt=dood_date_start[0])
    times_from0_s = times_from0_s[:,np.newaxis]
    
    #get frequency and v0
    t_const_freq_pd, v_0i_rad = get_freqv0_generic(hatyan_settings, const_list, dood_date_mid, dood_date_start)
    omega_i_rads = t_const_freq_pd[[&#39;freq&#39;]].values.T*(2*np.pi)/3600 #angular frequency, 2pi/T, in rad/s, https://en.wikipedia.org/wiki/Angular_frequency (2*np.pi)/(1/x*3600) = 2*np.pi*x/3600
    u_i_rad, f_i = get_uf_generic(hatyan_settings, const_list, dood_date_fu)
    v_u = v_0i_rad.values + u_i_rad.values
    
    check_rayleigh(ts_pd,t_const_freq_pd)
    
    #TODO: nyquist stuk code generieker maken met Henrique
    stats = Timeseries_Statistics(ts=ts_pd)
    unique_timesteps = stats.stats[&#39;timeseries unique timesteps (minutes)&#39;]
    if len(unique_timesteps)==1: #constant freq, so folding is possible
        constant_freq_phr = list(unique_timesteps)[0]/60
        fs = 1/constant_freq_phr
        nyquist_freq = 0.5*fs
        bool_isnyquist = t_const_freq_pd[&#39;freq&#39;]==nyquist_freq
        if bool_isnyquist.any():
            raise Exception(f&#39;there is a component on the Nyquist frequency ({nyquist_freq} [1/hr]), this not possible:\n{t_const_freq_pd.loc[bool_isnyquist]}&#39;)
        bool_freqtoohigh = t_const_freq_pd[&#39;freq&#39;]&gt;nyquist_freq
        t_const_freq_pd_folded = t_const_freq_pd.copy()
        t_const_freq_pd_folded.loc[bool_freqtoohigh,&#39;freq&#39;] = np.abs(fs - t_const_freq_pd_folded.loc[bool_freqtoohigh,&#39;freq&#39;] ) #remainder is better: 0.408%(1/3)
        t_const_freq_pd_folded = t_const_freq_pd_folded.sort_values(&#39;freq&#39;) #TODO: sorting also done in rayleigh check
        print(&#39;check folded rayleigh&#39;)
        check_rayleigh(ts_pd,t_const_freq_pd_folded)
    
    #### TIMESERIES ANALYSIS
    N = len(const_list)
    m = len(ts_pd_nonan[&#39;values&#39;])
    
    # get xmat and make dot product
    xmat = np.zeros((m,2*N))
    xmat[:,:N] = f_i.values * np.cos(omega_i_rads*times_from0_s+v_u)
    xmat[:,N:] = f_i.values * np.sin(omega_i_rads*times_from0_s+v_u)
    
    xTmat = xmat.T
    print(&#39;calculating xTx matrix&#39;)
    tic = dt.datetime.now()
    xTxmat = np.dot(xTmat,xmat)
    
    if 0:
        #TODO
        xTxmat2 = xTxmat/xTxmat[0,0]
        xTxmat2[np.abs(xTxmat2)&lt;0.05] = 0
        xTxmat2_condition = np.linalg.cond(xTxmat2)
        svd_u,svd_s,svd_vh = np.linalg.svd(xTxmat2) # s zijn singuliere waarden van groot naar klein, u en v zijn gespiegeld over diagonaal
        xTxmat2_check = svd_u@np.diag(svd_s)@svd_vh #matrix multiplicatie geeft weer originele matrix (ongeveer)
        xTxmat2_check = svd_u[:,:2]@np.diag(svd_s[:2])@svd_vh[:2,:] #helft van info weggooien, geeft approximatie van originele matrix
        
        #samp freq is 3hr, freq [1/hr],dus fs is 1/3, nyquist freq is 1/6 (0.5*fs)
        #probleem is freq van 3M2S10 (0.408201 [1/hr]) is groter dan 1/6
    
    print(&#39;xTx matrix calculated&#39;)
    if &#39;A0&#39; in const_list: #correct center value [N,N] for better matrix condition
        xTxmat_condition = np.linalg.cond(xTxmat)
        print(&#39;condition of xTx matrix before center adjustment for A0: %.2f&#39;%(xTxmat_condition))
        xTxmat[N,N] = m
    xTxmat_condition = np.linalg.cond(xTxmat)
    print(&#39;condition of xTx matrix: %.2f&#39;%(xTxmat_condition))
    if xTxmat_condition &gt; hatyan_settings.xTxmat_condition_max:#10:#100: #random treshold
        raise Exception(f&#39;ERROR: condition of xTx matrix is too high ({xTxmat_condition:.2f}), check your timeseries length, try different (shorter) component set or componentsplitting.\nAnalysed {check_ts(ts_pd)}&#39;)
    xTymat = np.dot(xTmat,ts_pd_nonan[&#39;values&#39;].values)
    
    #solve matrix to get beta_roof_mat (and thus a, b)
    beta_roof_mat = np.linalg.solve(xTxmat,xTymat)
    print(&#39;matrix system solved, elapsed time: %s&#39;%(dt.datetime.now()-tic))

    phi_i_rad = np.arctan2(beta_roof_mat[N:],beta_roof_mat[:N]) #(a,b) arctan_ab
    A_i = np.sqrt(beta_roof_mat[N:]**2 + beta_roof_mat[:N]**2) #(a,b) sqsqrt_ab

    COMP_pd = pd.DataFrame({&#39;A&#39;: A_i, &#39;phi_deg&#39;: np.rad2deg(phi_i_rad%(2*np.pi))}, index=const_list)
    if &#39;A0&#39; in COMP_pd.index: #correct 180 degrees A0 phase by making amplitude value negative
        if COMP_pd.loc[&#39;A0&#39;,&#39;phi_deg&#39;]==180:
            COMP_pd.loc[&#39;A0&#39;,&#39;A&#39;] = -COMP_pd.loc[&#39;A0&#39;,&#39;A&#39;]
            COMP_pd.loc[&#39;A0&#39;,&#39;phi_deg&#39;] = 0
    
    if hatyan_settings.CS_comps is not None:
        COMP_pd = split_components(comp=COMP_pd, dood_date_mid=dood_date_mid, hatyan_settings=hatyan_settings)
        
    print(&#39;ANALYSIS finished&#39;)
    
    if hatyan_settings.return_prediction:
        print(&#39;immediately generating a prediction for the same time array as the input ts&#39;)
        ts_prediction = prediction(comp=COMP_pd, times_pred_all=ts_pd.index, hatyan_settings=hatyan_settings)
        return COMP_pd, ts_prediction
    else:
        return COMP_pd


def split_components(comp, dood_date_mid, hatyan_settings=None, **kwargs):
    &#34;&#34;&#34;
    component splitting function
    for details about arguments and return variables, see get_components_from_ts() definition

    &#34;&#34;&#34;
    
    if hatyan_settings is None:
        hatyan_settings = HatyanSettings(**kwargs)
    elif len(kwargs)&gt;0:
        raise Exception(&#39;both arguments hatyan_settings and other settings (e.g. nodalfactors) are provided, this is not valid&#39;)
        
    #create sorted and complete component list
    const_list_inclCS_raw = comp.index.tolist() + hatyan_settings.CS_comps[&#39;CS_comps_derive&#39;].tolist()
    const_list_inclCS = sort_const_list(const_list=const_list_inclCS_raw)

    #retrieve freq and speed
    t_const_freq_pd, CS_v_0i_rad = get_freqv0_generic(hatyan_settings, const_list=const_list_inclCS, dood_date_mid=dood_date_mid, dood_date_start=dood_date_mid) # with split_components, v0 is calculated on the same timestep as u and f (middle of original series)
    CS_u_i_rad, CS_f_i = get_uf_generic(hatyan_settings, const_list=const_list_inclCS, dood_date_fu=dood_date_mid)
    
    comp_inclCS = pd.DataFrame(comp,index=const_list_inclCS,columns=comp.columns)
    #comp_inclCS_preCS = comp_inclCS.copy()
        
    for comp_main in np.unique(hatyan_settings.CS_comps[&#39;CS_comps_from&#39;]):
        bool_CS_maincomp = hatyan_settings.CS_comps[&#39;CS_comps_from&#39;] == comp_main #boolean of which rows of CS_comps dataframe corresponds to a main constituent, also makes it possible to select two rows
        CS_comps_formain = hatyan_settings.CS_comps.loc[bool_CS_maincomp]
        comp_slave_list = CS_comps_formain[&#39;CS_comps_derive&#39;].tolist()
        print(f&#39;splitting component {comp_main} into {comp_slave_list}&#39;)
        
        #first update main components based on degincrs/ampfacs of all components that are to be derived
        DBETA = 0
        for iR, CS_comps_row in CS_comps_formain.iterrows():
            comp_slave = CS_comps_row[&#39;CS_comps_derive&#39;]
            #code from resuda.f, line 440 to 455
            DMU = CS_f_i.loc[0,comp_slave]/CS_f_i.loc[0,comp_main]
            DTHETA = CS_comps_row[&#39;CS_ampfacs&#39;]
            DGAMMA = np.deg2rad(CS_comps_row[&#39;CS_degincrs&#39;])-DBETA-(CS_v_0i_rad.loc[0,comp_slave]+CS_u_i_rad.loc[0,comp_slave])+(CS_v_0i_rad.loc[0,comp_main]+CS_u_i_rad.loc[0,comp_main]) #in FORTRAN code, CS_f_i slave/main is also added, this seems wrong
            DREEEL = 1+DMU*DTHETA*np.cos(DGAMMA)
            DIMAGI = DMU*DTHETA*np.sin(DGAMMA)  
            DALPHA = np.sqrt(DREEEL*DREEEL+DIMAGI*DIMAGI)
            if DALPHA &lt; 1e-50:
                raise Exception(&#39;ERROR: DALPHA too small, component splitting failed?&#39;)
            DBETA = np.arctan2(DIMAGI,DREEEL)
            
            comp_inclCS.loc[comp_main,&#39;A&#39;] = comp_inclCS.loc[comp_main,&#39;A&#39;]/DALPHA
            comp_inclCS.loc[comp_main,&#39;phi_deg&#39;] = (comp_inclCS.loc[comp_main,&#39;phi_deg&#39;]-np.rad2deg(DBETA))%360 
        
        #updating slave components after updating main components, this makes a difference when splitting a component into more than two
        for iR, CS_comps_row in CS_comps_formain.iterrows():
            comp_slave = CS_comps_row[&#39;CS_comps_derive&#39;]
            comp_inclCS.loc[comp_slave,&#39;A&#39;] = comp_inclCS.loc[comp_main,&#39;A&#39;] * CS_comps_row[&#39;CS_ampfacs&#39;]
            comp_inclCS.loc[comp_slave,&#39;phi_deg&#39;] = (comp_inclCS.loc[comp_main,&#39;phi_deg&#39;] + CS_comps_row[&#39;CS_degincrs&#39;])%360
            
    return comp_inclCS


def prediction(comp, times_pred_all=None, times_ext=None, timestep_min=None, hatyan_settings=None, **kwargs):
    &#34;&#34;&#34;
    generates a tidal prediction from a set of components A and phi values.
    The component set has the same timezone as the timeseries used to create it, therefore the resulting prediction will also be in that original timezone.
    
    Parameters
    ----------
    comp : pandas.DataFrame
        The DataFrame contains the component data with component names as index, and colums &#39;A&#39; and &#39;phi_deg&#39;.
    times_pred_all : pandas.DatetimeIndex, optional
        Prediction timeseries. The default is None.
    times_ext : list of datetime.datetime, optional
        Prediction time extents (list of start time and stop time). The default is None.
    timestep_min : int, optional
        Prediction timestep in minutes. The default is None.
    hatyan_settings : hatyan.HatyanSettings()
        Contains the used settings

    Raises
    ------
    Exception
        DESCRIPTION.

    Returns
    -------
    ts_prediction_pd : pandas.DataFrame
        The DataFrame should contain a &#39;values&#39; column and a pd.DatetimeIndex as index, it contains the prediction times and values.
    
    &#34;&#34;&#34;
    
    if hatyan_settings is None:
        hatyan_settings = HatyanSettings(**kwargs)
    elif len(kwargs)&gt;0:
        raise Exception(&#39;both arguments hatyan_settings and other settings (e.g. nodalfactors) are provided, this is not valid&#39;)
    
    print(&#39;-&#39;*50)
    print(&#39;PREDICTION initializing&#39;)
    print(hatyan_settings)
    
    if times_pred_all is None:
        if times_ext is None or timestep_min is None:
            raise Exception(&#39;if argument times_pred_all is not provided, the arguments times_ext and timestep_min are obligatory&#39;)
        else:
            times_pred_all = robust_daterange_fromtimesextfreq(times_ext,timestep_min)
    else:
        if times_ext is not None or timestep_min is not None:
            raise Exception(&#39;if argument times_pred_all is provided, the arguments times_ext and timestep_min are not allowed&#39;)
    
    if not len(times_pred_all) &gt; 1:
        raise Exception(&#39;ERROR: requested prediction period is not more than one timestep_min&#39;)
    
    if isinstance(times_pred_all, pd.core.indexes.datetimes.DatetimeIndex) or isinstance(times_pred_all, pd.core.indexes.base.Index):
        times_pred_all_pdDTI = times_pred_all
    else:
        times_pred_all_pdDTI = pd.DatetimeIndex(times_pred_all)
    
    print(&#39;%-20s = %s&#39;%(&#39;components used&#39;,len(comp)))
    print(&#39;%-20s = %s&#39;%(&#39;tstart&#39;,times_pred_all_pdDTI[0].strftime(&#39;%Y-%m-%d %H:%M:%S&#39;)))
    print(&#39;%-20s = %s&#39;%(&#39;tstop&#39;,times_pred_all_pdDTI[-1].strftime(&#39;%Y-%m-%d %H:%M:%S&#39;)))
    if hasattr(times_pred_all_pdDTI,&#39;freq&#39;):
        print(&#39;%-20s = %s&#39;%(&#39;timestep&#39;,times_pred_all_pdDTI.freq))
    
    dood_date_mid = pd.Index([times_pred_all_pdDTI[len(times_pred_all_pdDTI)//2]]) #middle of analysis period (2july in case of 1jan-1jan), zoals bij hatyan.
    dood_date_start = times_pred_all_pdDTI[:1] #first date (for v0, also freq?)
    
    #sort component list and component dataframe
    if np.isnan(comp.values).any():
        raise Exception(&#39;provided component set contains nan values, prediction not possible&#39;)
    const_list = sort_const_list(comp.index.tolist())
    COMP = comp.loc[const_list]
    A = np.array(COMP[&#39;A&#39;])
    phi_rad = np.array(np.deg2rad(COMP[&#39;phi_deg&#39;]))

    t_const_freq_pd, v_0i_rad = get_freqv0_generic(hatyan_settings, const_list, dood_date_mid, dood_date_start)
    t_const_speed_all = t_const_freq_pd[&#39;freq&#39;].values[:,np.newaxis]*(2*np.pi)

    if hatyan_settings.fu_alltimes:
        dood_date_fu = times_pred_all_pdDTI
    else:
        dood_date_fu = dood_date_mid
    u_i_rad, f_i = get_uf_generic(hatyan_settings, const_list, dood_date_fu)

    print(&#39;PREDICTION started&#39;)
    omega_i_rads = t_const_speed_all.T/3600 #angular frequency, 2pi/T, in rad/s, https://en.wikipedia.org/wiki/Angular_frequency (2*np.pi)/(1/x*3600) = 2*np.pi*x/3600
    if ~isinstance(times_pred_all_pdDTI,pd.DatetimeIndex) &amp; (version.parse(pd.__version__) &gt;= version.parse(&#39;1.2.0&#39;)): #fix for non-backwards compatible change in pandas, pandas version 1.1.2 is used for RWS version. TODO: remove this fix once pandas&gt;=1.2.0 can be used (probably py3.7 required)
        times_from0allpred_s_orig = (times_pred_all_pdDTI-dood_date_start).total_seconds().values
    else:
        times_from0allpred_s_orig = (times_pred_all_pdDTI-dood_date_start[0]).total_seconds().values
    times_from0allpred_s = np.transpose(times_from0allpred_s_orig[np.newaxis])
    
    f_A = np.multiply(f_i.values,A)
    omeg_t = np.multiply(times_from0allpred_s,omega_i_rads)#_td)
    v_u_phi = np.subtract(np.add(v_0i_rad.values,u_i_rad.values),phi_rad)
    omeg_t_v_u_phi = np.add(omeg_t,v_u_phi)
    ht_res = np.sum(np.multiply(f_A,np.cos(omeg_t_v_u_phi)),axis=1) #not necessary to add A0, since it is already part of the component list
    
    ts_prediction_pd = pd.DataFrame({&#39;values&#39;: ht_res},index=times_pred_all_pdDTI)
    print(&#39;PREDICTION finished&#39;)
    
    return ts_prediction_pd


def prediction_peryear(comp_allyears, timestep_min, hatyan_settings=None, **kwargs):
    &#34;&#34;&#34;
    Wrapper around prediction(), to use component set of multiple years to generate multi-year timeseries.

    Parameters
    ----------
    comp_allyears : TYPE
        DESCRIPTION.
    timestep_min : TYPE
        DESCRIPTION.
    hatyan_settings : hatyan.HatyanSettings()
        Contains the used settings
        
    Returns
    -------
    ts_prediction_peryear : TYPE
        DESCRIPTION.

    &#34;&#34;&#34;
    
    if hatyan_settings is None:
        hatyan_settings = HatyanSettings(**kwargs)
    elif len(kwargs)&gt;0:
        raise Exception(&#39;both arguments hatyan_settings and other settings (e.g. nodalfactors) are provided, this is not valid&#39;)

    list_years = comp_allyears.columns.levels[1]
    ts_prediction_peryear = pd.DataFrame()
    for year in list_years:
        print(&#39;generating prediction %d of sequence %s&#39;%(year,list(list_years)))
        comp_oneyear = comp_allyears.loc[:,(slice(None),year)]
        comp_oneyear.columns = comp_oneyear.columns.droplevel(1)
        times_ext = [dt.datetime(year,1,1),dt.datetime(year+1,1,1)-dt.timedelta(minutes=timestep_min)]
        ts_prediction_oneyear = prediction(comp=comp_oneyear,times_ext=times_ext, timestep_min=timestep_min, hatyan_settings=hatyan_settings)
        ts_prediction_peryear = ts_prediction_peryear.append(ts_prediction_oneyear)
    return ts_prediction_peryear</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="hatyan.analysis_prediction.vectoravg"><code class="name flex">
<span>def <span class="ident">vectoravg</span></span>(<span>A_all, phi_deg_all)</span>
</code></dt>
<dd>
<div class="desc"><p>calculates the vector average of A and phi per constituent,
it vector averages over values resulting from multiple periods.
A regular average is calculated for the amplitude of A0 (middenstand)</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>A_i_all</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>DESCRIPTION.</dd>
<dt><strong><code>phi_i_deg_all</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>DESCRIPTION.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>A_i_mean</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>DESCRIPTION.</dd>
<dt><strong><code>phi_i_deg_mean</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>DESCRIPTION.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def vectoravg(A_all, phi_deg_all):
    &#34;&#34;&#34;
    calculates the vector average of A and phi per constituent, 
    it vector averages over values resulting from multiple periods.
    A regular average is calculated for the amplitude of A0 (middenstand)
    
    Parameters
    ----------
    A_i_all : TYPE
        DESCRIPTION.
    phi_i_deg_all : TYPE
        DESCRIPTION.

    Returns
    -------
    A_i_mean : TYPE
        DESCRIPTION.
    phi_i_deg_mean : TYPE
        DESCRIPTION.

    &#34;&#34;&#34;
        
    phi_rad_all = np.deg2rad(phi_deg_all)
    v_cos = A_all*np.cos(phi_rad_all)
    v_sin = A_all*np.sin(phi_rad_all)
    mean_v_cos = np.mean(v_cos,axis=1)
    mean_v_sin = np.mean(v_sin,axis=1)
    A_mean = np.sqrt(mean_v_cos**2 + mean_v_sin**2)
    phi_rad_mean = np.arctan2(mean_v_sin,mean_v_cos)
    phi_rad_mean[phi_rad_mean&lt;0] = phi_rad_mean[phi_rad_mean&lt;0]+(2*np.pi)
    
    #if phases of all years are exactly 0, it is the A0 component. Overwrite this A0 with mean amplitude and zero phase if present, otherwise negative values will become positive with 180 phase
    idx_A0 = np.where((phi_deg_all==0).any(axis=1))[0]
    A_mean[idx_A0] = np.mean(A_all[idx_A0,:])
    phi_rad_mean[idx_A0] = 0
    
    phi_deg_mean = np.rad2deg(phi_rad_mean)
    
    return A_mean, phi_deg_mean</code></pre>
</details>
</dd>
<dt id="hatyan.analysis_prediction.get_components_from_ts"><code class="name flex">
<span>def <span class="ident">get_components_from_ts</span></span>(<span>ts, const_list, hatyan_settings=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Wrapper around the analysis() function,
it optionally processes a timeseries per year and vector averages the results afterwards,
passes the rest of the arguments on to analysis function
The timezone of the timeseries, will also be reflected in the phases of the resulting component set, so the resulting component set can be used to make a prediction in the original timezone.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>ts</code></strong> :&ensp;<code>pandas.DataFrame</code></dt>
<dd>The DataFrame should contain a 'values' column and a pd.DatetimeIndex as index, it contains the timeseries to be analysed, as obtained from e.g. readts_*.</dd>
<dt><strong><code>const_list</code></strong> :&ensp;<code>list, pandas.Series</code> or <code>str</code></dt>
<dd>list or pandas.Series: contains the tidal constituent names for which to analyse the provided timeseries ts.
str: a predefined name of a component set for hatyan_core.get_const_list_hatyan()</dd>
<dt><strong><code>hatyan_settings</code></strong> :&ensp;<code>hatyan.HatyanSettings()</code></dt>
<dd>Contains the used settings</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>Exception</code></dt>
<dd>DESCRIPTION.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>COMP_mean_pd</code></strong> :&ensp;<code>pandas.DataFrame</code></dt>
<dd>The DataFrame contains the component data with component names as index, and colums 'A' and 'phi_deg'.</dd>
<dt><strong><code>COMP_all_pd</code></strong> :&ensp;<code>pandas.DataFrame</code>, optional</dt>
<dd>The same as COMP_mean_pd, but with all years added with MultiIndex</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_components_from_ts(ts, const_list, hatyan_settings=None, **kwargs):#nodalfactors=True, xfac=False, fu_alltimes=True, CS_comps=None, analysis_peryear=False, analysis_permonth=False, source=&#39;schureman&#39;):
    &#34;&#34;&#34;
    Wrapper around the analysis() function, 
    it optionally processes a timeseries per year and vector averages the results afterwards, 
    passes the rest of the arguments on to analysis function
    The timezone of the timeseries, will also be reflected in the phases of the resulting component set, so the resulting component set can be used to make a prediction in the original timezone.
    
    Parameters
    ----------
    ts : pandas.DataFrame
        The DataFrame should contain a &#39;values&#39; column and a pd.DatetimeIndex as index, it contains the timeseries to be analysed, as obtained from e.g. readts_*.
    const_list : list, pandas.Series or str
        list or pandas.Series: contains the tidal constituent names for which to analyse the provided timeseries ts. 
        str: a predefined name of a component set for hatyan_core.get_const_list_hatyan()
    hatyan_settings : hatyan.HatyanSettings()
        Contains the used settings

    Raises
    ------
    Exception
        DESCRIPTION.

    Returns
    -------
    COMP_mean_pd : pandas.DataFrame
        The DataFrame contains the component data with component names as index, and colums &#39;A&#39; and &#39;phi_deg&#39;.
    COMP_all_pd : pandas.DataFrame, optional
        The same as COMP_mean_pd, but with all years added with MultiIndex
    &#34;&#34;&#34;
    ts_pd = ts
    
    if hatyan_settings is None:
        hatyan_settings = HatyanSettings(**kwargs)
    elif len(kwargs)&gt;0:
        raise Exception(&#39;both arguments hatyan_settings and other settings (e.g. nodalfactors) are provided, this is not valid&#39;)
    
    print(&#39;-&#39;*50)
    print(&#39;running: get_components_from_ts&#39;)
    
    if type(const_list) is str:
        const_list = get_const_list_hatyan(const_list)
    elif type(const_list) is not list:
        const_list = const_list.tolist()
    if hatyan_settings.CS_comps is None:
        n_const = len(const_list)
    else:
        n_const = len(const_list) + len(hatyan_settings.CS_comps)

    if hatyan_settings.analysis_peryear or hatyan_settings.analysis_permonth:
        if hatyan_settings.analysis_peryear:
            print(&#39;analysis_peryear=True, separate years are automatically determined from unique calendar years in timeseries&#39;)
            ts_years_dt = ts_pd.index.year.unique()
            ts_years = ts_pd.index.year.unique()
        else:
            print(&#39;analysis_permonth=True, separate month/year combinations are automatically determined from unique calendar months/years in timeseries&#39;)
            ts_years_dt = pd.date_range(start=ts_pd.index[0], end=ts_pd.index[-1], freq=&#39;M&#39;)
            ts_years = [&#39;%d-%02d&#39;%(x.year,x.month) for x in ts_years_dt]

        n_years = len(ts_years)
        A_i_all = np.zeros((n_const,n_years))*np.nan
        phi_i_deg_all = np.zeros((n_const,n_years))*np.nan
        for iY, year_dt in enumerate(ts_years_dt):
            if hatyan_settings.analysis_peryear:
                print(&#39;analyzing %d of sequence %s&#39;%(year_dt,ts_years.tolist()))
                ts_oneyear_pd = ts_pd[ts_pd.index.year==year_dt]
                COMP_one = analysis(ts_oneyear_pd, const_list=const_list, hatyan_settings=hatyan_settings)
                A_i_all[:,iY] = COMP_one.loc[:,&#39;A&#39;]
                phi_i_deg_all[:,iY] = COMP_one.loc[:,&#39;phi_deg&#39;]
            else:
                print(&#39;analyzing %d-%02d of sequence [%s]&#39;%(year_dt.year, year_dt.month, &#39;, &#39;.join(ts_years)))
                ts_oneyear_pd = ts_pd[(ts_pd.index.year==year_dt.year) &amp; (ts_pd.index.month==year_dt.month)]
                try:
                    COMP_one = analysis(ts_oneyear_pd, const_list=const_list, hatyan_settings=hatyan_settings)
                    A_i_all[:,iY] = COMP_one.loc[:,&#39;A&#39;]
                    phi_i_deg_all[:,iY] = COMP_one.loc[:,&#39;phi_deg&#39;]
                except Exception as e:
                    print(&#39;WARNING: analysis of %d-%02d failed, error message: &#34;%s&#39;%(year_dt.year,year_dt.month,e))
        if np.isnan(A_i_all).all():
            raise Exception(&#39;analysis peryear or permonth failed for all years/months, check warnings above&#39;)
        
        COMP_all_pd = pd.DataFrame(data=np.hstack([A_i_all,phi_i_deg_all]), columns=pd.MultiIndex.from_product([[&#39;A&#39;,&#39;phi_deg&#39;],ts_years]), index=COMP_one.index)
        print(&#39;vector averaging analysis results&#39;)
        A_i_mean, phi_i_deg_mean = vectoravg(A_all=A_i_all, phi_deg_all=phi_i_deg_all)
        COMP_mean_pd = pd.DataFrame({ &#39;A&#39;: A_i_mean, &#39;phi_deg&#39;: phi_i_deg_mean},index=COMP_one.index)

    else: #dummy values, COMP_years should be equal to COMP_mean
        COMP_mean_pd = analysis(ts_pd, const_list=const_list, hatyan_settings=hatyan_settings)
        COMP_all_pd = None
    
    if hatyan_settings.return_allyears:
        return COMP_mean_pd, COMP_all_pd
    else:
        return COMP_mean_pd</code></pre>
</details>
</dd>
<dt id="hatyan.analysis_prediction.analysis"><code class="name flex">
<span>def <span class="ident">analysis</span></span>(<span>ts, const_list, hatyan_settings=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>harmonic analysis with matrix transformations (least squares fit), optionally with component splitting
for details about arguments and return variables, see get_components_from_ts() definition</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def analysis(ts, const_list, hatyan_settings=None, **kwargs):#nodalfactors=True, xfac=False, fu_alltimes=True, CS_comps=None, return_prediction=False, source=&#39;schureman&#39;):
    &#34;&#34;&#34;
    harmonic analysis with matrix transformations (least squares fit), optionally with component splitting
    for details about arguments and return variables, see get_components_from_ts() definition
    
    &#34;&#34;&#34;
    
    if hatyan_settings is None:
        hatyan_settings = HatyanSettings(**kwargs)
    elif len(kwargs)&gt;0:
        raise Exception(&#39;both arguments hatyan_settings and other settings (e.g. nodalfactors) are provided, this is not valid&#39;)

    print(&#39;-&#39;*50)
    print(&#39;ANALYSIS initializing&#39;)
    print(hatyan_settings)
        
    #drop duplicate times
    ts_pd = ts[~ts.index.duplicated(keep=&#39;first&#39;)]
    if len(ts_pd) != len(ts):
        print(&#39;WARNING: %i duplicate times of the input timeseries were dropped prior to the analysis&#39;%(len(ts)-len(ts_pd)))
    print(f&#39;#timesteps           = {len(ts)}&#39;)
    print(f&#39;tstart               = {ts.index[0].strftime(&#34;%Y-%m-%d %H:%M:%S&#34;)}&#39;)
    print(f&#39;tstop                = {ts.index[-1].strftime(&#34;%Y-%m-%d %H:%M:%S&#34;)}&#39;)
    if hasattr(ts.index,&#39;freq&#39;):
        print(f&#39;timestep             = {ts.index.freq}&#39;)
    
    #retrieving and sorting const_list
    if type(const_list) is str:
        const_list = get_const_list_hatyan(const_list)
    elif type(const_list) is not list:
        const_list = const_list.tolist()
    const_list = sort_const_list(const_list)
    print(f&#39;components analyzed  = {len(const_list)}&#39;)
    
    #check for duplicate components (results in singular matrix)
    if len(const_list) != len(np.unique(const_list)):
        const_list_uniq, const_list_uniq_counts = np.unique(const_list,return_counts=True)
        const_list_counts = pd.DataFrame({&#39;constituent&#39;:const_list_uniq,&#39;occurences&#39;:const_list_uniq_counts})
        raise Exception(&#39;remove duplicate constituents from const_list:\n%s&#39;%(const_list_counts.loc[const_list_counts[&#39;occurences&#39;]&gt;1]))
    
    #remove nans
    ts_pd_nonan = ts_pd[~ts_pd[&#39;values&#39;].isna()]
    if len(ts_pd_nonan)==0:
        raise Exception(&#39;provided timeseries only contains nan values, analysis not possible&#39;)
    times_pred_all_pdDTI = pd.DatetimeIndex(ts_pd_nonan.index)
    percentage_nan = 100-len(ts_pd_nonan[&#39;values&#39;])/len(ts_pd[&#39;values&#39;])*100
    print(f&#39;percentage_nan in values_meas_sel: {percentage_nan:.2f}%&#39;)
    
    #get times and time array
    dood_date_mid = pd.Index([ts_pd.index[len(ts_pd.index)//2]]) #middle of analysis period (2july in case of 1jan-1jan), zoals bij hatyan #TODO: this is incorrect in case of e.g. more missings in first half of year than second half
    dood_date_start = ts_pd.index[[0]] #first date (for v0, also freq?)
    if hatyan_settings.fu_alltimes:
        dood_date_fu = times_pred_all_pdDTI
    else:
        dood_date_fu = dood_date_mid
    #times_from0_s = (pd.DatetimeIndex(ts_pd_nonan.index)-dood_date_start[0]).total_seconds().values
    times_from0_s, fancy_pddt = robust_timedelta_sec(ts_pd_nonan.index,refdate_dt=dood_date_start[0])
    times_from0_s = times_from0_s[:,np.newaxis]
    
    #get frequency and v0
    t_const_freq_pd, v_0i_rad = get_freqv0_generic(hatyan_settings, const_list, dood_date_mid, dood_date_start)
    omega_i_rads = t_const_freq_pd[[&#39;freq&#39;]].values.T*(2*np.pi)/3600 #angular frequency, 2pi/T, in rad/s, https://en.wikipedia.org/wiki/Angular_frequency (2*np.pi)/(1/x*3600) = 2*np.pi*x/3600
    u_i_rad, f_i = get_uf_generic(hatyan_settings, const_list, dood_date_fu)
    v_u = v_0i_rad.values + u_i_rad.values
    
    check_rayleigh(ts_pd,t_const_freq_pd)
    
    #TODO: nyquist stuk code generieker maken met Henrique
    stats = Timeseries_Statistics(ts=ts_pd)
    unique_timesteps = stats.stats[&#39;timeseries unique timesteps (minutes)&#39;]
    if len(unique_timesteps)==1: #constant freq, so folding is possible
        constant_freq_phr = list(unique_timesteps)[0]/60
        fs = 1/constant_freq_phr
        nyquist_freq = 0.5*fs
        bool_isnyquist = t_const_freq_pd[&#39;freq&#39;]==nyquist_freq
        if bool_isnyquist.any():
            raise Exception(f&#39;there is a component on the Nyquist frequency ({nyquist_freq} [1/hr]), this not possible:\n{t_const_freq_pd.loc[bool_isnyquist]}&#39;)
        bool_freqtoohigh = t_const_freq_pd[&#39;freq&#39;]&gt;nyquist_freq
        t_const_freq_pd_folded = t_const_freq_pd.copy()
        t_const_freq_pd_folded.loc[bool_freqtoohigh,&#39;freq&#39;] = np.abs(fs - t_const_freq_pd_folded.loc[bool_freqtoohigh,&#39;freq&#39;] ) #remainder is better: 0.408%(1/3)
        t_const_freq_pd_folded = t_const_freq_pd_folded.sort_values(&#39;freq&#39;) #TODO: sorting also done in rayleigh check
        print(&#39;check folded rayleigh&#39;)
        check_rayleigh(ts_pd,t_const_freq_pd_folded)
    
    #### TIMESERIES ANALYSIS
    N = len(const_list)
    m = len(ts_pd_nonan[&#39;values&#39;])
    
    # get xmat and make dot product
    xmat = np.zeros((m,2*N))
    xmat[:,:N] = f_i.values * np.cos(omega_i_rads*times_from0_s+v_u)
    xmat[:,N:] = f_i.values * np.sin(omega_i_rads*times_from0_s+v_u)
    
    xTmat = xmat.T
    print(&#39;calculating xTx matrix&#39;)
    tic = dt.datetime.now()
    xTxmat = np.dot(xTmat,xmat)
    
    if 0:
        #TODO
        xTxmat2 = xTxmat/xTxmat[0,0]
        xTxmat2[np.abs(xTxmat2)&lt;0.05] = 0
        xTxmat2_condition = np.linalg.cond(xTxmat2)
        svd_u,svd_s,svd_vh = np.linalg.svd(xTxmat2) # s zijn singuliere waarden van groot naar klein, u en v zijn gespiegeld over diagonaal
        xTxmat2_check = svd_u@np.diag(svd_s)@svd_vh #matrix multiplicatie geeft weer originele matrix (ongeveer)
        xTxmat2_check = svd_u[:,:2]@np.diag(svd_s[:2])@svd_vh[:2,:] #helft van info weggooien, geeft approximatie van originele matrix
        
        #samp freq is 3hr, freq [1/hr],dus fs is 1/3, nyquist freq is 1/6 (0.5*fs)
        #probleem is freq van 3M2S10 (0.408201 [1/hr]) is groter dan 1/6
    
    print(&#39;xTx matrix calculated&#39;)
    if &#39;A0&#39; in const_list: #correct center value [N,N] for better matrix condition
        xTxmat_condition = np.linalg.cond(xTxmat)
        print(&#39;condition of xTx matrix before center adjustment for A0: %.2f&#39;%(xTxmat_condition))
        xTxmat[N,N] = m
    xTxmat_condition = np.linalg.cond(xTxmat)
    print(&#39;condition of xTx matrix: %.2f&#39;%(xTxmat_condition))
    if xTxmat_condition &gt; hatyan_settings.xTxmat_condition_max:#10:#100: #random treshold
        raise Exception(f&#39;ERROR: condition of xTx matrix is too high ({xTxmat_condition:.2f}), check your timeseries length, try different (shorter) component set or componentsplitting.\nAnalysed {check_ts(ts_pd)}&#39;)
    xTymat = np.dot(xTmat,ts_pd_nonan[&#39;values&#39;].values)
    
    #solve matrix to get beta_roof_mat (and thus a, b)
    beta_roof_mat = np.linalg.solve(xTxmat,xTymat)
    print(&#39;matrix system solved, elapsed time: %s&#39;%(dt.datetime.now()-tic))

    phi_i_rad = np.arctan2(beta_roof_mat[N:],beta_roof_mat[:N]) #(a,b) arctan_ab
    A_i = np.sqrt(beta_roof_mat[N:]**2 + beta_roof_mat[:N]**2) #(a,b) sqsqrt_ab

    COMP_pd = pd.DataFrame({&#39;A&#39;: A_i, &#39;phi_deg&#39;: np.rad2deg(phi_i_rad%(2*np.pi))}, index=const_list)
    if &#39;A0&#39; in COMP_pd.index: #correct 180 degrees A0 phase by making amplitude value negative
        if COMP_pd.loc[&#39;A0&#39;,&#39;phi_deg&#39;]==180:
            COMP_pd.loc[&#39;A0&#39;,&#39;A&#39;] = -COMP_pd.loc[&#39;A0&#39;,&#39;A&#39;]
            COMP_pd.loc[&#39;A0&#39;,&#39;phi_deg&#39;] = 0
    
    if hatyan_settings.CS_comps is not None:
        COMP_pd = split_components(comp=COMP_pd, dood_date_mid=dood_date_mid, hatyan_settings=hatyan_settings)
        
    print(&#39;ANALYSIS finished&#39;)
    
    if hatyan_settings.return_prediction:
        print(&#39;immediately generating a prediction for the same time array as the input ts&#39;)
        ts_prediction = prediction(comp=COMP_pd, times_pred_all=ts_pd.index, hatyan_settings=hatyan_settings)
        return COMP_pd, ts_prediction
    else:
        return COMP_pd</code></pre>
</details>
</dd>
<dt id="hatyan.analysis_prediction.split_components"><code class="name flex">
<span>def <span class="ident">split_components</span></span>(<span>comp, dood_date_mid, hatyan_settings=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>component splitting function
for details about arguments and return variables, see get_components_from_ts() definition</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def split_components(comp, dood_date_mid, hatyan_settings=None, **kwargs):
    &#34;&#34;&#34;
    component splitting function
    for details about arguments and return variables, see get_components_from_ts() definition

    &#34;&#34;&#34;
    
    if hatyan_settings is None:
        hatyan_settings = HatyanSettings(**kwargs)
    elif len(kwargs)&gt;0:
        raise Exception(&#39;both arguments hatyan_settings and other settings (e.g. nodalfactors) are provided, this is not valid&#39;)
        
    #create sorted and complete component list
    const_list_inclCS_raw = comp.index.tolist() + hatyan_settings.CS_comps[&#39;CS_comps_derive&#39;].tolist()
    const_list_inclCS = sort_const_list(const_list=const_list_inclCS_raw)

    #retrieve freq and speed
    t_const_freq_pd, CS_v_0i_rad = get_freqv0_generic(hatyan_settings, const_list=const_list_inclCS, dood_date_mid=dood_date_mid, dood_date_start=dood_date_mid) # with split_components, v0 is calculated on the same timestep as u and f (middle of original series)
    CS_u_i_rad, CS_f_i = get_uf_generic(hatyan_settings, const_list=const_list_inclCS, dood_date_fu=dood_date_mid)
    
    comp_inclCS = pd.DataFrame(comp,index=const_list_inclCS,columns=comp.columns)
    #comp_inclCS_preCS = comp_inclCS.copy()
        
    for comp_main in np.unique(hatyan_settings.CS_comps[&#39;CS_comps_from&#39;]):
        bool_CS_maincomp = hatyan_settings.CS_comps[&#39;CS_comps_from&#39;] == comp_main #boolean of which rows of CS_comps dataframe corresponds to a main constituent, also makes it possible to select two rows
        CS_comps_formain = hatyan_settings.CS_comps.loc[bool_CS_maincomp]
        comp_slave_list = CS_comps_formain[&#39;CS_comps_derive&#39;].tolist()
        print(f&#39;splitting component {comp_main} into {comp_slave_list}&#39;)
        
        #first update main components based on degincrs/ampfacs of all components that are to be derived
        DBETA = 0
        for iR, CS_comps_row in CS_comps_formain.iterrows():
            comp_slave = CS_comps_row[&#39;CS_comps_derive&#39;]
            #code from resuda.f, line 440 to 455
            DMU = CS_f_i.loc[0,comp_slave]/CS_f_i.loc[0,comp_main]
            DTHETA = CS_comps_row[&#39;CS_ampfacs&#39;]
            DGAMMA = np.deg2rad(CS_comps_row[&#39;CS_degincrs&#39;])-DBETA-(CS_v_0i_rad.loc[0,comp_slave]+CS_u_i_rad.loc[0,comp_slave])+(CS_v_0i_rad.loc[0,comp_main]+CS_u_i_rad.loc[0,comp_main]) #in FORTRAN code, CS_f_i slave/main is also added, this seems wrong
            DREEEL = 1+DMU*DTHETA*np.cos(DGAMMA)
            DIMAGI = DMU*DTHETA*np.sin(DGAMMA)  
            DALPHA = np.sqrt(DREEEL*DREEEL+DIMAGI*DIMAGI)
            if DALPHA &lt; 1e-50:
                raise Exception(&#39;ERROR: DALPHA too small, component splitting failed?&#39;)
            DBETA = np.arctan2(DIMAGI,DREEEL)
            
            comp_inclCS.loc[comp_main,&#39;A&#39;] = comp_inclCS.loc[comp_main,&#39;A&#39;]/DALPHA
            comp_inclCS.loc[comp_main,&#39;phi_deg&#39;] = (comp_inclCS.loc[comp_main,&#39;phi_deg&#39;]-np.rad2deg(DBETA))%360 
        
        #updating slave components after updating main components, this makes a difference when splitting a component into more than two
        for iR, CS_comps_row in CS_comps_formain.iterrows():
            comp_slave = CS_comps_row[&#39;CS_comps_derive&#39;]
            comp_inclCS.loc[comp_slave,&#39;A&#39;] = comp_inclCS.loc[comp_main,&#39;A&#39;] * CS_comps_row[&#39;CS_ampfacs&#39;]
            comp_inclCS.loc[comp_slave,&#39;phi_deg&#39;] = (comp_inclCS.loc[comp_main,&#39;phi_deg&#39;] + CS_comps_row[&#39;CS_degincrs&#39;])%360
            
    return comp_inclCS</code></pre>
</details>
</dd>
<dt id="hatyan.analysis_prediction.prediction"><code class="name flex">
<span>def <span class="ident">prediction</span></span>(<span>comp, times_pred_all=None, times_ext=None, timestep_min=None, hatyan_settings=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>generates a tidal prediction from a set of components A and phi values.
The component set has the same timezone as the timeseries used to create it, therefore the resulting prediction will also be in that original timezone.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>comp</code></strong> :&ensp;<code>pandas.DataFrame</code></dt>
<dd>The DataFrame contains the component data with component names as index, and colums 'A' and 'phi_deg'.</dd>
<dt><strong><code>times_pred_all</code></strong> :&ensp;<code>pandas.DatetimeIndex</code>, optional</dt>
<dd>Prediction timeseries. The default is None.</dd>
<dt><strong><code>times_ext</code></strong> :&ensp;<code>list</code> of <code>datetime.datetime</code>, optional</dt>
<dd>Prediction time extents (list of start time and stop time). The default is None.</dd>
<dt><strong><code>timestep_min</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Prediction timestep in minutes. The default is None.</dd>
<dt><strong><code>hatyan_settings</code></strong> :&ensp;<code>hatyan.HatyanSettings()</code></dt>
<dd>Contains the used settings</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>Exception</code></dt>
<dd>DESCRIPTION.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>ts_prediction_pd</code></strong> :&ensp;<code>pandas.DataFrame</code></dt>
<dd>The DataFrame should contain a 'values' column and a pd.DatetimeIndex as index, it contains the prediction times and values.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def prediction(comp, times_pred_all=None, times_ext=None, timestep_min=None, hatyan_settings=None, **kwargs):
    &#34;&#34;&#34;
    generates a tidal prediction from a set of components A and phi values.
    The component set has the same timezone as the timeseries used to create it, therefore the resulting prediction will also be in that original timezone.
    
    Parameters
    ----------
    comp : pandas.DataFrame
        The DataFrame contains the component data with component names as index, and colums &#39;A&#39; and &#39;phi_deg&#39;.
    times_pred_all : pandas.DatetimeIndex, optional
        Prediction timeseries. The default is None.
    times_ext : list of datetime.datetime, optional
        Prediction time extents (list of start time and stop time). The default is None.
    timestep_min : int, optional
        Prediction timestep in minutes. The default is None.
    hatyan_settings : hatyan.HatyanSettings()
        Contains the used settings

    Raises
    ------
    Exception
        DESCRIPTION.

    Returns
    -------
    ts_prediction_pd : pandas.DataFrame
        The DataFrame should contain a &#39;values&#39; column and a pd.DatetimeIndex as index, it contains the prediction times and values.
    
    &#34;&#34;&#34;
    
    if hatyan_settings is None:
        hatyan_settings = HatyanSettings(**kwargs)
    elif len(kwargs)&gt;0:
        raise Exception(&#39;both arguments hatyan_settings and other settings (e.g. nodalfactors) are provided, this is not valid&#39;)
    
    print(&#39;-&#39;*50)
    print(&#39;PREDICTION initializing&#39;)
    print(hatyan_settings)
    
    if times_pred_all is None:
        if times_ext is None or timestep_min is None:
            raise Exception(&#39;if argument times_pred_all is not provided, the arguments times_ext and timestep_min are obligatory&#39;)
        else:
            times_pred_all = robust_daterange_fromtimesextfreq(times_ext,timestep_min)
    else:
        if times_ext is not None or timestep_min is not None:
            raise Exception(&#39;if argument times_pred_all is provided, the arguments times_ext and timestep_min are not allowed&#39;)
    
    if not len(times_pred_all) &gt; 1:
        raise Exception(&#39;ERROR: requested prediction period is not more than one timestep_min&#39;)
    
    if isinstance(times_pred_all, pd.core.indexes.datetimes.DatetimeIndex) or isinstance(times_pred_all, pd.core.indexes.base.Index):
        times_pred_all_pdDTI = times_pred_all
    else:
        times_pred_all_pdDTI = pd.DatetimeIndex(times_pred_all)
    
    print(&#39;%-20s = %s&#39;%(&#39;components used&#39;,len(comp)))
    print(&#39;%-20s = %s&#39;%(&#39;tstart&#39;,times_pred_all_pdDTI[0].strftime(&#39;%Y-%m-%d %H:%M:%S&#39;)))
    print(&#39;%-20s = %s&#39;%(&#39;tstop&#39;,times_pred_all_pdDTI[-1].strftime(&#39;%Y-%m-%d %H:%M:%S&#39;)))
    if hasattr(times_pred_all_pdDTI,&#39;freq&#39;):
        print(&#39;%-20s = %s&#39;%(&#39;timestep&#39;,times_pred_all_pdDTI.freq))
    
    dood_date_mid = pd.Index([times_pred_all_pdDTI[len(times_pred_all_pdDTI)//2]]) #middle of analysis period (2july in case of 1jan-1jan), zoals bij hatyan.
    dood_date_start = times_pred_all_pdDTI[:1] #first date (for v0, also freq?)
    
    #sort component list and component dataframe
    if np.isnan(comp.values).any():
        raise Exception(&#39;provided component set contains nan values, prediction not possible&#39;)
    const_list = sort_const_list(comp.index.tolist())
    COMP = comp.loc[const_list]
    A = np.array(COMP[&#39;A&#39;])
    phi_rad = np.array(np.deg2rad(COMP[&#39;phi_deg&#39;]))

    t_const_freq_pd, v_0i_rad = get_freqv0_generic(hatyan_settings, const_list, dood_date_mid, dood_date_start)
    t_const_speed_all = t_const_freq_pd[&#39;freq&#39;].values[:,np.newaxis]*(2*np.pi)

    if hatyan_settings.fu_alltimes:
        dood_date_fu = times_pred_all_pdDTI
    else:
        dood_date_fu = dood_date_mid
    u_i_rad, f_i = get_uf_generic(hatyan_settings, const_list, dood_date_fu)

    print(&#39;PREDICTION started&#39;)
    omega_i_rads = t_const_speed_all.T/3600 #angular frequency, 2pi/T, in rad/s, https://en.wikipedia.org/wiki/Angular_frequency (2*np.pi)/(1/x*3600) = 2*np.pi*x/3600
    if ~isinstance(times_pred_all_pdDTI,pd.DatetimeIndex) &amp; (version.parse(pd.__version__) &gt;= version.parse(&#39;1.2.0&#39;)): #fix for non-backwards compatible change in pandas, pandas version 1.1.2 is used for RWS version. TODO: remove this fix once pandas&gt;=1.2.0 can be used (probably py3.7 required)
        times_from0allpred_s_orig = (times_pred_all_pdDTI-dood_date_start).total_seconds().values
    else:
        times_from0allpred_s_orig = (times_pred_all_pdDTI-dood_date_start[0]).total_seconds().values
    times_from0allpred_s = np.transpose(times_from0allpred_s_orig[np.newaxis])
    
    f_A = np.multiply(f_i.values,A)
    omeg_t = np.multiply(times_from0allpred_s,omega_i_rads)#_td)
    v_u_phi = np.subtract(np.add(v_0i_rad.values,u_i_rad.values),phi_rad)
    omeg_t_v_u_phi = np.add(omeg_t,v_u_phi)
    ht_res = np.sum(np.multiply(f_A,np.cos(omeg_t_v_u_phi)),axis=1) #not necessary to add A0, since it is already part of the component list
    
    ts_prediction_pd = pd.DataFrame({&#39;values&#39;: ht_res},index=times_pred_all_pdDTI)
    print(&#39;PREDICTION finished&#39;)
    
    return ts_prediction_pd</code></pre>
</details>
</dd>
<dt id="hatyan.analysis_prediction.prediction_peryear"><code class="name flex">
<span>def <span class="ident">prediction_peryear</span></span>(<span>comp_allyears, timestep_min, hatyan_settings=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Wrapper around prediction(), to use component set of multiple years to generate multi-year timeseries.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>comp_allyears</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>DESCRIPTION.</dd>
<dt><strong><code>timestep_min</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>DESCRIPTION.</dd>
<dt><strong><code>hatyan_settings</code></strong> :&ensp;<code>hatyan.HatyanSettings()</code></dt>
<dd>Contains the used settings</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>ts_prediction_peryear</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>DESCRIPTION.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def prediction_peryear(comp_allyears, timestep_min, hatyan_settings=None, **kwargs):
    &#34;&#34;&#34;
    Wrapper around prediction(), to use component set of multiple years to generate multi-year timeseries.

    Parameters
    ----------
    comp_allyears : TYPE
        DESCRIPTION.
    timestep_min : TYPE
        DESCRIPTION.
    hatyan_settings : hatyan.HatyanSettings()
        Contains the used settings
        
    Returns
    -------
    ts_prediction_peryear : TYPE
        DESCRIPTION.

    &#34;&#34;&#34;
    
    if hatyan_settings is None:
        hatyan_settings = HatyanSettings(**kwargs)
    elif len(kwargs)&gt;0:
        raise Exception(&#39;both arguments hatyan_settings and other settings (e.g. nodalfactors) are provided, this is not valid&#39;)

    list_years = comp_allyears.columns.levels[1]
    ts_prediction_peryear = pd.DataFrame()
    for year in list_years:
        print(&#39;generating prediction %d of sequence %s&#39;%(year,list(list_years)))
        comp_oneyear = comp_allyears.loc[:,(slice(None),year)]
        comp_oneyear.columns = comp_oneyear.columns.droplevel(1)
        times_ext = [dt.datetime(year,1,1),dt.datetime(year+1,1,1)-dt.timedelta(minutes=timestep_min)]
        ts_prediction_oneyear = prediction(comp=comp_oneyear,times_ext=times_ext, timestep_min=timestep_min, hatyan_settings=hatyan_settings)
        ts_prediction_peryear = ts_prediction_peryear.append(ts_prediction_oneyear)
    return ts_prediction_peryear</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="hatyan.analysis_prediction.HatyanSettings"><code class="flex name class">
<span>class <span class="ident">HatyanSettings</span></span>
<span>(</span><span>source='schureman', nodalfactors=True, fu_alltimes=True, xfac=False, CS_comps=None, analysis_peryear=False, analysis_permonth=False, return_allyears=False, return_prediction=False, xTxmat_condition_max=10)</span>
</code></dt>
<dd>
<div class="desc"><p>Settings class containing default hatyan settings, to be overwritten by input, initiate with:
hatyan_settings = hatyan.HatyanSettings(nodalfactors=False)</p>
<p>source : TYPE, optional
DESCRIPTION. The default is 'schureman'.
nodalfactors : bool/int, optional
Whether or not to apply nodal factors. The default is True.
fu_alltimes : bool/int, optional
Whether to calculate nodal factors in middle of the analysis/prediction period (default) or on every timestep. The default is True.
xfac : bool/int, optional
Whether or not to apply x-factors. The default is False.</p>
<h1 id="following-are-only-for-analysis">following are only for analysis</h1>
<p>CS_comps : pandas.DataFrame, optional
contains the from/derive component lists for components splitting, as well as the amplitude factor and the increase in degrees. The default is None.</p>
<h1 id="following-are-only-for-get_components_from_ts">following are only for get_components_from_ts</h1>
<p>analysis_peryear : bool/int, optional
DESCRIPTION. The default is False.
analysis_permonth : bool/int, optional
caution, it tries to analyse each month, but skips it if it fails. analysis_peryear argument has priority. The default is False.
return_allyears : bool/int, optional
DESCRIPTION. The default is False.
return_prediction : bool/int, optional
Whether to generate a prediction for the ts time array. The default is False.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class HatyanSettings:
    &#34;&#34;&#34;
    Settings class containing default hatyan settings, to be overwritten by input, initiate with:
    hatyan_settings = hatyan.HatyanSettings(nodalfactors=False)

    source : TYPE, optional
        DESCRIPTION. The default is &#39;schureman&#39;.
    nodalfactors : bool/int, optional
        Whether or not to apply nodal factors. The default is True.
    fu_alltimes : bool/int, optional
        Whether to calculate nodal factors in middle of the analysis/prediction period (default) or on every timestep. The default is True.
    xfac : bool/int, optional
        Whether or not to apply x-factors. The default is False.
    
    #following are only for analysis
    CS_comps : pandas.DataFrame, optional
        contains the from/derive component lists for components splitting, as well as the amplitude factor and the increase in degrees. The default is None.
    
    #following are only for get_components_from_ts
    analysis_peryear : bool/int, optional
        DESCRIPTION. The default is False.
    analysis_permonth : bool/int, optional
        caution, it tries to analyse each month, but skips it if it fails. analysis_peryear argument has priority. The default is False.
    return_allyears : bool/int, optional
        DESCRIPTION. The default is False.
    return_prediction : bool/int, optional
        Whether to generate a prediction for the ts time array. The default is False.
    
    &#34;&#34;&#34;
    #TODO: analysis_peryear,analysis_permonth,return_allyears only for get_components_from_ts, return_prediction only for analysis. Merge analysis and get_components_from_ts? Remove some from HatyanSettings class or maybe split? Add const_list to HatyanSettings?
    
    def __init__(self, source=&#39;schureman&#39;, nodalfactors=True, fu_alltimes=True, xfac=False, #prediction/analysis 
                 CS_comps=None, analysis_peryear=False, analysis_permonth=False, return_allyears=False, return_prediction=False,
                 xTxmat_condition_max=10): #analysis only
        if not isinstance(source,str):
            raise Exception(&#39;invalid source type, should be str&#39;)
        source = source.lower()
        if source not in [&#39;schureman&#39;,&#39;foreman&#39;]:
            raise Exception(&#39;invalid source {source}, should be schureman or foreman)&#39;)
        
        for var_in in [nodalfactors,fu_alltimes,xfac,
                       analysis_peryear,analysis_permonth,return_allyears,return_prediction]:
            if not isinstance(var_in,bool):
                raise Exception(f&#39;invalid {var_in} type, should be bool&#39;)
        
        if CS_comps is not None:
            if not isinstance(CS_comps,(dict,pd.DataFrame)):
                raise Exception(&#39;invalid CS_comps type, should be dict&#39;)
            CS_comps = pd.DataFrame(CS_comps) #TODO: convert all to dict or pd.DataFrame
            CS_comps_expectedkeys = [&#39;CS_comps_derive&#39;, &#39;CS_comps_from&#39;, &#39;CS_ampfacs&#39;, &#39;CS_degincrs&#39;]
            for CS_comps_key in CS_comps_expectedkeys:
                if CS_comps_key not in CS_comps.keys():
                    raise Exception(f&#39;CS_comps does not contain {CS_comps_key}&#39;)
            CS_comps_lenvals = [len(CS_comps[key]) for key in CS_comps]
            if len(np.unique(CS_comps_lenvals)) != 1:
                raise Exception(f&#39;CS_comps keys do not have equal lengths:\n{CS_comps}&#39;)
        
        self.source = source
        self.nodalfactors = nodalfactors
        self.fu_alltimes = fu_alltimes
        self.xfac = xfac
        self.CS_comps = CS_comps
        self.analysis_peryear = analysis_peryear
        self.analysis_permonth = analysis_permonth
        self.return_allyears = return_allyears
        self.return_prediction = return_prediction
        self.xTxmat_condition_max = xTxmat_condition_max
        
    def __str__(self):
        self_dict = vars(self)
        str_append = &#39;&#39;
        for key,val in self_dict.items():
            if key==&#39;CS_comps&#39; and self.CS_comps is not None:
                str_append += f&#39;{key:20s} = \n{val}\n&#39;
            else:
                str_append += f&#39;{key:20s} = {val}\n&#39;
        return str_append</code></pre>
</details>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="hatyan" href="index.html">hatyan</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="hatyan.analysis_prediction.vectoravg" href="#hatyan.analysis_prediction.vectoravg">vectoravg</a></code></li>
<li><code><a title="hatyan.analysis_prediction.get_components_from_ts" href="#hatyan.analysis_prediction.get_components_from_ts">get_components_from_ts</a></code></li>
<li><code><a title="hatyan.analysis_prediction.analysis" href="#hatyan.analysis_prediction.analysis">analysis</a></code></li>
<li><code><a title="hatyan.analysis_prediction.split_components" href="#hatyan.analysis_prediction.split_components">split_components</a></code></li>
<li><code><a title="hatyan.analysis_prediction.prediction" href="#hatyan.analysis_prediction.prediction">prediction</a></code></li>
<li><code><a title="hatyan.analysis_prediction.prediction_peryear" href="#hatyan.analysis_prediction.prediction_peryear">prediction_peryear</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="hatyan.analysis_prediction.HatyanSettings" href="#hatyan.analysis_prediction.HatyanSettings">HatyanSettings</a></code></h4>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>