<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>hatyan.kw_slotgemiddelden API documentation</title>
<meta name="description" content="Created on Thu Apr
7 17:12:42 2022 …" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>hatyan.kw_slotgemiddelden</code></h1>
</header>
<section id="section-intro">
<p>Created on Thu Apr
7 17:12:42 2022</p>
<p>@author: veenstra</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># -*- coding: utf-8 -*-
&#34;&#34;&#34;
Created on Thu Apr  7 17:12:42 2022

@author: veenstra
&#34;&#34;&#34;


import numpy as np
import statsmodels.api as sm
import pandas as pd
import datetime as dt
from hatyan.timeseries import calc_HWLW12345to12
from hatyan.analysis_prediction import HatyanSettings, prediction #PydanticConfig
#from pydantic import validate_arguments #TODO: enable validator (first add pydantic as dependency, plus how to validate comp df (columns A/phi, then maybe classed should be used instead)


def calc_HWLWtidalindicators(data_pd_HWLW_all, tresh_yearlyHWLWcount=None):
    &#34;&#34;&#34;
    computes several tidal extreme indicators from tidal extreme dataset

    Parameters
    ----------
    data_pd_HWLW_all : TYPE
        DESCRIPTION.

    Returns
    -------
    dict_tidalindicators : TYPE
        DESCRIPTION.

    &#34;&#34;&#34;
    if hasattr(data_pd_HWLW_all.index[0],&#39;tz&#39;): #timezone present in index
        data_pd_HWLW_all.index = data_pd_HWLW_all.index.tz_localize(None)
    if len(data_pd_HWLW_all[&#39;HWLWcode&#39;].unique()) &gt; 2: #aggers are present
        data_pd_HWLW_12 = calc_HWLW12345to12(data_pd_HWLW_all) #convert 12345 to 12 by taking minimum of 345 as 2 (laagste laagwater) #TODO: this drops first/last value if it is a LW, should be fixed
    else:
        data_pd_HWLW_12 = data_pd_HWLW_all.copy()
    
    #split to HW and LW separately, also groupby year
    data_pd_HW = data_pd_HWLW_12.loc[data_pd_HWLW_12[&#39;HWLWcode&#39;]==1]
    data_pd_LW = data_pd_HWLW_12.loc[data_pd_HWLW_12[&#39;HWLWcode&#39;]==2]
    
    #count HWLW values per year/month
    HWLW_count_peryear = data_pd_HWLW_12.groupby(pd.PeriodIndex(data_pd_HWLW_12.index, freq=&#34;y&#34;))[&#39;values&#39;].count()
    HWLW_count_permonth = data_pd_HWLW_12.groupby(pd.PeriodIndex(data_pd_HWLW_12.index, freq=&#34;m&#34;))[&#39;values&#39;].count()
    
    #yearmean HWLW from HWLW values #maybe also add *_mean_permonth
    HW_mean_peryear = data_pd_HW.groupby(pd.PeriodIndex(data_pd_HW.index, freq=&#34;y&#34;))[[&#39;values&#39;]].mean()
    LW_mean_peryear = data_pd_LW.groupby(pd.PeriodIndex(data_pd_LW.index, freq=&#34;y&#34;))[[&#39;values&#39;]].mean()
    
    #derive GHHW/GHWS (gemiddeld hoogwater springtij) per month
    HW_monthmax_permonth = data_pd_HW.groupby(pd.PeriodIndex(data_pd_HW.index, freq=&#34;m&#34;))[[&#39;values&#39;]].max() #proxy for HW at spring tide
    LW_monthmin_permonth = data_pd_LW.groupby(pd.PeriodIndex(data_pd_LW.index, freq=&#34;m&#34;))[[&#39;values&#39;]].min() #proxy for LW at spring tide
    
    #replace invalids with nan (in case of too less values per month or year)
    if tresh_yearlyHWLWcount is not None:
        tresh_monthlyHWLWcount = tresh_yearlyHWLWcount/13 #not 13 but 12, to also make the threshold valid in short months
        HW_mean_peryear.loc[HWLW_count_peryear&lt;tresh_yearlyHWLWcount] = np.nan
        LW_mean_peryear.loc[HWLW_count_peryear&lt;tresh_yearlyHWLWcount] = np.nan
        HW_monthmax_permonth.loc[HWLW_count_permonth&lt;tresh_monthlyHWLWcount] = np.nan
        LW_monthmin_permonth.loc[HWLW_count_permonth&lt;tresh_monthlyHWLWcount] = np.nan
    
    #derive GHHW/GHWS (gemiddeld hoogwater springtij)
    HW_monthmax_peryear = HW_monthmax_permonth.groupby(pd.PeriodIndex(HW_monthmax_permonth.index, freq=&#34;y&#34;))[[&#39;values&#39;]].mean()
    LW_monthmin_peryear = LW_monthmin_permonth.groupby(pd.PeriodIndex(LW_monthmin_permonth.index, freq=&#34;y&#34;))[[&#39;values&#39;]].mean()
    
    dict_HWLWtidalindicators = {&#39;HW_mean&#39;:data_pd_HW[&#39;values&#39;].mean(), #GHW
                                &#39;LW_mean&#39;:data_pd_LW[&#39;values&#39;].mean(), #GLW
                                &#39;HW_mean_peryear&#39;:HW_mean_peryear[&#39;values&#39;], #GHW peryear
                                &#39;LW_mean_peryear&#39;:LW_mean_peryear[&#39;values&#39;], #GLW peryear
                                &#39;HW_monthmax_permonth&#39;:HW_monthmax_permonth[&#39;values&#39;], #GHHW/GHWS permonth
                                &#39;LW_monthmin_permonth&#39;:LW_monthmin_permonth[&#39;values&#39;], #GLLW/GLWS permonth
                                &#39;HW_monthmax_mean_peryear&#39;:HW_monthmax_peryear[&#39;values&#39;], #GHHW/GHWS peryear
                                &#39;LW_monthmin_mean_peryear&#39;:LW_monthmin_peryear[&#39;values&#39;], #GLLW/GLWS peryear
                                }
    
    for key in dict_HWLWtidalindicators.keys():
        if not hasattr(dict_HWLWtidalindicators[key],&#39;index&#39;):
            continue
        dict_HWLWtidalindicators[key].index = dict_HWLWtidalindicators[key].index.to_timestamp()
        
    return dict_HWLWtidalindicators


def calc_wltidalindicators(data_wl_pd, tresh_yearlywlcount=None):
    &#34;&#34;&#34;
    computes monthly and yearly means from waterlevel timeseries

    Parameters
    ----------
    data_wl_pd : TYPE
        DESCRIPTION.

    Returns
    -------
    dict_wltidalindicators : TYPE
        DESCRIPTION.

    &#34;&#34;&#34;
    if hasattr(data_wl_pd.index[0],&#39;tz&#39;): #timezone present in index
        data_wl_pd.index = data_wl_pd.index.tz_localize(None)
    
    #count wl values per year/month
    wl_count_peryear = data_wl_pd.groupby(pd.PeriodIndex(data_wl_pd.index, freq=&#34;y&#34;))[&#39;values&#39;].count()
    wl_count_permonth = data_wl_pd.groupby(pd.PeriodIndex(data_wl_pd.index, freq=&#34;m&#34;))[&#39;values&#39;].count()
    
    #yearmean wl from wl values
    wl_mean_peryear = data_wl_pd.groupby(pd.PeriodIndex(data_wl_pd.index, freq=&#34;y&#34;))[[&#39;values&#39;]].mean()
    wl_mean_permonth = data_wl_pd.groupby(pd.PeriodIndex(data_wl_pd.index, freq=&#34;m&#34;))[[&#39;values&#39;]].mean()
    
    #replace invalids with nan (in case of too less values per month or year)
    if tresh_yearlywlcount is not None:
        tresh_monthlyywlcount = tresh_yearlywlcount/12
        wl_mean_peryear.loc[wl_count_peryear&lt;tresh_yearlywlcount] = np.nan
        wl_mean_permonth.loc[wl_count_permonth&lt;tresh_monthlyywlcount] = np.nan
        
    dict_wltidalindicators = {&#39;wl_mean_peryear&#39;:wl_mean_peryear[&#39;values&#39;], #yearly mean wl
                              &#39;wl_mean_permonth&#39;:wl_mean_permonth[&#39;values&#39;], #monthly mean wl
                              }
    
    for key in dict_wltidalindicators.keys():
        if not hasattr(dict_wltidalindicators[key],&#39;index&#39;):
            continue
        dict_wltidalindicators[key].index = dict_wltidalindicators[key].index.to_timestamp()
        
    return dict_wltidalindicators


#@validate_arguments(config=PydanticConfig)
def calc_LAT_HAT_fromcomponents(comp: pd.DataFrame, hatyan_settings: HatyanSettings = None) -&gt; tuple:
    &#34;&#34;&#34;
    Derive lowest and highest astronomical tide (LAT/HAT) from a component set.
    The component set is used to make a tidal prediction for an arbitrary period of 19 years with a 1 minute interval. The min/max values of the predictions of all years are the LAT/HAT values.
    The LAT/HAT is very dependent on the A0 of the component set. Therefore, the LAT/HAT values are relevant for the same year as the slotgemiddelde that is used to replace A0 in the component set. For instance, if the slotgemiddelde is valid for 2021.0, LAT and HAT are also relevant for that year.
    The LAT/HAT values are also very dependent on the hatyan_settings used, in general it is important to use the same settings as used to derive the tidal components.
    
    Parameters
    ----------
    comp : pd.DataFrame
        DESCRIPTION.
    hatyan_settings : TYPE, optional
        DESCRIPTION. The default is None.

    Returns
    -------
    tuple
        DESCRIPTION.

    &#34;&#34;&#34;
    
    min_vallist_allyears = pd.Series(dtype=float)
    max_vallist_allyears = pd.Series(dtype=float)
    for year in range(2020,2039): # 19 arbitrary consequtive years to capture entire nodal cycle
        times_pred_all = pd.date_range(start=dt.datetime(year,1,1), end=dt.datetime(year+1,1,1), freq=&#39;1min&#39;)
        ts_prediction = prediction(comp=comp, hatyan_settings=hatyan_settings, times_pred_all=times_pred_all)
        
        min_vallist_allyears.loc[year] = ts_prediction[&#39;values&#39;].min()
        max_vallist_allyears.loc[year] = ts_prediction[&#39;values&#39;].max()
    #vallist_allyears.plot()
    #print(vallist_allyears)
    #vallist_allyears.to_csv(&#39;LAT_HAT_indication_19Y_%s.csv&#39;%(current_station))
    LAT = min_vallist_allyears.min()
    HAT = max_vallist_allyears.max()
    return LAT, HAT


def fit_models(mean_array_todate: pd.Series) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Fit linear model over yearly means in mean_array_todate, including five years in the future.

    Parameters
    ----------
    mean_array_todate : pd.Series
        DESCRIPTION.

    Returns
    -------
    pred_pd : TYPE
        DESCRIPTION.

    &#34;&#34;&#34;
    
    
    # We&#39;ll just use the years. This assumes that annual waterlevels are used that are stored left-padded, the mean waterlevel for 2020 is stored as 2020-1-1. This is not logical, but common practice.
    allyears_DTI = pd.date_range(mean_array_todate.index.min(),mean_array_todate.index.max()+dt.timedelta(days=5*360),freq=&#39;AS&#39;)
    mean_array_allyears = pd.Series(mean_array_todate,index=allyears_DTI)
    
    df = pd.DataFrame({&#39;year&#39;:mean_array_allyears.index.year, &#39;height&#39;:mean_array_allyears.values}) #TODO: make functions accept mean_array instead of df as argument?
    
    # below methods are copied from https://github.com/openearth/sealevel/blob/master/slr/slr/models.py #TODO: install slr package as dependency or keep separate?
    fit, names, X = linear_model(df, with_wind=False, with_nodal=False)
    pred_linear_nonodal = fit.predict(X)
    fit, names, X = linear_model(df, with_wind=False)
    pred_linear_winodal = fit.predict(X)
    
    pred_pd = pd.DataFrame({&#39;pred_linear_nonodal&#39;:pred_linear_nonodal,
                            &#39;pred_linear_winodal&#39;:pred_linear_winodal},
                            index=allyears_DTI)
    return pred_pd


# copied from https://github.com/openearth/sealevel/blob/master/slr/slr/models.py
def broken_linear_model(df, with_wind=True, quantity=&#39;height&#39;, start_acceleration=1993):
    &#34;&#34;&#34;This model fits the sea-level rise has started to rise faster in 1993.&#34;&#34;&#34;
    y = df[quantity]
    X = np.c_[
        df[&#39;year&#39;]-1970,
        (df[&#39;year&#39;] &gt; start_acceleration),# * (df[&#39;year&#39;] - start_acceleration),
        np.cos(2*np.pi*(df[&#39;year&#39;]-1970)/18.613),
        np.sin(2*np.pi*(df[&#39;year&#39;]-1970)/18.613)
    ]
    names = [&#39;Constant&#39;, &#39;Trend&#39;, f&#39;+trend ({start_acceleration})&#39;, &#39;Nodal U&#39;, &#39;Nodal V&#39;]
    if with_wind:
        X = np.c_[
            X,
            df[&#39;u2&#39;],
            df[&#39;v2&#39;]
        ]
        names.extend([&#39;Wind $u^2$&#39;, &#39;Wind $v^2$&#39;])
    X = sm.add_constant(X)
    model_broken_linear = sm.GLSAR(y, X, rho=1, missing=&#39;drop&#39;)
    fit = model_broken_linear.iterative_fit(cov_type=&#39;HC0&#39;, missing=&#39;drop&#39;)
    return fit, names, X


# copied from https://github.com/openearth/sealevel/blob/master/slr/slr/models.py
def linear_model(df, with_wind=True, with_ar=True, with_nodal=True, quantity=&#39;height&#39;):
    &#34;&#34;&#34;Define the linear model with optional wind and autoregression.
    See the latest report for a detailed description.
    &#34;&#34;&#34;

    y = df[quantity]
    X = np.c_[df[&#39;year&#39;]-1970,
              ]
    #month = np.mod(df[&#39;year&#39;], 1) * 12.0
    names = [&#39;Constant&#39;, &#39;Trend&#39;]
    if with_nodal:
        X = np.c_[X,
                  np.cos(2*np.pi*(df[&#39;year&#39;]-1970)/18.613),
                  np.sin(2*np.pi*(df[&#39;year&#39;]-1970)/18.613)
                  ]
        names.extend([&#39;Nodal U&#39;, &#39;Nodal V&#39;])
    if with_wind:
        X = np.c_[
            X,
            df[&#39;u2&#39;],
            df[&#39;v2&#39;]
        ]
        names.extend([&#39;Wind $u^2$&#39;, &#39;Wind $v^2$&#39;])
    X = sm.add_constant(X)
    if with_ar:
        model = sm.GLSAR(y, X, missing=&#39;drop&#39;, rho=1)
    else:
        model = sm.OLS(y, X, missing=&#39;drop&#39;)
    fit = model.fit(cov_type=&#39;HC0&#39;)
    return fit, names, X</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="hatyan.kw_slotgemiddelden.calc_HWLWtidalindicators"><code class="name flex">
<span>def <span class="ident">calc_HWLWtidalindicators</span></span>(<span>data_pd_HWLW_all, tresh_yearlyHWLWcount=None)</span>
</code></dt>
<dd>
<div class="desc"><p>computes several tidal extreme indicators from tidal extreme dataset</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>data_pd_HWLW_all</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>DESCRIPTION.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>dict_tidalindicators</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>DESCRIPTION.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calc_HWLWtidalindicators(data_pd_HWLW_all, tresh_yearlyHWLWcount=None):
    &#34;&#34;&#34;
    computes several tidal extreme indicators from tidal extreme dataset

    Parameters
    ----------
    data_pd_HWLW_all : TYPE
        DESCRIPTION.

    Returns
    -------
    dict_tidalindicators : TYPE
        DESCRIPTION.

    &#34;&#34;&#34;
    if hasattr(data_pd_HWLW_all.index[0],&#39;tz&#39;): #timezone present in index
        data_pd_HWLW_all.index = data_pd_HWLW_all.index.tz_localize(None)
    if len(data_pd_HWLW_all[&#39;HWLWcode&#39;].unique()) &gt; 2: #aggers are present
        data_pd_HWLW_12 = calc_HWLW12345to12(data_pd_HWLW_all) #convert 12345 to 12 by taking minimum of 345 as 2 (laagste laagwater) #TODO: this drops first/last value if it is a LW, should be fixed
    else:
        data_pd_HWLW_12 = data_pd_HWLW_all.copy()
    
    #split to HW and LW separately, also groupby year
    data_pd_HW = data_pd_HWLW_12.loc[data_pd_HWLW_12[&#39;HWLWcode&#39;]==1]
    data_pd_LW = data_pd_HWLW_12.loc[data_pd_HWLW_12[&#39;HWLWcode&#39;]==2]
    
    #count HWLW values per year/month
    HWLW_count_peryear = data_pd_HWLW_12.groupby(pd.PeriodIndex(data_pd_HWLW_12.index, freq=&#34;y&#34;))[&#39;values&#39;].count()
    HWLW_count_permonth = data_pd_HWLW_12.groupby(pd.PeriodIndex(data_pd_HWLW_12.index, freq=&#34;m&#34;))[&#39;values&#39;].count()
    
    #yearmean HWLW from HWLW values #maybe also add *_mean_permonth
    HW_mean_peryear = data_pd_HW.groupby(pd.PeriodIndex(data_pd_HW.index, freq=&#34;y&#34;))[[&#39;values&#39;]].mean()
    LW_mean_peryear = data_pd_LW.groupby(pd.PeriodIndex(data_pd_LW.index, freq=&#34;y&#34;))[[&#39;values&#39;]].mean()
    
    #derive GHHW/GHWS (gemiddeld hoogwater springtij) per month
    HW_monthmax_permonth = data_pd_HW.groupby(pd.PeriodIndex(data_pd_HW.index, freq=&#34;m&#34;))[[&#39;values&#39;]].max() #proxy for HW at spring tide
    LW_monthmin_permonth = data_pd_LW.groupby(pd.PeriodIndex(data_pd_LW.index, freq=&#34;m&#34;))[[&#39;values&#39;]].min() #proxy for LW at spring tide
    
    #replace invalids with nan (in case of too less values per month or year)
    if tresh_yearlyHWLWcount is not None:
        tresh_monthlyHWLWcount = tresh_yearlyHWLWcount/13 #not 13 but 12, to also make the threshold valid in short months
        HW_mean_peryear.loc[HWLW_count_peryear&lt;tresh_yearlyHWLWcount] = np.nan
        LW_mean_peryear.loc[HWLW_count_peryear&lt;tresh_yearlyHWLWcount] = np.nan
        HW_monthmax_permonth.loc[HWLW_count_permonth&lt;tresh_monthlyHWLWcount] = np.nan
        LW_monthmin_permonth.loc[HWLW_count_permonth&lt;tresh_monthlyHWLWcount] = np.nan
    
    #derive GHHW/GHWS (gemiddeld hoogwater springtij)
    HW_monthmax_peryear = HW_monthmax_permonth.groupby(pd.PeriodIndex(HW_monthmax_permonth.index, freq=&#34;y&#34;))[[&#39;values&#39;]].mean()
    LW_monthmin_peryear = LW_monthmin_permonth.groupby(pd.PeriodIndex(LW_monthmin_permonth.index, freq=&#34;y&#34;))[[&#39;values&#39;]].mean()
    
    dict_HWLWtidalindicators = {&#39;HW_mean&#39;:data_pd_HW[&#39;values&#39;].mean(), #GHW
                                &#39;LW_mean&#39;:data_pd_LW[&#39;values&#39;].mean(), #GLW
                                &#39;HW_mean_peryear&#39;:HW_mean_peryear[&#39;values&#39;], #GHW peryear
                                &#39;LW_mean_peryear&#39;:LW_mean_peryear[&#39;values&#39;], #GLW peryear
                                &#39;HW_monthmax_permonth&#39;:HW_monthmax_permonth[&#39;values&#39;], #GHHW/GHWS permonth
                                &#39;LW_monthmin_permonth&#39;:LW_monthmin_permonth[&#39;values&#39;], #GLLW/GLWS permonth
                                &#39;HW_monthmax_mean_peryear&#39;:HW_monthmax_peryear[&#39;values&#39;], #GHHW/GHWS peryear
                                &#39;LW_monthmin_mean_peryear&#39;:LW_monthmin_peryear[&#39;values&#39;], #GLLW/GLWS peryear
                                }
    
    for key in dict_HWLWtidalindicators.keys():
        if not hasattr(dict_HWLWtidalindicators[key],&#39;index&#39;):
            continue
        dict_HWLWtidalindicators[key].index = dict_HWLWtidalindicators[key].index.to_timestamp()
        
    return dict_HWLWtidalindicators</code></pre>
</details>
</dd>
<dt id="hatyan.kw_slotgemiddelden.calc_wltidalindicators"><code class="name flex">
<span>def <span class="ident">calc_wltidalindicators</span></span>(<span>data_wl_pd, tresh_yearlywlcount=None)</span>
</code></dt>
<dd>
<div class="desc"><p>computes monthly and yearly means from waterlevel timeseries</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>data_wl_pd</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>DESCRIPTION.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>dict_wltidalindicators</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>DESCRIPTION.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calc_wltidalindicators(data_wl_pd, tresh_yearlywlcount=None):
    &#34;&#34;&#34;
    computes monthly and yearly means from waterlevel timeseries

    Parameters
    ----------
    data_wl_pd : TYPE
        DESCRIPTION.

    Returns
    -------
    dict_wltidalindicators : TYPE
        DESCRIPTION.

    &#34;&#34;&#34;
    if hasattr(data_wl_pd.index[0],&#39;tz&#39;): #timezone present in index
        data_wl_pd.index = data_wl_pd.index.tz_localize(None)
    
    #count wl values per year/month
    wl_count_peryear = data_wl_pd.groupby(pd.PeriodIndex(data_wl_pd.index, freq=&#34;y&#34;))[&#39;values&#39;].count()
    wl_count_permonth = data_wl_pd.groupby(pd.PeriodIndex(data_wl_pd.index, freq=&#34;m&#34;))[&#39;values&#39;].count()
    
    #yearmean wl from wl values
    wl_mean_peryear = data_wl_pd.groupby(pd.PeriodIndex(data_wl_pd.index, freq=&#34;y&#34;))[[&#39;values&#39;]].mean()
    wl_mean_permonth = data_wl_pd.groupby(pd.PeriodIndex(data_wl_pd.index, freq=&#34;m&#34;))[[&#39;values&#39;]].mean()
    
    #replace invalids with nan (in case of too less values per month or year)
    if tresh_yearlywlcount is not None:
        tresh_monthlyywlcount = tresh_yearlywlcount/12
        wl_mean_peryear.loc[wl_count_peryear&lt;tresh_yearlywlcount] = np.nan
        wl_mean_permonth.loc[wl_count_permonth&lt;tresh_monthlyywlcount] = np.nan
        
    dict_wltidalindicators = {&#39;wl_mean_peryear&#39;:wl_mean_peryear[&#39;values&#39;], #yearly mean wl
                              &#39;wl_mean_permonth&#39;:wl_mean_permonth[&#39;values&#39;], #monthly mean wl
                              }
    
    for key in dict_wltidalindicators.keys():
        if not hasattr(dict_wltidalindicators[key],&#39;index&#39;):
            continue
        dict_wltidalindicators[key].index = dict_wltidalindicators[key].index.to_timestamp()
        
    return dict_wltidalindicators</code></pre>
</details>
</dd>
<dt id="hatyan.kw_slotgemiddelden.calc_LAT_HAT_fromcomponents"><code class="name flex">
<span>def <span class="ident">calc_LAT_HAT_fromcomponents</span></span>(<span>comp: pandas.core.frame.DataFrame, hatyan_settings: <a title="hatyan.analysis_prediction.HatyanSettings" href="analysis_prediction.html#hatyan.analysis_prediction.HatyanSettings">HatyanSettings</a> = None) ‑> tuple</span>
</code></dt>
<dd>
<div class="desc"><p>Derive lowest and highest astronomical tide (LAT/HAT) from a component set.
The component set is used to make a tidal prediction for an arbitrary period of 19 years with a 1 minute interval. The min/max values of the predictions of all years are the LAT/HAT values.
The LAT/HAT is very dependent on the A0 of the component set. Therefore, the LAT/HAT values are relevant for the same year as the slotgemiddelde that is used to replace A0 in the component set. For instance, if the slotgemiddelde is valid for 2021.0, LAT and HAT are also relevant for that year.
The LAT/HAT values are also very dependent on the hatyan_settings used, in general it is important to use the same settings as used to derive the tidal components.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>comp</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>DESCRIPTION.</dd>
<dt><strong><code>hatyan_settings</code></strong> :&ensp;<code>TYPE</code>, optional</dt>
<dd>DESCRIPTION. The default is None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple</code></dt>
<dd>DESCRIPTION.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def calc_LAT_HAT_fromcomponents(comp: pd.DataFrame, hatyan_settings: HatyanSettings = None) -&gt; tuple:
    &#34;&#34;&#34;
    Derive lowest and highest astronomical tide (LAT/HAT) from a component set.
    The component set is used to make a tidal prediction for an arbitrary period of 19 years with a 1 minute interval. The min/max values of the predictions of all years are the LAT/HAT values.
    The LAT/HAT is very dependent on the A0 of the component set. Therefore, the LAT/HAT values are relevant for the same year as the slotgemiddelde that is used to replace A0 in the component set. For instance, if the slotgemiddelde is valid for 2021.0, LAT and HAT are also relevant for that year.
    The LAT/HAT values are also very dependent on the hatyan_settings used, in general it is important to use the same settings as used to derive the tidal components.
    
    Parameters
    ----------
    comp : pd.DataFrame
        DESCRIPTION.
    hatyan_settings : TYPE, optional
        DESCRIPTION. The default is None.

    Returns
    -------
    tuple
        DESCRIPTION.

    &#34;&#34;&#34;
    
    min_vallist_allyears = pd.Series(dtype=float)
    max_vallist_allyears = pd.Series(dtype=float)
    for year in range(2020,2039): # 19 arbitrary consequtive years to capture entire nodal cycle
        times_pred_all = pd.date_range(start=dt.datetime(year,1,1), end=dt.datetime(year+1,1,1), freq=&#39;1min&#39;)
        ts_prediction = prediction(comp=comp, hatyan_settings=hatyan_settings, times_pred_all=times_pred_all)
        
        min_vallist_allyears.loc[year] = ts_prediction[&#39;values&#39;].min()
        max_vallist_allyears.loc[year] = ts_prediction[&#39;values&#39;].max()
    #vallist_allyears.plot()
    #print(vallist_allyears)
    #vallist_allyears.to_csv(&#39;LAT_HAT_indication_19Y_%s.csv&#39;%(current_station))
    LAT = min_vallist_allyears.min()
    HAT = max_vallist_allyears.max()
    return LAT, HAT</code></pre>
</details>
</dd>
<dt id="hatyan.kw_slotgemiddelden.fit_models"><code class="name flex">
<span>def <span class="ident">fit_models</span></span>(<span>mean_array_todate: pandas.core.series.Series) ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Fit linear model over yearly means in mean_array_todate, including five years in the future.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>mean_array_todate</code></strong> :&ensp;<code>pd.Series</code></dt>
<dd>DESCRIPTION.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>pred_pd</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>DESCRIPTION.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fit_models(mean_array_todate: pd.Series) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Fit linear model over yearly means in mean_array_todate, including five years in the future.

    Parameters
    ----------
    mean_array_todate : pd.Series
        DESCRIPTION.

    Returns
    -------
    pred_pd : TYPE
        DESCRIPTION.

    &#34;&#34;&#34;
    
    
    # We&#39;ll just use the years. This assumes that annual waterlevels are used that are stored left-padded, the mean waterlevel for 2020 is stored as 2020-1-1. This is not logical, but common practice.
    allyears_DTI = pd.date_range(mean_array_todate.index.min(),mean_array_todate.index.max()+dt.timedelta(days=5*360),freq=&#39;AS&#39;)
    mean_array_allyears = pd.Series(mean_array_todate,index=allyears_DTI)
    
    df = pd.DataFrame({&#39;year&#39;:mean_array_allyears.index.year, &#39;height&#39;:mean_array_allyears.values}) #TODO: make functions accept mean_array instead of df as argument?
    
    # below methods are copied from https://github.com/openearth/sealevel/blob/master/slr/slr/models.py #TODO: install slr package as dependency or keep separate?
    fit, names, X = linear_model(df, with_wind=False, with_nodal=False)
    pred_linear_nonodal = fit.predict(X)
    fit, names, X = linear_model(df, with_wind=False)
    pred_linear_winodal = fit.predict(X)
    
    pred_pd = pd.DataFrame({&#39;pred_linear_nonodal&#39;:pred_linear_nonodal,
                            &#39;pred_linear_winodal&#39;:pred_linear_winodal},
                            index=allyears_DTI)
    return pred_pd</code></pre>
</details>
</dd>
<dt id="hatyan.kw_slotgemiddelden.broken_linear_model"><code class="name flex">
<span>def <span class="ident">broken_linear_model</span></span>(<span>df, with_wind=True, quantity='height', start_acceleration=1993)</span>
</code></dt>
<dd>
<div class="desc"><p>This model fits the sea-level rise has started to rise faster in 1993.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def broken_linear_model(df, with_wind=True, quantity=&#39;height&#39;, start_acceleration=1993):
    &#34;&#34;&#34;This model fits the sea-level rise has started to rise faster in 1993.&#34;&#34;&#34;
    y = df[quantity]
    X = np.c_[
        df[&#39;year&#39;]-1970,
        (df[&#39;year&#39;] &gt; start_acceleration),# * (df[&#39;year&#39;] - start_acceleration),
        np.cos(2*np.pi*(df[&#39;year&#39;]-1970)/18.613),
        np.sin(2*np.pi*(df[&#39;year&#39;]-1970)/18.613)
    ]
    names = [&#39;Constant&#39;, &#39;Trend&#39;, f&#39;+trend ({start_acceleration})&#39;, &#39;Nodal U&#39;, &#39;Nodal V&#39;]
    if with_wind:
        X = np.c_[
            X,
            df[&#39;u2&#39;],
            df[&#39;v2&#39;]
        ]
        names.extend([&#39;Wind $u^2$&#39;, &#39;Wind $v^2$&#39;])
    X = sm.add_constant(X)
    model_broken_linear = sm.GLSAR(y, X, rho=1, missing=&#39;drop&#39;)
    fit = model_broken_linear.iterative_fit(cov_type=&#39;HC0&#39;, missing=&#39;drop&#39;)
    return fit, names, X</code></pre>
</details>
</dd>
<dt id="hatyan.kw_slotgemiddelden.linear_model"><code class="name flex">
<span>def <span class="ident">linear_model</span></span>(<span>df, with_wind=True, with_ar=True, with_nodal=True, quantity='height')</span>
</code></dt>
<dd>
<div class="desc"><p>Define the linear model with optional wind and autoregression.
See the latest report for a detailed description.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def linear_model(df, with_wind=True, with_ar=True, with_nodal=True, quantity=&#39;height&#39;):
    &#34;&#34;&#34;Define the linear model with optional wind and autoregression.
    See the latest report for a detailed description.
    &#34;&#34;&#34;

    y = df[quantity]
    X = np.c_[df[&#39;year&#39;]-1970,
              ]
    #month = np.mod(df[&#39;year&#39;], 1) * 12.0
    names = [&#39;Constant&#39;, &#39;Trend&#39;]
    if with_nodal:
        X = np.c_[X,
                  np.cos(2*np.pi*(df[&#39;year&#39;]-1970)/18.613),
                  np.sin(2*np.pi*(df[&#39;year&#39;]-1970)/18.613)
                  ]
        names.extend([&#39;Nodal U&#39;, &#39;Nodal V&#39;])
    if with_wind:
        X = np.c_[
            X,
            df[&#39;u2&#39;],
            df[&#39;v2&#39;]
        ]
        names.extend([&#39;Wind $u^2$&#39;, &#39;Wind $v^2$&#39;])
    X = sm.add_constant(X)
    if with_ar:
        model = sm.GLSAR(y, X, missing=&#39;drop&#39;, rho=1)
    else:
        model = sm.OLS(y, X, missing=&#39;drop&#39;)
    fit = model.fit(cov_type=&#39;HC0&#39;)
    return fit, names, X</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="hatyan" href="index.html">hatyan</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="hatyan.kw_slotgemiddelden.calc_HWLWtidalindicators" href="#hatyan.kw_slotgemiddelden.calc_HWLWtidalindicators">calc_HWLWtidalindicators</a></code></li>
<li><code><a title="hatyan.kw_slotgemiddelden.calc_wltidalindicators" href="#hatyan.kw_slotgemiddelden.calc_wltidalindicators">calc_wltidalindicators</a></code></li>
<li><code><a title="hatyan.kw_slotgemiddelden.calc_LAT_HAT_fromcomponents" href="#hatyan.kw_slotgemiddelden.calc_LAT_HAT_fromcomponents">calc_LAT_HAT_fromcomponents</a></code></li>
<li><code><a title="hatyan.kw_slotgemiddelden.fit_models" href="#hatyan.kw_slotgemiddelden.fit_models">fit_models</a></code></li>
<li><code><a title="hatyan.kw_slotgemiddelden.broken_linear_model" href="#hatyan.kw_slotgemiddelden.broken_linear_model">broken_linear_model</a></code></li>
<li><code><a title="hatyan.kw_slotgemiddelden.linear_model" href="#hatyan.kw_slotgemiddelden.linear_model">linear_model</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>