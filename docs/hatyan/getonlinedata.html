<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>hatyan.getonlinedata API documentation</title>
<meta name="description" content="Created on Wed Dec
1 17:03:03 2021 â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>hatyan.getonlinedata</code></h1>
</header>
<section id="section-intro">
<p>Created on Wed Dec
1 17:03:03 2021</p>
<p>@author: veenstra</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># -*- coding: utf-8 -*-
&#34;&#34;&#34;
Created on Wed Dec  1 17:03:03 2021

@author: veenstra
&#34;&#34;&#34;

import pandas as pd
import numpy as np
import datetime as dt
import requests
import json

from hatyan.convert import convert_tzone2tzinfo

def get_DDL_catalog(catalog_extrainfo=[]):
    &#34;&#34;&#34;
    check get_DDL_data() for details

    Parameters
    ----------
    catalog_filter : TYPE, optional
        DESCRIPTION. The default is []. Possibilities are in https://rijkswaterstaat.github.io/wm-ws-dl/?json#ophalencatalogus, for instance &#39;MeetApparaten&#39; and &#39;Parameters&#39;.

    Raises
    ------
    Exception
        DESCRIPTION.

    Returns
    -------
    result_cat_dict : TYPE
        DESCRIPTION.
    &#34;&#34;&#34;
    
    #the webservices 
    url_catalog = &#39;https://waterwebservices.rijkswaterstaat.nl/METADATASERVICES_DBO/OphalenCatalogus&#39;
    
    #The request for ophalencatalogus
    catalog_filter = [&#39;Compartimenten&#39;,&#39;Eenheden&#39;,&#39;Grootheden&#39;,&#39;Hoedanigheden&#39;,&#39;Groeperingen&#39;]+catalog_extrainfo
    request_cat = {&#34;CatalogusFilter&#34;: {x:True for x in catalog_filter}}
    
    # pull catalog from the API and store in json format
    resp = requests.post(url_catalog, json=request_cat) # DDL IMPROVEMENT: it takes a long time to retrieve the catalog, it would be valuable if this could be instantaneous (eg by caching on server side).
    if not resp.ok:
        raise Exception(&#39;%s for %s: %s&#39;%(resp.reason, resp.url, str(resp.text)))
    result_cat = resp.json()
    if not result_cat[&#39;Succesvol&#39;]:
        raise Exception(&#39;catalog query not succesful, DDL foutmelding: &#34;%s&#34;&#39;%(result_cat[&#39;Foutmelding&#39;]))
    
    result_cat_dict = {}
    for catalog_key in result_cat.keys():
        if catalog_key==&#39;Succesvol&#39;:
            continue
        if isinstance(result_cat[catalog_key][0],dict):
            result_cat_dict[catalog_key] = pd.json_normalize(result_cat[catalog_key])
        else:
            result_cat_dict[catalog_key] = result_cat[catalog_key]
    
    #this part is only added to show duplicate stations, not essential code
    cat_locatielijst = result_cat_dict[&#39;LocatieLijst&#39;].set_index(&#39;Locatie_MessageID&#39;,drop=True)
    bool_dupl_code = cat_locatielijst[&#39;Code&#39;].duplicated(keep=False) #DDL IMPROVEMENT: there are duplicate station Codes present in the catalogus LocatieLijst, sometimes also the Naam+Code combination is duplicated. Possible to merge stations?
    if bool_dupl_code.any():
        print(f&#39;WARNING: {bool_dupl_code.sum()} duplicate station Codes present in cat_locatielijst. This issue can be reported to Servicedesk data via: https://www.rijkswaterstaat.nl/formulieren/contactformulier-servicedesk-data&#39;)
        print(cat_locatielijst.loc[bool_dupl_code,[&#39;Naam&#39;,&#39;Code&#39;]].sort_values(&#39;Code&#39;))
    
    return result_cat_dict


def get_DDL_queryserver(query_station,query_metadata,query_tstart,query_tstop,check_available=False):
    &#34;&#34;&#34;
    check get_DDL_data() for details
    &#34;&#34;&#34;
    
    tzinfo_numraw = query_tstart.strftime(&#39;%z&#39;) #&#39;+0100&#39;
    tzinfo_numstr = tzinfo_numraw[:3]+&#39;:&#39;+tzinfo_numraw[-2:] #&#39;+01:00&#39;
    query_tstart_str = query_tstart.strftime(&#39;%Y-%m-%dT%H:%M:%S.000&#39;+tzinfo_numstr) #&#34;2021-01-14T09:47:00.000+01:00&#34;
    query_tstop_str  = query_tstop.strftime(&#39;%Y-%m-%dT%H:%M:%S.000&#39;+tzinfo_numstr) #&#34;2021-11-27T10:00:00.000+01:00&#34;
    
    if isinstance(query_station,(pd.Series,dict)):
        query_station = json.loads(pd.Series(query_station).to_json()) # converts pd.Series/dict to_json() and back to dict. This avoids issue with query_station[&#39;Locatie_MessageID&#39;] of type np.int64 (TypeError: Object of type int64 is not JSON serializable)
    else:
        raise Exception(&#39;provide pd.Series or dict as query_station argument&#39;)
    
    if check_available: # Check if data is available
        url_ddl = &#39;https://waterwebservices.rijkswaterstaat.nl/ONLINEWAARNEMINGENSERVICES_DBO/CheckWaarnemingenAanwezig&#39;
        request_ddl = {&#34;AquoMetadataLijst&#34; :[query_metadata],
                         &#34;LocatieLijst&#34;:[query_station],
                         &#34;Periode&#34;:{&#34;Begindatumtijd&#34;:query_tstart_str, # DDL IMPROVEMENT: if user accidentally switches start/stop dates in query, OphalenWaarnemingen returns &#39;Begindatum is groter dan einddatum. (check_available=False)&#39;, CheckWaarnemingenAanwezig crashes instead of returning a proper error
                                    &#34;Einddatumtijd&#34;:query_tstop_str}
                        }
        # DDL IMPROVEMENT: would be valuable to quickly get available start/stop time and number of available measurements (timesteps). Below is a (slow) example, seems to take as much time as retrieving measurements
        # DDL IMPROVEMENT: welke groeperingsperiodes zijn beschikbaar en kan &#39;geen&#39; ook? (JsonProcessingException: Can not construct instance of nl.ordina.request.OphalenAantalWaarnemingenRequest$Groepering from String value &#39;geen&#39;: value not one of declared Enum instance names.)
        &#34;&#34;&#34;
        url_ddl = &#39;https://waterwebservices.rijkswaterstaat.nl/ONLINEWAARNEMINGENSERVICES_DBO/OphalenAantalWaarnemingen&#39;
        request_ddl = {&#34;AquoMetadataLijst&#34; :[query_metadata],
                         &#34;Groeperingsperiode&#34; : &#39;Jaar&#39;, 
                         &#34;LocatieLijst&#34;:[query_station],
                         &#34;Periode&#34;:{&#34;Begindatumtijd&#34;:query_tstart_str,
                                    &#34;Einddatumtijd&#34;:query_tstop_str}
                        }
        print(result[&#39;AantalWaarnemingenPerPeriodeLijst&#39;][0][&#39;AantalMetingenPerPeriodeLijst&#39;])
        &#34;&#34;&#34;
        # DDL IMPROVEMENT: OphalenLaatsteWaarnemingen seems to be valuable to get the end time for a station, however resulted waarnemingenlijst for one station has multiple entries (probably multiple WaardeBepalingsmethode?) but also MetingenLijst sometimes also has multiple entries, how to interpret this?
        &#34;&#34;&#34;
        url_ddl = &#39;https://waterwebservices.rijkswaterstaat.nl/ONLINEWAARNEMINGENSERVICES_DBO/OphalenLaatsteWaarnemingen&#39;
        request_ddl = {&#34;AquoPlusWaarnemingMetadataLijst&#34;:[{&#34;AquoMetadata&#34;:query_metadata}],&#34;LocatieLijst&#34;:[query_station]}
        result[&#39;WaarnemingenLijst&#39;][2][&#39;MetingenLijst&#39;] 
        &#34;&#34;&#34;
    else:
        #retrieve data
        url_ddl = &#39;https://waterwebservices.rijkswaterstaat.nl/ONLINEWAARNEMINGENSERVICES_DBO/OphalenWaarnemingen&#39;
        request_ddl = {&#34;AquoPlusWaarnemingMetadata&#34;:{&#34;AquoMetadata&#34;:query_metadata},
                      &#34;Locatie&#34;:query_station,#{&#34;X&#34;:518882.333320247,&#34;Y&#34;:5760829.11729589,&#34;Code&#34;:&#34;EURPFM&#34;}, # DDL IMPROVEMENT: it seems not not possible to retreive by station Naam/Code/Locatie_MessageID only. X+Y+Code is minimum, so supplying entire dict. Why is this so strict? It seems odd that one needs to supply a six decimal RD coordinate (so micrometer accuracy) while &#39;Code&#39; and &#39;Locatie_MessageID&#39; are both already unique.
                      &#34;Periode&#34;:{&#34;Begindatumtijd&#34;:query_tstart_str, # DDL IMPROVEMENT: longer timeseries (eg 4 years) take a long time or return error (Foutmelding: Het max aantal waarnemingen (157824) is overschreven, beperk uw request.). Can this not be extended? &gt;&gt; now retrieving per year, is that always possible with this limit?
                                 &#34;Einddatumtijd&#34;:query_tstop_str} # DDL IMPROVEMENT: recent data for eg HOEKVLD is not available but it is as station HOEK, can these stations not be one, but with a different kaliteitscode/statuswaarde/GrootheidCode/GroeperingCode etc? I was a bit surprised that &#39;ongecontroleerd&#39; (and HOEK in general) also has kwaliteitscode=0
                      }
        
    #print(request_ddl)
    resp = requests.post(url_ddl, json=request_ddl)
    if not resp.ok:
        raise Exception(&#39;%s for %s: %s&#39;%(resp.reason, resp.url, str(resp.text)))
    result = resp.json()
    if not result[&#39;Succesvol&#39;]:
        raise Exception(&#39;query not succesful, Foutmelding: %s from %s&#39;%(result[&#39;Foutmelding&#39;],url_ddl))
    return result


def get_DDL_data(station_dict,meta_dict,tstart_dt,tstop_dt,tzone=&#39;UTC+01:00&#39;,allow_multipleresultsfor=[]):
    &#34;&#34;&#34;
    ddl tutorial: https://rijkswaterstaat.github.io/wm-ws-dl/?python#tutorial-locations
    normalizing json output: https://towardsdatascience.com/how-to-convert-json-into-a-pandas-dataframe-100b2ae1e0d8

    query_tzone: MET/CET results in Europe/Amsterdam (so including DST), use fixed offset instead
    allow_multipleresultsfor: when a query returns multiple results, there is also multiple metadata lines. If e.g. allow_multipleresultsfor=[&#39;MeetApparaat&#39;], the metadata fields &#39;MeetApparaat.Code&#39; and &#39;MeetApparaat.Omschrijving&#39; are allowed to be different and the multiple timeseries are merged. A column is added to the output timeseries with these fields, to be able to distinguish measurements taken with different &#39;MeetApparaat&#39;.
    
    &#34;&#34;&#34;

    if not isinstance(allow_multipleresultsfor,list):
        allow_multipleresultsfor = [allow_multipleresultsfor]
    
    #parse meta_dict to query_metadata dict
    query_metadata = {}
    for metakeypoint in meta_dict:
        metakeymain = metakeypoint.split(&#39;.&#39;)[0]
        metakeysub = metakeypoint.split(&#39;.&#39;)[1]
        query_metadata[metakeymain] = {metakeysub:meta_dict[metakeypoint]}
    
    tzinfo = convert_tzone2tzinfo(tzone)
    
    tstart_dt = tstart_dt.replace(tzinfo=tzinfo)
    tstop_dt = tstop_dt.replace(tzinfo=tzinfo)
    year_list = range(tstart_dt.year, tstop_dt.year+1)
    
    station_str = &#39;/&#39;.join([str(station_dict[x]) for x in station_dict.keys() if x not in [&#39;X&#39;,&#39;Y&#39;,&#39;Coordinatenstelsel&#39;]])
    print(&#39;processing station %s: %s to %s (%d years)&#39;%(station_str,tstart_dt,tstop_dt,len(year_list)))
    result_available = get_DDL_queryserver(station_dict,query_metadata,tstart_dt,tstop_dt,check_available=True)
    if result_available[&#39;WaarnemingenAanwezig&#39;]!=&#39;true&#39;: # DDL IMPROVEMENT: WaarnemingenAanwezig is now a &#39;true&#39; string instead of a True boolean (result_available[&#39;Succesvol&#39;] is also a boolean)
        print(&#39;WARNING: no values present for this query, returning None&#39;)
        return #preliminary abort of definition

    addcolumns_list = [f&#39;{x}.{y}&#39; for x in allow_multipleresultsfor for y in [&#39;Code&#39;,&#39;Omschrijving&#39;]]
    result_wl0_metingenlijst_alldates = pd.DataFrame()
    result_wl0_aquometadata_unique = pd.DataFrame()
    result_wl0_locatie_unique = pd.DataFrame()
    for year in year_list:
        tstart_dt_oneyear = np.maximum(tstart_dt,dt.datetime(year,1,1,tzinfo=tzinfo))
        tstop_dt_oneyear = np.minimum(tstop_dt,dt.datetime(year+1,1,1,tzinfo=tzinfo))

        result_available = get_DDL_queryserver(station_dict,query_metadata,tstart_dt_oneyear,tstop_dt_oneyear,check_available=True)
        if result_available[&#39;WaarnemingenAanwezig&#39;]!=&#39;true&#39;: # DDL IMPROVEMENT: WaarnemingenAanwezig is now a &#39;true&#39; string instead of a True boolean (result_available[&#39;Succesvol&#39;] is also a boolean)
            print(&#39;year %d: no values&#39;%(year))
            continue
        print(&#39;year %d: retrieving data&#39;%(year))
        
        result_wl = get_DDL_queryserver(station_dict,query_metadata,tstart_dt_oneyear,tstop_dt_oneyear,check_available=False)
        
        if not result_wl[&#39;Succesvol&#39;]:
            raise Exception(&#39;measurement query not succesful, Foutmelding: %s&#39;%(result_wl[&#39;Foutmelding&#39;]))
        
        range_nresults = range(len(result_wl[&#39;WaarnemingenLijst&#39;]))
        for result_idx in range_nresults:
            result_wl0 = result_wl[&#39;WaarnemingenLijst&#39;][result_idx]
            #get and append locatiedata and metadata
            result_wl0_locatie = pd.json_normalize(result_wl0[&#39;Locatie&#39;])
            result_wl0_locatie_unique = result_wl0_locatie_unique.append(result_wl0_locatie).drop_duplicates() #this will always be just one
            result_wl0_aquometadata = pd.json_normalize(result_wl0[&#39;AquoMetadata&#39;])
            result_wl0_aquometadata_unique = result_wl0_aquometadata_unique.append(result_wl0_aquometadata).drop_duplicates() #this can grow longer for longer periods, if eg the &#39;WaardeBepalingsmethode&#39; changes
            #get one block of meetdata, sort on time and make timezone aware
            result_wl0_metingenlijst = pd.json_normalize(result_wl0[&#39;MetingenLijst&#39;]) # the actual waterlevel data for this station
            if not result_wl0_metingenlijst[&#39;Tijdstip&#39;].is_monotonic_increasing:
                result_wl0_metingenlijst = result_wl0_metingenlijst.sort_values(&#39;Tijdstip&#39;).reset_index(drop=True) # DDL IMPROVEMENT: data in response is not always sorted on time
            last_timestamp_tzaware = pd.to_datetime(result_wl0_metingenlijst[&#39;Tijdstip&#39;].iloc[-1]).tz_convert(tstart_dt.tzinfo)
            if not last_timestamp_tzaware.isoformat().startswith(str(year)): #need to remove the last data entry if it is 1 January in next year (correct for timezone first). (This is often not the necessary for eg extremes since they probably do not have a value on that exact datetime)
                result_wl0_metingenlijst = result_wl0_metingenlijst.iloc[:-1]
            #add metadata to timeseries for allow_multipleresultsfor (to be able to distinguish difference later on)
            for addcolumn in addcolumns_list:
                result_wl0_metingenlijst[addcolumn] = result_wl0_aquometadata.loc[0,addcolumn]
            result_wl0_metingenlijst_alldates = result_wl0_metingenlijst_alldates.append(result_wl0_metingenlijst)
        
        if allow_multipleresultsfor==[]:
            result_wl0_aquometadata_uniqueallowed = result_wl0_aquometadata_unique
        else: #allow multiple results for eg [&#39;MeetApparaat&#39;, &#39;WaardeBepalingsmethode&#39;]
            try:
                list_dropcolumns = [&#39;AquoMetadata_MessageID&#39;,&#39;Parameter_Wat_Omschrijving&#39;]+[&#39;%s.%s&#39;%(colname,postfix) for colname in allow_multipleresultsfor for postfix in [&#39;Code&#39;,&#39;Omschrijving&#39;]]
                result_wl0_aquometadata_uniqueallowed = result_wl0_aquometadata_unique.drop(list_dropcolumns,axis=1).drop_duplicates()
            except KeyError as e:
                metakeys_forCode = [x.replace(&#39;.Code&#39;,&#39;&#39;) for x in result_wl0_aquometadata_unique.keys() if x.endswith(&#39;.Code&#39;)]
                raise Exception(&#39;%s, available are: %s&#39;%(e,metakeys_forCode))
        
        result_wl0_aquometadata_unique = result_wl0_aquometadata_unique.reset_index(drop=True) #necessary to print &#39;Result n:&#39; numbers properly below
        if len(result_wl0_aquometadata_uniqueallowed)&gt;1:
            bool_nonuniquecols = (result_wl0_aquometadata_unique.iloc[0]!=result_wl0_aquometadata_unique).any(axis=0)
            metakeys_forCode_nonunique = [x.replace(&#39;.Code&#39;,&#39;&#39;) for x in result_wl0_aquometadata_unique.loc[:,bool_nonuniquecols].columns if x.endswith(&#39;.Code&#39;)]
            for iR, result_one in result_wl0_aquometadata_unique.iterrows():
                print(f&#39;Result {iR+1}:&#39;)
                metakey_list = sorted(set([&#39;Compartiment&#39;,&#39;Eenheid&#39;,&#39;Grootheid&#39;,&#39;Hoedanigheid&#39;,&#39;Groepering&#39;]+metakeys_forCode_nonunique))
                for metakey in metakey_list:
                    print(&#39;%28s: %s,&#39;%(&#34;&#39;%s&#39;&#34;%metakey,dict(result_one[[f&#39;{metakey}.Code&#39;,f&#39;{metakey}.Omschrijving&#39;]])))
            raise Exception(&#39;query returned more than one result (differences in %s, details above), use more specific query_metadata argument or more extensive allow_multipleresultsfor argument (the latter might result in duplicate timesteps)&#39;%(metakeys_forCode_nonunique))
            
    result_wl0_metingenlijst_alldates = result_wl0_metingenlijst_alldates.reset_index(drop=True)
    # DDL IMPROVEMENT: WaarnemingMetadata: all values are nested lists of length 1, can be flattened (they are actually not list/lijst, but statuswaarde instead of statuswaardelijst and kwaliteitswaardecode instead of kwaliteitswaardecodelijst).
    # DDL IMPROVEMENT: WaarnemingMetadata: Bemonsteringshoogte/Referentievlak/OpdrachtgevendeInstantie is probably constant for each query result, so could be added to aquometadata frame instead of a value per timestep (probably makes query faster and can be longer)
    # DDL IMPROVEMENT: WaarnemingMetadata: there seems to be no explanation in the catalog or metadata of the KwaliteitswaardecodeLijst values
    # DDL IMPROVEMENT: when retrieving waterlevel extremes, it is not possible to distinguish between HW and LW, since the codes are not available in the output
    # create improved pandas DataFrame
    key_numericvalues = &#39;Meetwaarde.Waarde_Numeriek&#39;
    if not key_numericvalues in result_wl0_metingenlijst_alldates.columns: #alfanumeric values for &#39;Typering.Code&#39;:&#39;GETETTPE&#39; #DDL IMPROVEMENT: also include numeric values for getijtype. Also, it is quite complex to get this data in the first place, would be convenient if it would be a column when retrieving &#39;Groepering.Code&#39;:&#39;GETETM2&#39; or &#39;GETETBRKD2&#39;
        key_numericvalues = &#39;Meetwaarde.Waarde_Alfanumeriek&#39;
    ts_meas_pd = pd.DataFrame({&#39;values&#39;:result_wl0_metingenlijst_alldates[key_numericvalues].values,
                               &#39;QC&#39;:pd.to_numeric(result_wl0_metingenlijst_alldates[&#39;WaarnemingMetadata.KwaliteitswaardecodeLijst&#39;].str[0],downcast=&#39;integer&#39;).values, # DDL IMPROVEMENT: should be possible with .astype(int), but pd.to_numeric() is necessary for HARVT10 (eg 2019-09-01 to 2019-11-01) since QC contains None values that cannot be ints (in that case array of floats with some nans is returned) &gt;&gt; replace None with int code
                               &#39;Status&#39;:result_wl0_metingenlijst_alldates[&#39;WaarnemingMetadata.StatuswaardeLijst&#39;].str[0].values,
                               #&#39;Bemonsteringshoogte&#39;:result_wl0_metingenlijst_alldates[&#39;WaarnemingMetadata.BemonsteringshoogteLijst&#39;].str[0].astype(int).values, 
                               #&#39;Referentievlak&#39;:result_wl0_metingenlijst_alldates[&#39;WaarnemingMetadata.ReferentievlakLijst&#39;].str[0].values,
                               #&#39;OpdrachtgevendeInstantie&#39;:result_wl0_metingenlijst_alldates[&#39;WaarnemingMetadata.OpdrachtgevendeInstantieLijst&#39;].str[0].values,
                               },
                              index=pd.to_datetime(result_wl0_metingenlijst_alldates[&#39;Tijdstip&#39;]))
    #add metadata to timeseries for allow_multipleresultsfor (to be able to distinguish difference later on)
    for addcolumn in addcolumns_list:
        ts_meas_pd[addcolumn] = result_wl0_metingenlijst_alldates[addcolumn].values
    #convert timezone from MET to requested timezone
    ts_meas_pd.index = ts_meas_pd.index.tz_convert(tstart_dt.tzinfo)

    bool_timeduplicated = ts_meas_pd.index.duplicated()
    if bool_timeduplicated.any():
        print(f&#39;WARNING: query returned {bool_timeduplicated.sum()} duplicate times, use less extensive allow_multipleresultsfor&#39;) # DDL IMPROVEMENT: even without allow_multipleresultsfor, there are duplicates for e.g. HARVT10  dt.datetime(2013,12,31,23,0) to dt.datetime(2014,1,1), topdesk M220206235
 
    return ts_meas_pd, result_wl0_aquometadata_unique, result_wl0_locatie_unique


def get_DDL_stationmetasubset(catalog_dict, station_dict=None, meta_dict=None, error_empty=True):
    
    cat_aquometadatalijst = catalog_dict[&#39;AquoMetadataLijst&#39;].set_index(&#39;AquoMetadata_MessageID&#39;)
    cat_locatielijst = catalog_dict[&#39;LocatieLijst&#39;].set_index(&#39;Locatie_MessageID&#39;)
    cat_AquoMetadataLocatieLijst_locidx = catalog_dict[&#39;AquoMetadataLocatieLijst&#39;].set_index(&#39;Locatie_MessageID&#39;)
    cat_AquoMetadataLocatieLijst_metaidx = catalog_dict[&#39;AquoMetadataLocatieLijst&#39;].set_index(&#39;AquoMetaData_MessageID&#39;)
    # DDL IMPROVEMENT: AquoMetadataLocatieLijst is missing AquoMetaData_MessageIDs: [38, 43, 75, 98, 99, 176] (and probably somewhat more), so these will not be present in cat_locatielijst_sel
    
    if meta_dict is None and station_dict is None: #this makes the rest of the function a bit simpler to write
        raise Exception(&#39;using this function has no added value when not supplying meta and station&#39;)

    if meta_dict is not None:
        #loop over meta_dict keys, append to array and 
        bool_aquometadatalijst_containingmeta_list = []
        for metakey in meta_dict.keys():
            bool_aquometadatalijst_containingmeta_list.append(cat_aquometadatalijst[metakey].str.contains(meta_dict[metakey],case=False))
        bool_aquometadatalijst_containingmeta = np.array(bool_aquometadatalijst_containingmeta_list).all(axis=0) #logical and
        
        cat_aquometadatalijst_containingmeta = cat_aquometadatalijst.loc[bool_aquometadatalijst_containingmeta]
        bool_metaid_intranslatetable = cat_aquometadatalijst.index.isin(cat_AquoMetadataLocatieLijst_metaidx.index)
        if not bool_metaid_intranslatetable.all():
            cat_AquoMetadataLocatieLijst_missingAquoIDs = cat_aquometadatalijst.loc[~bool_metaid_intranslatetable].index
            print(&#39;WARNING: AquoMetadataLocatieLijst is missing AquoMetaData_MessageIDs:\n%s\nThese IDs will not be present in cat_locatielijst_sel. This issue can be reported to Servicedesk data via: https://www.rijkswaterstaat.nl/formulieren/contactformulier-servicedesk-data&#39;%(cat_aquometadatalijst.loc[cat_AquoMetadataLocatieLijst_missingAquoIDs,[&#39;Grootheid.Code&#39;,&#39;Grootheid.Omschrijving&#39;]]))
            cat_aquometadatalijst_containingmeta = cat_aquometadatalijst.loc[bool_aquometadatalijst_containingmeta &amp; bool_metaid_intranslatetable]
        bool_locatielijst_containingmeta = cat_locatielijst[&#39;Code&#39;].str.contains(&#39;THISSTRINGISNOTINCOLUMN&#39;) #first generate all false bool
        bool_locatielijst_containingmeta_idxtrue = cat_AquoMetadataLocatieLijst_metaidx.loc[cat_aquometadatalijst_containingmeta.index,&#39;Locatie_MessageID&#39;]
        bool_locatielijst_containingmeta.loc[bool_locatielijst_containingmeta_idxtrue] = True
    if station_dict is not None:
        #loop over meta_dict keys, append to array and 
        bool_locatielijst_containingstation_list = []
        for stationkey in station_dict.keys():
            bool_locatielijst_containingstation_list.append(cat_locatielijst[stationkey].str.contains(station_dict[stationkey],case=False))
        bool_locatielijst_containingstation = np.array(bool_locatielijst_containingstation_list).all(axis=0) #logical and
        
        cat_locatielijst_containingstation = cat_locatielijst.loc[bool_locatielijst_containingstation]
        bool_locid_intranslatetable = cat_locatielijst.index.isin(cat_AquoMetadataLocatieLijst_locidx.index)
        if not bool_locid_intranslatetable.all():
            raise Exception(&#39;AquoMetadataLocatieLijst is missing Locatie_MessageID. First time that this occurs, so code is not prepared for this exception&#39;)
            #cat_AquoMetadataLocatieLijst_missingLocIDs = cat_locatielijst.loc[~bool_locid_intranslatetable].index
            #print(&#39;WARNING: AquoMetadataLocatieLijst is missing Locatie_MessageIDs:\n%s\nThese IDs will not be present in cat_aquometadatalijst_sel. This issue can be reported to Servicedesk data via: https://www.rijkswaterstaat.nl/formulieren/contactformulier-servicedesk-data&#39;%(cat_locatielijst.loc[cat_AquoMetadataLocatieLijst_missingLocIDs]))
            #cat_locatielijst_containingstation = cat_locatielijst.loc[bool_locatielijst_containingstation &amp; bool_locid_intranslatetable]
        bool_aquometadatalijst_containingstation = cat_aquometadatalijst[&#39;Grootheid.Omschrijving&#39;].str.contains(&#39;THISSTRINGISNOTINCOLUMN&#39;) #first generate all false bool
        bool_aquometadatalijst_containingstation_idxtrue = cat_AquoMetadataLocatieLijst_locidx.loc[cat_locatielijst_containingstation.index,&#39;AquoMetaData_MessageID&#39;]
        bool_aquometadatalijst_containingstation.loc[bool_aquometadatalijst_containingstation_idxtrue] = True
    
    if meta_dict is not None and station_dict is not None: 
        cat_aquometadatalijst_sel = cat_aquometadatalijst.loc[bool_aquometadatalijst_containingmeta &amp; bool_aquometadatalijst_containingstation]
        cat_locatielijst_sel = cat_locatielijst.loc[bool_locatielijst_containingmeta &amp; bool_locatielijst_containingstation]
    elif meta_dict is None and station_dict is not None:
        cat_aquometadatalijst_sel = cat_aquometadatalijst.loc[bool_aquometadatalijst_containingstation]
        cat_locatielijst_sel = cat_locatielijst.loc[bool_locatielijst_containingstation]
    elif meta_dict is not None and station_dict is None:
        cat_aquometadatalijst_sel = cat_aquometadatalijst.loc[bool_aquometadatalijst_containingmeta]
        cat_locatielijst_sel = cat_locatielijst.loc[bool_locatielijst_containingmeta]

    if error_empty and len(cat_aquometadatalijst_sel)==0 and len(cat_locatielijst_sel)==0:
        raise Exception(&#39;Catalog query yielded no results&#39;)
        
    return cat_aquometadatalijst_sel, cat_locatielijst_sel


def convert_HWLWstr2num(ts_measwlHWLW,ts_measwlHWLWtype):
    &#34;&#34;&#34;
    TVL;1;1;hoogwater
    TVL;1;2;laagwater
    TVL;1;3;laagwater 1
    TVL;1;4;topagger
    TVL;1;5;laagwater 2
    &#34;&#34;&#34;
    ts_measwlHWLW.loc[ts_measwlHWLWtype[&#39;values&#39;]==&#39;hoogwater&#39;,&#39;HWLWcode&#39;] = 1
    ts_measwlHWLW.loc[ts_measwlHWLWtype[&#39;values&#39;]==&#39;laagwater&#39;,&#39;HWLWcode&#39;] = 2
    ts_measwlHWLW.loc[ts_measwlHWLWtype[&#39;values&#39;]==&#39;laagwater 1&#39;,&#39;HWLWcode&#39;] = 3
    ts_measwlHWLW.loc[ts_measwlHWLWtype[&#39;values&#39;]==&#39;topagger&#39;,&#39;HWLWcode&#39;] = 4
    ts_measwlHWLW.loc[ts_measwlHWLWtype[&#39;values&#39;]==&#39;laagwater 2&#39;,&#39;HWLWcode&#39;] = 5
    ts_measwlHWLW[&#39;HWLWcode&#39;] = ts_measwlHWLW[&#39;HWLWcode&#39;].astype(int)
    return ts_measwlHWLW</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="hatyan.getonlinedata.get_DDL_catalog"><code class="name flex">
<span>def <span class="ident">get_DDL_catalog</span></span>(<span>catalog_extrainfo=[])</span>
</code></dt>
<dd>
<div class="desc"><p>check get_DDL_data() for details</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>catalog_filter</code></strong> :&ensp;<code>TYPE</code>, optional</dt>
<dd>DESCRIPTION. The default is []. Possibilities are in <a href="https://rijkswaterstaat.github.io/wm-ws-dl/?json#ophalencatalogus,">https://rijkswaterstaat.github.io/wm-ws-dl/?json#ophalencatalogus,</a> for instance 'MeetApparaten' and 'Parameters'.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>Exception</code></dt>
<dd>DESCRIPTION.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>result_cat_dict</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>DESCRIPTION.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_DDL_catalog(catalog_extrainfo=[]):
    &#34;&#34;&#34;
    check get_DDL_data() for details

    Parameters
    ----------
    catalog_filter : TYPE, optional
        DESCRIPTION. The default is []. Possibilities are in https://rijkswaterstaat.github.io/wm-ws-dl/?json#ophalencatalogus, for instance &#39;MeetApparaten&#39; and &#39;Parameters&#39;.

    Raises
    ------
    Exception
        DESCRIPTION.

    Returns
    -------
    result_cat_dict : TYPE
        DESCRIPTION.
    &#34;&#34;&#34;
    
    #the webservices 
    url_catalog = &#39;https://waterwebservices.rijkswaterstaat.nl/METADATASERVICES_DBO/OphalenCatalogus&#39;
    
    #The request for ophalencatalogus
    catalog_filter = [&#39;Compartimenten&#39;,&#39;Eenheden&#39;,&#39;Grootheden&#39;,&#39;Hoedanigheden&#39;,&#39;Groeperingen&#39;]+catalog_extrainfo
    request_cat = {&#34;CatalogusFilter&#34;: {x:True for x in catalog_filter}}
    
    # pull catalog from the API and store in json format
    resp = requests.post(url_catalog, json=request_cat) # DDL IMPROVEMENT: it takes a long time to retrieve the catalog, it would be valuable if this could be instantaneous (eg by caching on server side).
    if not resp.ok:
        raise Exception(&#39;%s for %s: %s&#39;%(resp.reason, resp.url, str(resp.text)))
    result_cat = resp.json()
    if not result_cat[&#39;Succesvol&#39;]:
        raise Exception(&#39;catalog query not succesful, DDL foutmelding: &#34;%s&#34;&#39;%(result_cat[&#39;Foutmelding&#39;]))
    
    result_cat_dict = {}
    for catalog_key in result_cat.keys():
        if catalog_key==&#39;Succesvol&#39;:
            continue
        if isinstance(result_cat[catalog_key][0],dict):
            result_cat_dict[catalog_key] = pd.json_normalize(result_cat[catalog_key])
        else:
            result_cat_dict[catalog_key] = result_cat[catalog_key]
    
    #this part is only added to show duplicate stations, not essential code
    cat_locatielijst = result_cat_dict[&#39;LocatieLijst&#39;].set_index(&#39;Locatie_MessageID&#39;,drop=True)
    bool_dupl_code = cat_locatielijst[&#39;Code&#39;].duplicated(keep=False) #DDL IMPROVEMENT: there are duplicate station Codes present in the catalogus LocatieLijst, sometimes also the Naam+Code combination is duplicated. Possible to merge stations?
    if bool_dupl_code.any():
        print(f&#39;WARNING: {bool_dupl_code.sum()} duplicate station Codes present in cat_locatielijst. This issue can be reported to Servicedesk data via: https://www.rijkswaterstaat.nl/formulieren/contactformulier-servicedesk-data&#39;)
        print(cat_locatielijst.loc[bool_dupl_code,[&#39;Naam&#39;,&#39;Code&#39;]].sort_values(&#39;Code&#39;))
    
    return result_cat_dict</code></pre>
</details>
</dd>
<dt id="hatyan.getonlinedata.get_DDL_queryserver"><code class="name flex">
<span>def <span class="ident">get_DDL_queryserver</span></span>(<span>query_station, query_metadata, query_tstart, query_tstop, check_available=False)</span>
</code></dt>
<dd>
<div class="desc"><p>check get_DDL_data() for details</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_DDL_queryserver(query_station,query_metadata,query_tstart,query_tstop,check_available=False):
    &#34;&#34;&#34;
    check get_DDL_data() for details
    &#34;&#34;&#34;
    
    tzinfo_numraw = query_tstart.strftime(&#39;%z&#39;) #&#39;+0100&#39;
    tzinfo_numstr = tzinfo_numraw[:3]+&#39;:&#39;+tzinfo_numraw[-2:] #&#39;+01:00&#39;
    query_tstart_str = query_tstart.strftime(&#39;%Y-%m-%dT%H:%M:%S.000&#39;+tzinfo_numstr) #&#34;2021-01-14T09:47:00.000+01:00&#34;
    query_tstop_str  = query_tstop.strftime(&#39;%Y-%m-%dT%H:%M:%S.000&#39;+tzinfo_numstr) #&#34;2021-11-27T10:00:00.000+01:00&#34;
    
    if isinstance(query_station,(pd.Series,dict)):
        query_station = json.loads(pd.Series(query_station).to_json()) # converts pd.Series/dict to_json() and back to dict. This avoids issue with query_station[&#39;Locatie_MessageID&#39;] of type np.int64 (TypeError: Object of type int64 is not JSON serializable)
    else:
        raise Exception(&#39;provide pd.Series or dict as query_station argument&#39;)
    
    if check_available: # Check if data is available
        url_ddl = &#39;https://waterwebservices.rijkswaterstaat.nl/ONLINEWAARNEMINGENSERVICES_DBO/CheckWaarnemingenAanwezig&#39;
        request_ddl = {&#34;AquoMetadataLijst&#34; :[query_metadata],
                         &#34;LocatieLijst&#34;:[query_station],
                         &#34;Periode&#34;:{&#34;Begindatumtijd&#34;:query_tstart_str, # DDL IMPROVEMENT: if user accidentally switches start/stop dates in query, OphalenWaarnemingen returns &#39;Begindatum is groter dan einddatum. (check_available=False)&#39;, CheckWaarnemingenAanwezig crashes instead of returning a proper error
                                    &#34;Einddatumtijd&#34;:query_tstop_str}
                        }
        # DDL IMPROVEMENT: would be valuable to quickly get available start/stop time and number of available measurements (timesteps). Below is a (slow) example, seems to take as much time as retrieving measurements
        # DDL IMPROVEMENT: welke groeperingsperiodes zijn beschikbaar en kan &#39;geen&#39; ook? (JsonProcessingException: Can not construct instance of nl.ordina.request.OphalenAantalWaarnemingenRequest$Groepering from String value &#39;geen&#39;: value not one of declared Enum instance names.)
        &#34;&#34;&#34;
        url_ddl = &#39;https://waterwebservices.rijkswaterstaat.nl/ONLINEWAARNEMINGENSERVICES_DBO/OphalenAantalWaarnemingen&#39;
        request_ddl = {&#34;AquoMetadataLijst&#34; :[query_metadata],
                         &#34;Groeperingsperiode&#34; : &#39;Jaar&#39;, 
                         &#34;LocatieLijst&#34;:[query_station],
                         &#34;Periode&#34;:{&#34;Begindatumtijd&#34;:query_tstart_str,
                                    &#34;Einddatumtijd&#34;:query_tstop_str}
                        }
        print(result[&#39;AantalWaarnemingenPerPeriodeLijst&#39;][0][&#39;AantalMetingenPerPeriodeLijst&#39;])
        &#34;&#34;&#34;
        # DDL IMPROVEMENT: OphalenLaatsteWaarnemingen seems to be valuable to get the end time for a station, however resulted waarnemingenlijst for one station has multiple entries (probably multiple WaardeBepalingsmethode?) but also MetingenLijst sometimes also has multiple entries, how to interpret this?
        &#34;&#34;&#34;
        url_ddl = &#39;https://waterwebservices.rijkswaterstaat.nl/ONLINEWAARNEMINGENSERVICES_DBO/OphalenLaatsteWaarnemingen&#39;
        request_ddl = {&#34;AquoPlusWaarnemingMetadataLijst&#34;:[{&#34;AquoMetadata&#34;:query_metadata}],&#34;LocatieLijst&#34;:[query_station]}
        result[&#39;WaarnemingenLijst&#39;][2][&#39;MetingenLijst&#39;] 
        &#34;&#34;&#34;
    else:
        #retrieve data
        url_ddl = &#39;https://waterwebservices.rijkswaterstaat.nl/ONLINEWAARNEMINGENSERVICES_DBO/OphalenWaarnemingen&#39;
        request_ddl = {&#34;AquoPlusWaarnemingMetadata&#34;:{&#34;AquoMetadata&#34;:query_metadata},
                      &#34;Locatie&#34;:query_station,#{&#34;X&#34;:518882.333320247,&#34;Y&#34;:5760829.11729589,&#34;Code&#34;:&#34;EURPFM&#34;}, # DDL IMPROVEMENT: it seems not not possible to retreive by station Naam/Code/Locatie_MessageID only. X+Y+Code is minimum, so supplying entire dict. Why is this so strict? It seems odd that one needs to supply a six decimal RD coordinate (so micrometer accuracy) while &#39;Code&#39; and &#39;Locatie_MessageID&#39; are both already unique.
                      &#34;Periode&#34;:{&#34;Begindatumtijd&#34;:query_tstart_str, # DDL IMPROVEMENT: longer timeseries (eg 4 years) take a long time or return error (Foutmelding: Het max aantal waarnemingen (157824) is overschreven, beperk uw request.). Can this not be extended? &gt;&gt; now retrieving per year, is that always possible with this limit?
                                 &#34;Einddatumtijd&#34;:query_tstop_str} # DDL IMPROVEMENT: recent data for eg HOEKVLD is not available but it is as station HOEK, can these stations not be one, but with a different kaliteitscode/statuswaarde/GrootheidCode/GroeperingCode etc? I was a bit surprised that &#39;ongecontroleerd&#39; (and HOEK in general) also has kwaliteitscode=0
                      }
        
    #print(request_ddl)
    resp = requests.post(url_ddl, json=request_ddl)
    if not resp.ok:
        raise Exception(&#39;%s for %s: %s&#39;%(resp.reason, resp.url, str(resp.text)))
    result = resp.json()
    if not result[&#39;Succesvol&#39;]:
        raise Exception(&#39;query not succesful, Foutmelding: %s from %s&#39;%(result[&#39;Foutmelding&#39;],url_ddl))
    return result</code></pre>
</details>
</dd>
<dt id="hatyan.getonlinedata.get_DDL_data"><code class="name flex">
<span>def <span class="ident">get_DDL_data</span></span>(<span>station_dict, meta_dict, tstart_dt, tstop_dt, tzone='UTC+01:00', allow_multipleresultsfor=[])</span>
</code></dt>
<dd>
<div class="desc"><p>ddl tutorial: <a href="https://rijkswaterstaat.github.io/wm-ws-dl/?python#tutorial-locations">https://rijkswaterstaat.github.io/wm-ws-dl/?python#tutorial-locations</a>
normalizing json output: <a href="https://towardsdatascience.com/how-to-convert-json-into-a-pandas-dataframe-100b2ae1e0d8">https://towardsdatascience.com/how-to-convert-json-into-a-pandas-dataframe-100b2ae1e0d8</a></p>
<p>query_tzone: MET/CET results in Europe/Amsterdam (so including DST), use fixed offset instead
allow_multipleresultsfor: when a query returns multiple results, there is also multiple metadata lines. If e.g. allow_multipleresultsfor=['MeetApparaat'], the metadata fields 'MeetApparaat.Code' and 'MeetApparaat.Omschrijving' are allowed to be different and the multiple timeseries are merged. A column is added to the output timeseries with these fields, to be able to distinguish measurements taken with different 'MeetApparaat'.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_DDL_data(station_dict,meta_dict,tstart_dt,tstop_dt,tzone=&#39;UTC+01:00&#39;,allow_multipleresultsfor=[]):
    &#34;&#34;&#34;
    ddl tutorial: https://rijkswaterstaat.github.io/wm-ws-dl/?python#tutorial-locations
    normalizing json output: https://towardsdatascience.com/how-to-convert-json-into-a-pandas-dataframe-100b2ae1e0d8

    query_tzone: MET/CET results in Europe/Amsterdam (so including DST), use fixed offset instead
    allow_multipleresultsfor: when a query returns multiple results, there is also multiple metadata lines. If e.g. allow_multipleresultsfor=[&#39;MeetApparaat&#39;], the metadata fields &#39;MeetApparaat.Code&#39; and &#39;MeetApparaat.Omschrijving&#39; are allowed to be different and the multiple timeseries are merged. A column is added to the output timeseries with these fields, to be able to distinguish measurements taken with different &#39;MeetApparaat&#39;.
    
    &#34;&#34;&#34;

    if not isinstance(allow_multipleresultsfor,list):
        allow_multipleresultsfor = [allow_multipleresultsfor]
    
    #parse meta_dict to query_metadata dict
    query_metadata = {}
    for metakeypoint in meta_dict:
        metakeymain = metakeypoint.split(&#39;.&#39;)[0]
        metakeysub = metakeypoint.split(&#39;.&#39;)[1]
        query_metadata[metakeymain] = {metakeysub:meta_dict[metakeypoint]}
    
    tzinfo = convert_tzone2tzinfo(tzone)
    
    tstart_dt = tstart_dt.replace(tzinfo=tzinfo)
    tstop_dt = tstop_dt.replace(tzinfo=tzinfo)
    year_list = range(tstart_dt.year, tstop_dt.year+1)
    
    station_str = &#39;/&#39;.join([str(station_dict[x]) for x in station_dict.keys() if x not in [&#39;X&#39;,&#39;Y&#39;,&#39;Coordinatenstelsel&#39;]])
    print(&#39;processing station %s: %s to %s (%d years)&#39;%(station_str,tstart_dt,tstop_dt,len(year_list)))
    result_available = get_DDL_queryserver(station_dict,query_metadata,tstart_dt,tstop_dt,check_available=True)
    if result_available[&#39;WaarnemingenAanwezig&#39;]!=&#39;true&#39;: # DDL IMPROVEMENT: WaarnemingenAanwezig is now a &#39;true&#39; string instead of a True boolean (result_available[&#39;Succesvol&#39;] is also a boolean)
        print(&#39;WARNING: no values present for this query, returning None&#39;)
        return #preliminary abort of definition

    addcolumns_list = [f&#39;{x}.{y}&#39; for x in allow_multipleresultsfor for y in [&#39;Code&#39;,&#39;Omschrijving&#39;]]
    result_wl0_metingenlijst_alldates = pd.DataFrame()
    result_wl0_aquometadata_unique = pd.DataFrame()
    result_wl0_locatie_unique = pd.DataFrame()
    for year in year_list:
        tstart_dt_oneyear = np.maximum(tstart_dt,dt.datetime(year,1,1,tzinfo=tzinfo))
        tstop_dt_oneyear = np.minimum(tstop_dt,dt.datetime(year+1,1,1,tzinfo=tzinfo))

        result_available = get_DDL_queryserver(station_dict,query_metadata,tstart_dt_oneyear,tstop_dt_oneyear,check_available=True)
        if result_available[&#39;WaarnemingenAanwezig&#39;]!=&#39;true&#39;: # DDL IMPROVEMENT: WaarnemingenAanwezig is now a &#39;true&#39; string instead of a True boolean (result_available[&#39;Succesvol&#39;] is also a boolean)
            print(&#39;year %d: no values&#39;%(year))
            continue
        print(&#39;year %d: retrieving data&#39;%(year))
        
        result_wl = get_DDL_queryserver(station_dict,query_metadata,tstart_dt_oneyear,tstop_dt_oneyear,check_available=False)
        
        if not result_wl[&#39;Succesvol&#39;]:
            raise Exception(&#39;measurement query not succesful, Foutmelding: %s&#39;%(result_wl[&#39;Foutmelding&#39;]))
        
        range_nresults = range(len(result_wl[&#39;WaarnemingenLijst&#39;]))
        for result_idx in range_nresults:
            result_wl0 = result_wl[&#39;WaarnemingenLijst&#39;][result_idx]
            #get and append locatiedata and metadata
            result_wl0_locatie = pd.json_normalize(result_wl0[&#39;Locatie&#39;])
            result_wl0_locatie_unique = result_wl0_locatie_unique.append(result_wl0_locatie).drop_duplicates() #this will always be just one
            result_wl0_aquometadata = pd.json_normalize(result_wl0[&#39;AquoMetadata&#39;])
            result_wl0_aquometadata_unique = result_wl0_aquometadata_unique.append(result_wl0_aquometadata).drop_duplicates() #this can grow longer for longer periods, if eg the &#39;WaardeBepalingsmethode&#39; changes
            #get one block of meetdata, sort on time and make timezone aware
            result_wl0_metingenlijst = pd.json_normalize(result_wl0[&#39;MetingenLijst&#39;]) # the actual waterlevel data for this station
            if not result_wl0_metingenlijst[&#39;Tijdstip&#39;].is_monotonic_increasing:
                result_wl0_metingenlijst = result_wl0_metingenlijst.sort_values(&#39;Tijdstip&#39;).reset_index(drop=True) # DDL IMPROVEMENT: data in response is not always sorted on time
            last_timestamp_tzaware = pd.to_datetime(result_wl0_metingenlijst[&#39;Tijdstip&#39;].iloc[-1]).tz_convert(tstart_dt.tzinfo)
            if not last_timestamp_tzaware.isoformat().startswith(str(year)): #need to remove the last data entry if it is 1 January in next year (correct for timezone first). (This is often not the necessary for eg extremes since they probably do not have a value on that exact datetime)
                result_wl0_metingenlijst = result_wl0_metingenlijst.iloc[:-1]
            #add metadata to timeseries for allow_multipleresultsfor (to be able to distinguish difference later on)
            for addcolumn in addcolumns_list:
                result_wl0_metingenlijst[addcolumn] = result_wl0_aquometadata.loc[0,addcolumn]
            result_wl0_metingenlijst_alldates = result_wl0_metingenlijst_alldates.append(result_wl0_metingenlijst)
        
        if allow_multipleresultsfor==[]:
            result_wl0_aquometadata_uniqueallowed = result_wl0_aquometadata_unique
        else: #allow multiple results for eg [&#39;MeetApparaat&#39;, &#39;WaardeBepalingsmethode&#39;]
            try:
                list_dropcolumns = [&#39;AquoMetadata_MessageID&#39;,&#39;Parameter_Wat_Omschrijving&#39;]+[&#39;%s.%s&#39;%(colname,postfix) for colname in allow_multipleresultsfor for postfix in [&#39;Code&#39;,&#39;Omschrijving&#39;]]
                result_wl0_aquometadata_uniqueallowed = result_wl0_aquometadata_unique.drop(list_dropcolumns,axis=1).drop_duplicates()
            except KeyError as e:
                metakeys_forCode = [x.replace(&#39;.Code&#39;,&#39;&#39;) for x in result_wl0_aquometadata_unique.keys() if x.endswith(&#39;.Code&#39;)]
                raise Exception(&#39;%s, available are: %s&#39;%(e,metakeys_forCode))
        
        result_wl0_aquometadata_unique = result_wl0_aquometadata_unique.reset_index(drop=True) #necessary to print &#39;Result n:&#39; numbers properly below
        if len(result_wl0_aquometadata_uniqueallowed)&gt;1:
            bool_nonuniquecols = (result_wl0_aquometadata_unique.iloc[0]!=result_wl0_aquometadata_unique).any(axis=0)
            metakeys_forCode_nonunique = [x.replace(&#39;.Code&#39;,&#39;&#39;) for x in result_wl0_aquometadata_unique.loc[:,bool_nonuniquecols].columns if x.endswith(&#39;.Code&#39;)]
            for iR, result_one in result_wl0_aquometadata_unique.iterrows():
                print(f&#39;Result {iR+1}:&#39;)
                metakey_list = sorted(set([&#39;Compartiment&#39;,&#39;Eenheid&#39;,&#39;Grootheid&#39;,&#39;Hoedanigheid&#39;,&#39;Groepering&#39;]+metakeys_forCode_nonunique))
                for metakey in metakey_list:
                    print(&#39;%28s: %s,&#39;%(&#34;&#39;%s&#39;&#34;%metakey,dict(result_one[[f&#39;{metakey}.Code&#39;,f&#39;{metakey}.Omschrijving&#39;]])))
            raise Exception(&#39;query returned more than one result (differences in %s, details above), use more specific query_metadata argument or more extensive allow_multipleresultsfor argument (the latter might result in duplicate timesteps)&#39;%(metakeys_forCode_nonunique))
            
    result_wl0_metingenlijst_alldates = result_wl0_metingenlijst_alldates.reset_index(drop=True)
    # DDL IMPROVEMENT: WaarnemingMetadata: all values are nested lists of length 1, can be flattened (they are actually not list/lijst, but statuswaarde instead of statuswaardelijst and kwaliteitswaardecode instead of kwaliteitswaardecodelijst).
    # DDL IMPROVEMENT: WaarnemingMetadata: Bemonsteringshoogte/Referentievlak/OpdrachtgevendeInstantie is probably constant for each query result, so could be added to aquometadata frame instead of a value per timestep (probably makes query faster and can be longer)
    # DDL IMPROVEMENT: WaarnemingMetadata: there seems to be no explanation in the catalog or metadata of the KwaliteitswaardecodeLijst values
    # DDL IMPROVEMENT: when retrieving waterlevel extremes, it is not possible to distinguish between HW and LW, since the codes are not available in the output
    # create improved pandas DataFrame
    key_numericvalues = &#39;Meetwaarde.Waarde_Numeriek&#39;
    if not key_numericvalues in result_wl0_metingenlijst_alldates.columns: #alfanumeric values for &#39;Typering.Code&#39;:&#39;GETETTPE&#39; #DDL IMPROVEMENT: also include numeric values for getijtype. Also, it is quite complex to get this data in the first place, would be convenient if it would be a column when retrieving &#39;Groepering.Code&#39;:&#39;GETETM2&#39; or &#39;GETETBRKD2&#39;
        key_numericvalues = &#39;Meetwaarde.Waarde_Alfanumeriek&#39;
    ts_meas_pd = pd.DataFrame({&#39;values&#39;:result_wl0_metingenlijst_alldates[key_numericvalues].values,
                               &#39;QC&#39;:pd.to_numeric(result_wl0_metingenlijst_alldates[&#39;WaarnemingMetadata.KwaliteitswaardecodeLijst&#39;].str[0],downcast=&#39;integer&#39;).values, # DDL IMPROVEMENT: should be possible with .astype(int), but pd.to_numeric() is necessary for HARVT10 (eg 2019-09-01 to 2019-11-01) since QC contains None values that cannot be ints (in that case array of floats with some nans is returned) &gt;&gt; replace None with int code
                               &#39;Status&#39;:result_wl0_metingenlijst_alldates[&#39;WaarnemingMetadata.StatuswaardeLijst&#39;].str[0].values,
                               #&#39;Bemonsteringshoogte&#39;:result_wl0_metingenlijst_alldates[&#39;WaarnemingMetadata.BemonsteringshoogteLijst&#39;].str[0].astype(int).values, 
                               #&#39;Referentievlak&#39;:result_wl0_metingenlijst_alldates[&#39;WaarnemingMetadata.ReferentievlakLijst&#39;].str[0].values,
                               #&#39;OpdrachtgevendeInstantie&#39;:result_wl0_metingenlijst_alldates[&#39;WaarnemingMetadata.OpdrachtgevendeInstantieLijst&#39;].str[0].values,
                               },
                              index=pd.to_datetime(result_wl0_metingenlijst_alldates[&#39;Tijdstip&#39;]))
    #add metadata to timeseries for allow_multipleresultsfor (to be able to distinguish difference later on)
    for addcolumn in addcolumns_list:
        ts_meas_pd[addcolumn] = result_wl0_metingenlijst_alldates[addcolumn].values
    #convert timezone from MET to requested timezone
    ts_meas_pd.index = ts_meas_pd.index.tz_convert(tstart_dt.tzinfo)

    bool_timeduplicated = ts_meas_pd.index.duplicated()
    if bool_timeduplicated.any():
        print(f&#39;WARNING: query returned {bool_timeduplicated.sum()} duplicate times, use less extensive allow_multipleresultsfor&#39;) # DDL IMPROVEMENT: even without allow_multipleresultsfor, there are duplicates for e.g. HARVT10  dt.datetime(2013,12,31,23,0) to dt.datetime(2014,1,1), topdesk M220206235
 
    return ts_meas_pd, result_wl0_aquometadata_unique, result_wl0_locatie_unique</code></pre>
</details>
</dd>
<dt id="hatyan.getonlinedata.get_DDL_stationmetasubset"><code class="name flex">
<span>def <span class="ident">get_DDL_stationmetasubset</span></span>(<span>catalog_dict, station_dict=None, meta_dict=None, error_empty=True)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_DDL_stationmetasubset(catalog_dict, station_dict=None, meta_dict=None, error_empty=True):
    
    cat_aquometadatalijst = catalog_dict[&#39;AquoMetadataLijst&#39;].set_index(&#39;AquoMetadata_MessageID&#39;)
    cat_locatielijst = catalog_dict[&#39;LocatieLijst&#39;].set_index(&#39;Locatie_MessageID&#39;)
    cat_AquoMetadataLocatieLijst_locidx = catalog_dict[&#39;AquoMetadataLocatieLijst&#39;].set_index(&#39;Locatie_MessageID&#39;)
    cat_AquoMetadataLocatieLijst_metaidx = catalog_dict[&#39;AquoMetadataLocatieLijst&#39;].set_index(&#39;AquoMetaData_MessageID&#39;)
    # DDL IMPROVEMENT: AquoMetadataLocatieLijst is missing AquoMetaData_MessageIDs: [38, 43, 75, 98, 99, 176] (and probably somewhat more), so these will not be present in cat_locatielijst_sel
    
    if meta_dict is None and station_dict is None: #this makes the rest of the function a bit simpler to write
        raise Exception(&#39;using this function has no added value when not supplying meta and station&#39;)

    if meta_dict is not None:
        #loop over meta_dict keys, append to array and 
        bool_aquometadatalijst_containingmeta_list = []
        for metakey in meta_dict.keys():
            bool_aquometadatalijst_containingmeta_list.append(cat_aquometadatalijst[metakey].str.contains(meta_dict[metakey],case=False))
        bool_aquometadatalijst_containingmeta = np.array(bool_aquometadatalijst_containingmeta_list).all(axis=0) #logical and
        
        cat_aquometadatalijst_containingmeta = cat_aquometadatalijst.loc[bool_aquometadatalijst_containingmeta]
        bool_metaid_intranslatetable = cat_aquometadatalijst.index.isin(cat_AquoMetadataLocatieLijst_metaidx.index)
        if not bool_metaid_intranslatetable.all():
            cat_AquoMetadataLocatieLijst_missingAquoIDs = cat_aquometadatalijst.loc[~bool_metaid_intranslatetable].index
            print(&#39;WARNING: AquoMetadataLocatieLijst is missing AquoMetaData_MessageIDs:\n%s\nThese IDs will not be present in cat_locatielijst_sel. This issue can be reported to Servicedesk data via: https://www.rijkswaterstaat.nl/formulieren/contactformulier-servicedesk-data&#39;%(cat_aquometadatalijst.loc[cat_AquoMetadataLocatieLijst_missingAquoIDs,[&#39;Grootheid.Code&#39;,&#39;Grootheid.Omschrijving&#39;]]))
            cat_aquometadatalijst_containingmeta = cat_aquometadatalijst.loc[bool_aquometadatalijst_containingmeta &amp; bool_metaid_intranslatetable]
        bool_locatielijst_containingmeta = cat_locatielijst[&#39;Code&#39;].str.contains(&#39;THISSTRINGISNOTINCOLUMN&#39;) #first generate all false bool
        bool_locatielijst_containingmeta_idxtrue = cat_AquoMetadataLocatieLijst_metaidx.loc[cat_aquometadatalijst_containingmeta.index,&#39;Locatie_MessageID&#39;]
        bool_locatielijst_containingmeta.loc[bool_locatielijst_containingmeta_idxtrue] = True
    if station_dict is not None:
        #loop over meta_dict keys, append to array and 
        bool_locatielijst_containingstation_list = []
        for stationkey in station_dict.keys():
            bool_locatielijst_containingstation_list.append(cat_locatielijst[stationkey].str.contains(station_dict[stationkey],case=False))
        bool_locatielijst_containingstation = np.array(bool_locatielijst_containingstation_list).all(axis=0) #logical and
        
        cat_locatielijst_containingstation = cat_locatielijst.loc[bool_locatielijst_containingstation]
        bool_locid_intranslatetable = cat_locatielijst.index.isin(cat_AquoMetadataLocatieLijst_locidx.index)
        if not bool_locid_intranslatetable.all():
            raise Exception(&#39;AquoMetadataLocatieLijst is missing Locatie_MessageID. First time that this occurs, so code is not prepared for this exception&#39;)
            #cat_AquoMetadataLocatieLijst_missingLocIDs = cat_locatielijst.loc[~bool_locid_intranslatetable].index
            #print(&#39;WARNING: AquoMetadataLocatieLijst is missing Locatie_MessageIDs:\n%s\nThese IDs will not be present in cat_aquometadatalijst_sel. This issue can be reported to Servicedesk data via: https://www.rijkswaterstaat.nl/formulieren/contactformulier-servicedesk-data&#39;%(cat_locatielijst.loc[cat_AquoMetadataLocatieLijst_missingLocIDs]))
            #cat_locatielijst_containingstation = cat_locatielijst.loc[bool_locatielijst_containingstation &amp; bool_locid_intranslatetable]
        bool_aquometadatalijst_containingstation = cat_aquometadatalijst[&#39;Grootheid.Omschrijving&#39;].str.contains(&#39;THISSTRINGISNOTINCOLUMN&#39;) #first generate all false bool
        bool_aquometadatalijst_containingstation_idxtrue = cat_AquoMetadataLocatieLijst_locidx.loc[cat_locatielijst_containingstation.index,&#39;AquoMetaData_MessageID&#39;]
        bool_aquometadatalijst_containingstation.loc[bool_aquometadatalijst_containingstation_idxtrue] = True
    
    if meta_dict is not None and station_dict is not None: 
        cat_aquometadatalijst_sel = cat_aquometadatalijst.loc[bool_aquometadatalijst_containingmeta &amp; bool_aquometadatalijst_containingstation]
        cat_locatielijst_sel = cat_locatielijst.loc[bool_locatielijst_containingmeta &amp; bool_locatielijst_containingstation]
    elif meta_dict is None and station_dict is not None:
        cat_aquometadatalijst_sel = cat_aquometadatalijst.loc[bool_aquometadatalijst_containingstation]
        cat_locatielijst_sel = cat_locatielijst.loc[bool_locatielijst_containingstation]
    elif meta_dict is not None and station_dict is None:
        cat_aquometadatalijst_sel = cat_aquometadatalijst.loc[bool_aquometadatalijst_containingmeta]
        cat_locatielijst_sel = cat_locatielijst.loc[bool_locatielijst_containingmeta]

    if error_empty and len(cat_aquometadatalijst_sel)==0 and len(cat_locatielijst_sel)==0:
        raise Exception(&#39;Catalog query yielded no results&#39;)
        
    return cat_aquometadatalijst_sel, cat_locatielijst_sel</code></pre>
</details>
</dd>
<dt id="hatyan.getonlinedata.convert_HWLWstr2num"><code class="name flex">
<span>def <span class="ident">convert_HWLWstr2num</span></span>(<span>ts_measwlHWLW, ts_measwlHWLWtype)</span>
</code></dt>
<dd>
<div class="desc"><p>TVL;1;1;hoogwater
TVL;1;2;laagwater
TVL;1;3;laagwater 1
TVL;1;4;topagger
TVL;1;5;laagwater 2</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def convert_HWLWstr2num(ts_measwlHWLW,ts_measwlHWLWtype):
    &#34;&#34;&#34;
    TVL;1;1;hoogwater
    TVL;1;2;laagwater
    TVL;1;3;laagwater 1
    TVL;1;4;topagger
    TVL;1;5;laagwater 2
    &#34;&#34;&#34;
    ts_measwlHWLW.loc[ts_measwlHWLWtype[&#39;values&#39;]==&#39;hoogwater&#39;,&#39;HWLWcode&#39;] = 1
    ts_measwlHWLW.loc[ts_measwlHWLWtype[&#39;values&#39;]==&#39;laagwater&#39;,&#39;HWLWcode&#39;] = 2
    ts_measwlHWLW.loc[ts_measwlHWLWtype[&#39;values&#39;]==&#39;laagwater 1&#39;,&#39;HWLWcode&#39;] = 3
    ts_measwlHWLW.loc[ts_measwlHWLWtype[&#39;values&#39;]==&#39;topagger&#39;,&#39;HWLWcode&#39;] = 4
    ts_measwlHWLW.loc[ts_measwlHWLWtype[&#39;values&#39;]==&#39;laagwater 2&#39;,&#39;HWLWcode&#39;] = 5
    ts_measwlHWLW[&#39;HWLWcode&#39;] = ts_measwlHWLW[&#39;HWLWcode&#39;].astype(int)
    return ts_measwlHWLW</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="hatyan" href="index.html">hatyan</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="hatyan.getonlinedata.get_DDL_catalog" href="#hatyan.getonlinedata.get_DDL_catalog">get_DDL_catalog</a></code></li>
<li><code><a title="hatyan.getonlinedata.get_DDL_queryserver" href="#hatyan.getonlinedata.get_DDL_queryserver">get_DDL_queryserver</a></code></li>
<li><code><a title="hatyan.getonlinedata.get_DDL_data" href="#hatyan.getonlinedata.get_DDL_data">get_DDL_data</a></code></li>
<li><code><a title="hatyan.getonlinedata.get_DDL_stationmetasubset" href="#hatyan.getonlinedata.get_DDL_stationmetasubset">get_DDL_stationmetasubset</a></code></li>
<li><code><a title="hatyan.getonlinedata.convert_HWLWstr2num" href="#hatyan.getonlinedata.convert_HWLWstr2num">convert_HWLWstr2num</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>